{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0f8a78-6669-4822-b6d7-4648c45530e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# venv setup, select in the top right\n",
    "# mamba create -n torchchat python=3.10 ipykernel ccache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac4d5b0-7d83-42c8-a042-672673a75448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'torchchat' already exists and is not an empty directory.\n",
      "/mnt/nvme1n1p1/MI300-testing/torchchat\n",
      "/mnt/nvme1n1p1/MI300-testing/torchchat\n",
      "+ pip install -r install/requirements.txt --extra-index-url https://download.pytorch.org/whl/nightly/cu121\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cu121\n",
      "Collecting huggingface_hub (from -r install/requirements.txt (line 4))\n",
      "  Using cached huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting gguf (from -r install/requirements.txt (line 7))\n",
      "  Using cached gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tiktoken (from -r install/requirements.txt (line 10))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting snakeviz (from -r install/requirements.txt (line 13))\n",
      "  Using cached snakeviz-2.2.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting sentencepiece (from -r install/requirements.txt (line 14))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy<2.0 (from -r install/requirements.txt (line 15))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m187.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting blobfile (from -r install/requirements.txt (line 17))\n",
      "  Using cached https://download.pytorch.org/whl/nightly/blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "Collecting tomli>=1.1.0 (from -r install/requirements.txt (line 18))\n",
      "  Downloading tomli-2.0.2-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting openai (from -r install/requirements.txt (line 19))\n",
      "  Using cached openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wheel in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from -r install/requirements.txt (line 22)) (0.44.0)\n",
      "Collecting cmake>=3.24 (from -r install/requirements.txt (line 23))\n",
      "  Using cached cmake-3.30.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting ninja (from -r install/requirements.txt (line 24))\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting zstd (from -r install/requirements.txt (line 25))\n",
      "  Downloading zstd-1.5.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting streamlit (from -r install/requirements.txt (line 28))\n",
      "  Using cached streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting flask (from -r install/requirements.txt (line 31))\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting filelock (from huggingface_hub->-r install/requirements.txt (line 4))\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub->-r install/requirements.txt (line 4))\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from huggingface_hub->-r install/requirements.txt (line 4)) (24.1)\n",
      "Collecting pyyaml>=5.1 (from huggingface_hub->-r install/requirements.txt (line 4))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from huggingface_hub->-r install/requirements.txt (line 4))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub->-r install/requirements.txt (line 4))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from huggingface_hub->-r install/requirements.txt (line 4)) (4.12.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->-r install/requirements.txt (line 10))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m190.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado>=2.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from snakeviz->-r install/requirements.txt (line 13)) (6.4.1)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile->-r install/requirements.txt (line 17))\n",
      "  Using cached https://download.pytorch.org/whl/nightly/pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "Collecting urllib3<3,>=1.25.3 (from blobfile->-r install/requirements.txt (line 17))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting lxml>=4.9 (from blobfile->-r install/requirements.txt (line 17))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio<5,>=3.5.0 (from openai->-r install/requirements.txt (line 19))\n",
      "  Using cached anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r install/requirements.txt (line 19))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r install/requirements.txt (line 19))\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->-r install/requirements.txt (line 19))\n",
      "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r install/requirements.txt (line 19))\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting sniffio (from openai->-r install/requirements.txt (line 19))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m190.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow<11,>=7.1.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m205.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich<14,>=10.14.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting watchdog<6,>=2.1.5 (from streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from flask->-r install/requirements.txt (line 31))\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Jinja2>=3.1.2 (from flask->-r install/requirements.txt (line 31))\n",
      "  Using cached https://download.pytorch.org/whl/nightly/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from flask->-r install/requirements.txt (line 31))\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.5.2 (from altair<6,>=4.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached narwhals-1.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai->-r install/requirements.txt (line 19))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/idna-3.10-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r install/requirements.txt (line 19)) (1.2.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai->-r install/requirements.txt (line 19))\n",
      "  Downloading https://download.pytorch.org/whl/nightly/certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r install/requirements.txt (line 19))\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r install/requirements.txt (line 19))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask->-r install/requirements.txt (line 31))\n",
      "  Downloading MarkupSafe-3.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit->-r install/requirements.txt (line 28)) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached https://download.pytorch.org/whl/nightly/pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached https://download.pytorch.org/whl/nightly/tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai->-r install/requirements.txt (line 19))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->openai->-r install/requirements.txt (line 19))\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface_hub->-r install/requirements.txt (line 4))\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->-r install/requirements.txt (line 28)) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached https://download.pytorch.org/whl/nightly/attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Downloading rpds_py-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r install/requirements.txt (line 28))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit->-r install/requirements.txt (line 28)) (1.16.0)\n",
      "Using cached huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "Using cached gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "Using cached snakeviz-2.2.0-py2.py3-none-any.whl (283 kB)\n",
      "Downloading tomli-2.0.2-py3-none-any.whl (13 kB)\n",
      "Using cached openai-1.51.2-py3-none-any.whl (383 kB)\n",
      "Using cached cmake-3.30.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n",
      "Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Downloading zstd-1.5.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m245.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m337.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Using cached narwhals-1.9.3-py3-none-any.whl (185 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: zstd, sentencepiece, pytz, ninja, watchdog, urllib3, tzdata, tqdm, tomli, toml, tenacity, sniffio, snakeviz, smmap, rpds-py, regex, pyyaml, pydantic-core, pycryptodomex, protobuf, pillow, numpy, narwhals, mdurl, MarkupSafe, lxml, jiter, itsdangerous, idna, h11, fsspec, filelock, distro, cmake, click, charset-normalizer, certifi, cachetools, blinker, attrs, annotated-types, Werkzeug, requests, referencing, pydantic, pyarrow, pandas, markdown-it-py, Jinja2, httpcore, gitdb, gguf, blobfile, anyio, tiktoken, rich, pydeck, jsonschema-specifications, huggingface_hub, httpx, gitpython, flask, openai, jsonschema, altair, streamlit\n",
      "Successfully installed Jinja2-3.1.4 MarkupSafe-3.0.1 Werkzeug-3.0.4 altair-5.4.1 annotated-types-0.7.0 anyio-4.6.2.post1 attrs-24.2.0 blinker-1.8.2 blobfile-3.0.0 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 cmake-3.30.4 distro-1.9.0 filelock-3.16.1 flask-3.0.3 fsspec-2024.9.0 gguf-0.10.0 gitdb-4.0.11 gitpython-3.1.43 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface_hub-0.25.2 idna-3.10 itsdangerous-2.2.0 jiter-0.6.1 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 lxml-5.3.0 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.9.3 ninja-1.11.1.1 numpy-1.26.4 openai-1.51.2 pandas-2.2.3 pillow-10.4.0 protobuf-5.28.2 pyarrow-17.0.0 pycryptodomex-3.21.0 pydantic-2.9.2 pydantic-core-2.23.4 pydeck-0.9.1 pytz-2024.2 pyyaml-6.0.2 referencing-0.35.1 regex-2024.9.11 requests-2.32.3 rich-13.9.2 rpds-py-0.20.0 sentencepiece-0.2.0 smmap-5.0.1 snakeviz-2.2.0 sniffio-1.3.1 streamlit-1.39.0 tenacity-9.0.0 tiktoken-0.8.0 toml-0.10.2 tomli-2.0.2 tqdm-4.66.5 tzdata-2024.2 urllib3-2.2.3 watchdog-5.0.3 zstd-1.5.5.1\n",
      "+ pip uninstall -y triton\n",
      "\u001b[33mWARNING: Skipping triton as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m+ pip install --extra-index-url https://download.pytorch.org/whl/nightly/rocm6.2 torch==2.6.0.dev20241002 torchvision==0.20.0.dev20241002 torchtune==0.3.0.dev20240928\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/rocm6.2\n",
      "Collecting torch==2.6.0.dev20241002\n",
      "  Downloading https://download.pytorch.org/whl/nightly/rocm6.2/torch-2.6.0.dev20241002%2Brocm6.2-cp310-cp310-linux_x86_64.whl (3974.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 GB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.20.0.dev20241002\n",
      "  Downloading https://download.pytorch.org/whl/nightly/rocm6.2/torchvision-0.20.0.dev20241002%2Brocm6.2-cp310-cp310-linux_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torchtune==0.3.0.dev20240928 (from versions: 0.0.1, 0.1.0, 0.1.1, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.4.0.dev20241009+rocm6.2, 0.4.0.dev20241010+rocm6.2, 0.4.0.dev20241011+rocm6.2)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtune==0.3.0.dev20240928\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/torchchat.git\n",
    "%cd torchchat\n",
    "!pwd\n",
    "!install/install_requirements.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8feefc6e-ec0c-406c-81b3-5b1c86691d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/rocm6.2\n",
      "Requirement already satisfied: torch in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (2.6.0.dev20241015+rocm6.2)\n",
      "Requirement already satisfied: torchvision in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (0.20.0.dev20241015+rocm6.2)\n",
      "Requirement already satisfied: torchaudio in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (2.5.0.dev20241015+rocm6.2)\n",
      "Requirement already satisfied: filelock in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.1.0+cf34004b8a in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torch) (3.1.0+cf34004b8a)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from jinja2->torch) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.2 -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dee35fb-64fd-4814-b460-898911fd3189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtune\n",
      "  Using cached torchtune-0.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets (from torchtune)\n",
      "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: huggingface-hub in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchtune) (0.25.2)\n",
      "Collecting safetensors (from torchtune)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: sentencepiece in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchtune) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchtune) (0.8.0)\n",
      "Requirement already satisfied: blobfile>=2 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchtune) (3.0.0)\n",
      "Requirement already satisfied: numpy in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchtune) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchtune) (4.66.5)\n",
      "Collecting omegaconf (from torchtune)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: psutil in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchtune) (6.0.0)\n",
      "Requirement already satisfied: Pillow>=9.4.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from torchtune) (10.4.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from blobfile>=2->torchtune) (3.21.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from blobfile>=2->torchtune) (2.2.3)\n",
      "Requirement already satisfied: lxml>=4.9 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from blobfile>=2->torchtune) (5.3.0)\n",
      "Requirement already satisfied: filelock>=3.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from blobfile>=2->torchtune) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from datasets->torchtune) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->torchtune)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from datasets->torchtune) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from datasets->torchtune) (2.32.3)\n",
      "Collecting xxhash (from datasets->torchtune)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->torchtune)\n",
      "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->torchtune)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets->torchtune)\n",
      "  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: packaging in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from datasets->torchtune) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from datasets->torchtune) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from huggingface-hub->torchtune) (4.12.2)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from tiktoken->torchtune) (2024.9.11)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->torchtune)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->torchtune)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from aiohttp->datasets->torchtune) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->torchtune)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->torchtune)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets->torchtune)\n",
      "  Downloading yarl-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->torchtune)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from requests>=2.32.2->datasets->torchtune) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from requests>=2.32.2->datasets->torchtune) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from requests>=2.32.2->datasets->torchtune) (2024.8.30)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets->torchtune)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from pandas->datasets->torchtune) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from pandas->datasets->torchtune) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from pandas->datasets->torchtune) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/nvme1n1p1/miniforge3/envs/torchchat/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.16.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets->torchtune)\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Using cached torchtune-0.3.1-py3-none-any.whl (596 kB)\n",
      "Using cached datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m140.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading yarl-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=a8bf8f81681a16f4d24e2a84fd3ee3b73987e0a1fb1a4a063a7912bc419d0bee\n",
      "  Stored in directory: /home/hotaisle/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, xxhash, safetensors, propcache, omegaconf, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets, torchtune\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.3 datasets-3.0.1 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.6.1 multidict-6.1.0 multiprocess-0.70.16 omegaconf-2.3.0 propcache-0.2.0 safetensors-0.4.5 torchtune-0.3.1 xxhash-3.5.0 yarl-1.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f1f4ab-00ea-4003-ba37-6daab3607f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchao\n",
      "  Downloading torchao-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading torchao-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchao\n",
      "Successfully installed torchao-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2339afc3-9549-4c21-bcdd-e952a9f4f03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                                        Aliases                                                    Downloaded \n",
      "-------------------------------------------- ---------------------------------------------------------- -----------\n",
      "meta-llama/llama-2-7b-hf                     llama2-base, llama2-7b                                                \n",
      "meta-llama/llama-2-7b-chat-hf                llama2, llama2-chat, llama2-7b-chat                                   \n",
      "meta-llama/llama-2-13b-chat-hf               llama2-13b-chat                                                       \n",
      "meta-llama/llama-2-70b-chat-hf               llama2-70b-chat                                                       \n",
      "meta-llama/meta-llama-3-8b                   llama3-base                                                           \n",
      "meta-llama/meta-llama-3-8b-instruct          llama3, llama3-chat, llama3-instruct                                  \n",
      "meta-llama/meta-llama-3-70b-instruct         llama3-70b                                                            \n",
      "meta-llama/meta-llama-3.1-8b                 llama3.1-base                                                         \n",
      "meta-llama/meta-llama-3.1-8b-instruct        llama3.1, llama3.1-chat, llama3.1-instruct                            \n",
      "meta-llama/meta-llama-3.1-70b-instruct       llama3.1-70b                                                          \n",
      "meta-llama/meta-llama-3.1-8b-instruct-tune   llama3.1-tune, llama3.1-chat-tune, llama3.1-instruct-tune             \n",
      "meta-llama/meta-llama-3.1-70b-instruct-tune  llama3.1-70b-tune                                                     \n",
      "meta-llama/meta-llama-3.2-1b                 llama3.2-1b-base                                                      \n",
      "meta-llama/meta-llama-3.2-1b-instruct        llama3.2-1b, llama3.2-1b-chat, llama3.2-1b-instruct                   \n",
      "meta-llama/llama-guard-3-1b                  llama3-1b-guard, llama3.2-1b-guard                                    \n",
      "meta-llama/meta-llama-3.2-3b                 llama3.2-3b-base                                                      \n",
      "meta-llama/meta-llama-3.2-3b-instruct        llama3.2-3b, llama3.2-3b-chat, llama3.2-3b-instruct                   \n",
      "meta-llama/llama-3.2-11b-vision              llama3.2-11B-base, Llama-3.2-11B-Vision-base                          \n",
      "meta-llama/llama-3.2-11b-vision-instruct     llama3.2-11B, Llama-3.2-11B-Vision, Llama-3.2-mm                      \n",
      "meta-llama/codellama-7b-python-hf            codellama, codellama-7b                                               \n",
      "meta-llama/codellama-34b-python-hf           codellama-34b                                                         \n",
      "mistralai/mistral-7b-v0.1                    mistral-7b-v01-base                                                   \n",
      "mistralai/mistral-7b-instruct-v0.1           mistral-7b-v01-instruct                                               \n",
      "mistralai/mistral-7b-instruct-v0.2           mistral, mistral-7b, mistral-7b-instruct                              \n",
      "openlm-research/open_llama_7b                open-llama, open-llama-7b                                             \n",
      "stories15m                                                                                                         \n",
      "stories42m                                                                                                         \n",
      "stories110m                                                                                                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python torchchat.py list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b60e8bc-a646-4cc2-b4db-8d71b560a763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device=cuda AMD Instinct MI300X\n",
      "Loading model...\n",
      "Time to load model: 6.34 seconds\n",
      "-----------------------------------------------------------\n",
      "write me a story about a boy and his bear\n",
      "The sun was setting over the forest, casting a warm golden light over the tall trees and the wildflowers that bloomed beneath them. In a small clearing, a boy named Max was sitting on a bench, his furry companion, Boris the bear, curled up beside him.\n",
      "\n",
      "Max and Boris had been inseparable since they were both just a few years old. Their families had brought them together, bonding over their love of adventure and the great outdoors. As they grew older, their friendship only deepened, and Max and Boris became a familiar sight in the forest, exploring every nook and cranny, and always finding new wonders to discover.\n",
      "\n",
      "As the sun dipped lower in the sky, Max leaned over and scratched Boris behind the ears, earning a contented sigh from his furry friend. \"What do you want to do tonight, boy?\" Max asked, grinning at Boris's sleepy expression.\n",
      "\n",
      "Boris yawned, his tongue lolling out of his mouth, but his\n",
      "========================================\n",
      "\n",
      "\n",
      "      Average tokens/sec (total): 10.71                 \n",
      "Average tokens/sec (first token): 0.08                 \n",
      "Average tokens/sec (next tokens): 30.94 \n",
      "                \n",
      "Memory used: 16.68 GB\n"
     ]
    }
   ],
   "source": [
    "!python3 torchchat.py generate llama3.1 --prompt \"write me a story about a boy and his bear\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchchat]",
   "language": "python",
   "name": "conda-env-torchchat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
