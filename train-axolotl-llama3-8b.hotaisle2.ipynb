{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620ad71f-089d-49dc-b4e2-78e2208f8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ulimit -n 1031072\n",
    "# sudo mount /dev/nvme8n1p1 /tmp -o noatime\n",
    "#sudo apt install libaio-dev\n",
    "\"\"\"\n",
    "mkdir /mnt/nvme7n1p1/outputs\n",
    "ln -s /mnt/nvme7n1p1/outputs\n",
    "\n",
    "mamba install ipykernel\n",
    "python -m ipykernel install --user --name axolotl\n",
    "\n",
    "\n",
    "# xformers 46bc17de\n",
    "clone https://github.com/ROCm/xformers\n",
    "cd xformers\n",
    "git submodule update --init --recursive\n",
    "pip install . \n",
    "\n",
    "│\n",
    "  3ms   13h ago git clone https://github.com/microsoft/DeepSpeed.git                                                                                                 │\n",
    " │   813us 13h ago cd DeepSpeed/                                                                                                                                        │\n",
    " │   36ms  13h ago git submodule update --init --recursive      \n",
    "\n",
    "\n",
    "INSTALL_KERNELS=1 pip install git+https://github.com/casper-hansen/AutoAWQ.git                                                                       │\n",
    "\n",
    "│   776ms  1d ago git clone https://github.com/OpenAccess-AI-Collective/axolotl                                                                                        │\n",
    "cd axololtl\n",
    "│   35s   13h ago pip install -e . \n",
    "\n",
    "\n",
    "\n",
    "pip install 'https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_multi-backend-refactor/bitsandbytes-0.44.1.│\n",
    "\n",
    "│   181ms 13h ago wget https://raw.githubusercontent.com/ROCm/rocm-blogs/refs/heads/release/blogs/artificial-intelligence/axolotl/src/fft-8b-amd.yaml                  │\n",
    "accelerate launch -m axolotl.cli.train fft-8b-amd.yaml                                                                                               │\n",
    "\n",
    "\n",
    "# Let's try CK FA2 https://embeddedllm.com/blog/how-to-build-vllm-on-mi300x-from-source\n",
    "%cd ..\n",
    "!git clone https://github.com/ROCm/flash-attention.git\n",
    "%cd flash-attention\n",
    "!git pull\n",
    "!git submodule update --init\n",
    "# speed up compile\n",
    "!pip install ninja\n",
    "!GPU_ARCHS=\"gfx942\" time python setup.py install\n",
    "%cd ..\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e90c914-76a9-4a41-b848-4021ac12f7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-23 07:54:20,924] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "--------------------------------------------------\n",
      "DeepSpeed C++/CUDA extension op report\n",
      "--------------------------------------------------\n",
      "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
      "      runtime if needed. Op compatibility means that your system\n",
      "      meet the required dependencies to JIT install the op.\n",
      "--------------------------------------------------\n",
      "JIT compiled ops requires ninja\n",
      "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "op name ................ installed .. compatible\n",
      "--------------------------------------------------\n",
      "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_adagrad ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_lion ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "evoformer_attn ......... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
      "\u001b[93m [WARNING] \u001b[0m FP Quantizer is using an untested triton version (3.1.0), only 2.3.(0, 1) and 3.0.0 are known to be compatible with these kernels\n",
      "fp_quantizer ........... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
      "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_lion ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "\u001b[93m [WARNING] \u001b[0m gds is not compatible with ROCM\n",
      "gds .................... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
      "transformer_inference .. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "inference_core_ops ..... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "cutlass_ops ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "quantizer .............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "ragged_device_ops ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "ragged_ops ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "random_ltd ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn is not compatible with ROCM\n",
      "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
      "spatial_inference ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "DeepSpeed general environment info:\n",
      "torch install path ............... ['/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/torch']\n",
      "torch version .................... 2.5.0+rocm6.2\n",
      "deepspeed install path ........... ['/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/deepspeed']\n",
      "deepspeed info ................... 0.15.3+unknown, unknown, unknown\n",
      "torch cuda version ............... None\n",
      "torch hip version ................ 6.2.41133-dd7f95766\n",
      "nvcc version ..................... None\n",
      "deepspeed wheel compiled w. ...... torch 2.5, hip 6.2\n",
      "shared memory (/dev/shm) size .... 1007.67 GB\n"
     ]
    }
   ],
   "source": [
    "!ds_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120f55c7-4be7-4191-9be2-eceb55506e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `8`\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "[2024-10-23 07:58:54,859] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 07:58:54,860] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 07:58:54,889] [INFO] [root.spawn:60] [PID:162822] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpo5ua8dur/test.c -o /tmp/tmpo5ua8dur/test.o\n",
      "[2024-10-23 07:58:54,889] [INFO] [root.spawn:60] [PID:162821] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpp4a1dofb/test.c -o /tmp/tmpp4a1dofb/test.o\n",
      "[2024-10-23 07:58:54,898] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 07:58:54,901] [INFO] [root.spawn:60] [PID:162822] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpo5ua8dur/test.o -laio -o /tmp/tmpo5ua8dur/a.out\n",
      "[2024-10-23 07:58:54,902] [INFO] [root.spawn:60] [PID:162821] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpp4a1dofb/test.o -laio -o /tmp/tmpp4a1dofb/a.out\n",
      "[2024-10-23 07:58:54,918] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 07:58:54,927] [INFO] [root.spawn:60] [PID:162820] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmp5gy6shy4/test.c -o /tmp/tmp5gy6shy4/test.o\n",
      "[2024-10-23 07:58:54,940] [INFO] [root.spawn:60] [PID:162820] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmp5gy6shy4/test.o -laio -o /tmp/tmp5gy6shy4/a.out\n",
      "[2024-10-23 07:58:54,947] [INFO] [root.spawn:60] [PID:162819] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpfrfwvxqj/test.c -o /tmp/tmpfrfwvxqj/test.o\n",
      "[2024-10-23 07:58:54,959] [INFO] [root.spawn:60] [PID:162819] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpfrfwvxqj/test.o -laio -o /tmp/tmpfrfwvxqj/a.out\n",
      "[2024-10-23 07:58:54,980] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 07:58:55,012] [INFO] [root.spawn:60] [PID:162818] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpmxg2gu0t/test.c -o /tmp/tmpmxg2gu0t/test.o\n",
      "[2024-10-23 07:58:55,029] [INFO] [root.spawn:60] [PID:162818] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpmxg2gu0t/test.o -laio -o /tmp/tmpmxg2gu0t/a.out\n",
      "[2024-10-23 07:58:55,102] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 07:58:55,132] [INFO] [root.spawn:60] [PID:162823] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmp7t9w0lz9/test.c -o /tmp/tmp7t9w0lz9/test.o\n",
      "[2024-10-23 07:58:55,145] [INFO] [root.spawn:60] [PID:162823] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmp7t9w0lz9/test.o -laio -o /tmp/tmp7t9w0lz9/a.out\n",
      "[2024-10-23 07:58:55,223] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 07:58:55,255] [INFO] [root.spawn:60] [PID:162816] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpoa7fkg13/test.c -o /tmp/tmpoa7fkg13/test.o\n",
      "[2024-10-23 07:58:55,267] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 07:58:55,268] [INFO] [root.spawn:60] [PID:162816] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpoa7fkg13/test.o -laio -o /tmp/tmpoa7fkg13/a.out\n",
      "[2024-10-23 07:58:55,298] [INFO] [root.spawn:60] [PID:162817] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpeoprr1ty/test.c -o /tmp/tmpeoprr1ty/test.o\n",
      "[2024-10-23 07:58:55,311] [INFO] [root.spawn:60] [PID:162817] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpeoprr1ty/test.o -laio -o /tmp/tmpeoprr1ty/a.out\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "[2024-10-23 07:58:56,166] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:162821] [RANK:5] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 07:58:56,166] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:162819] [RANK:3] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 07:58:56,167] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:162820] [RANK:4] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 07:58:56,167] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:162822] [RANK:6] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 07:58:56,169] [DEBUG] [axolotl.normalize_config:83] [PID:162821] [RANK:5] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 07:58:56,169] [DEBUG] [axolotl.normalize_config:83] [PID:162820] [RANK:4] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 07:58:56,169] [DEBUG] [axolotl.normalize_config:83] [PID:162822] [RANK:6] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 07:58:56,169] [DEBUG] [axolotl.normalize_config:83] [PID:162819] [RANK:3] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "[2024-10-23 07:58:56,231] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:162818] [RANK:2] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 07:58:56,233] [DEBUG] [axolotl.normalize_config:83] [PID:162818] [RANK:2] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "[2024-10-23 07:58:56,261] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:162823] [RANK:7] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 07:58:56,264] [DEBUG] [axolotl.normalize_config:83] [PID:162823] [RANK:7] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 07:58:56,347] [INFO] [axolotl.normalize_config:207] [PID:162821] [RANK:5] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 07:58:56,347] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:162821] [RANK:5] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 07:58:56,350] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 07:58:56,350] [INFO] [axolotl.normalize_config:207] [PID:162820] [RANK:4] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 07:58:56,350] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:162820] [RANK:4] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 07:58:56,350] [INFO] [axolotl.normalize_config:207] [PID:162822] [RANK:6] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 07:58:56,351] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:162822] [RANK:6] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 07:58:56,352] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 07:58:56,353] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 07:58:56,358] [INFO] [axolotl.normalize_config:207] [PID:162819] [RANK:3] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 07:58:56,358] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:162819] [RANK:3] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 07:58:56,359] [INFO] [axolotl.normalize_config:207] [PID:162818] [RANK:2] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 07:58:56,359] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:162818] [RANK:2] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 07:58:56,360] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 07:58:56,361] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 07:58:56,391] [INFO] [axolotl.normalize_config:207] [PID:162823] [RANK:7] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 07:58:56,391] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:162823] [RANK:7] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 07:58:56,393] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 07:58:56,471] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:162816] [RANK:0] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 07:58:56,474] [DEBUG] [axolotl.normalize_config:83] [PID:162816] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 07:58:56,492] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:162817] [RANK:1] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 07:58:56,495] [DEBUG] [axolotl.normalize_config:83] [PID:162817] [RANK:1] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 07:58:56,606] [INFO] [axolotl.normalize_config:207] [PID:162816] [RANK:0] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 07:58:56,606] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:162816] [RANK:0] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 07:58:56,607] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 07:58:56,607] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2024-10-23 07:58:56,625] [INFO] [axolotl.normalize_config:207] [PID:162817] [RANK:1] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 07:58:56,625] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:162817] [RANK:1] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 07:58:56,627] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 07:58:56,993] [DEBUG] [axolotl.load_tokenizer:290] [PID:162821] [RANK:5] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:58:56,994] [DEBUG] [axolotl.load_tokenizer:291] [PID:162821] [RANK:5] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:56,994] [DEBUG] [axolotl.load_tokenizer:292] [PID:162821] [RANK:5] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:56,994] [DEBUG] [axolotl.load_tokenizer:293] [PID:162821] [RANK:5] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:58:56,994] [DEBUG] [axolotl.load_tokenizer:290] [PID:162822] [RANK:6] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:58:56,994] [DEBUG] [axolotl.load_tokenizer:291] [PID:162822] [RANK:6] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:56,994] [DEBUG] [axolotl.load_tokenizer:292] [PID:162822] [RANK:6] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:56,994] [DEBUG] [axolotl.load_tokenizer:293] [PID:162822] [RANK:6] UNK: None / None\u001b[39m\n",
      "[rank5]:[W1023 07:58:56.100392485 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank6]:[W1023 07:58:56.100726075 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 07:58:57,065] [DEBUG] [axolotl.load_tokenizer:290] [PID:162823] [RANK:7] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:58:57,065] [DEBUG] [axolotl.load_tokenizer:291] [PID:162823] [RANK:7] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,065] [DEBUG] [axolotl.load_tokenizer:292] [PID:162823] [RANK:7] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,065] [DEBUG] [axolotl.load_tokenizer:293] [PID:162823] [RANK:7] UNK: None / None\u001b[39m\n",
      "[rank7]:[W1023 07:58:57.171500192 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 07:58:57,077] [DEBUG] [axolotl.load_tokenizer:290] [PID:162820] [RANK:4] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:58:57,077] [DEBUG] [axolotl.load_tokenizer:291] [PID:162820] [RANK:4] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,077] [DEBUG] [axolotl.load_tokenizer:292] [PID:162820] [RANK:4] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,077] [DEBUG] [axolotl.load_tokenizer:293] [PID:162820] [RANK:4] UNK: None / None\u001b[39m\n",
      "[rank4]:[W1023 07:58:57.183975989 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 07:58:57,141] [DEBUG] [axolotl.load_tokenizer:290] [PID:162818] [RANK:2] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:58:57,141] [DEBUG] [axolotl.load_tokenizer:291] [PID:162818] [RANK:2] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,141] [DEBUG] [axolotl.load_tokenizer:292] [PID:162818] [RANK:2] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,141] [DEBUG] [axolotl.load_tokenizer:293] [PID:162818] [RANK:2] UNK: None / None\u001b[39m\n",
      "[rank2]:[W1023 07:58:57.248420881 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 07:58:57,217] [DEBUG] [axolotl.load_tokenizer:290] [PID:162819] [RANK:3] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:58:57,217] [DEBUG] [axolotl.load_tokenizer:291] [PID:162819] [RANK:3] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,217] [DEBUG] [axolotl.load_tokenizer:292] [PID:162819] [RANK:3] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,217] [DEBUG] [axolotl.load_tokenizer:293] [PID:162819] [RANK:3] UNK: None / None\u001b[39m\n",
      "[rank3]:[W1023 07:58:57.324067912 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 07:58:57,384] [DEBUG] [axolotl.load_tokenizer:290] [PID:162817] [RANK:1] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:58:57,384] [DEBUG] [axolotl.load_tokenizer:291] [PID:162817] [RANK:1] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,384] [DEBUG] [axolotl.load_tokenizer:292] [PID:162817] [RANK:1] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,384] [DEBUG] [axolotl.load_tokenizer:293] [PID:162817] [RANK:1] UNK: None / None\u001b[39m\n",
      "[rank1]:[W1023 07:58:57.491187584 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 07:58:57,418] [DEBUG] [axolotl.load_tokenizer:290] [PID:162816] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:58:57,418] [DEBUG] [axolotl.load_tokenizer:291] [PID:162816] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,418] [DEBUG] [axolotl.load_tokenizer:292] [PID:162816] [RANK:0] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:58:57,418] [DEBUG] [axolotl.load_tokenizer:293] [PID:162816] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:58:57,419] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:162816] [RANK:0] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 07:58:57,462] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:162816] [RANK:0] Prepared dataset loaded from disk...\u001b[39m\n",
      "[rank0]:[W1023 07:58:57.590103840 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 07:58:58,880] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:162817] [RANK:1] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 07:58:58,880] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:162818] [RANK:2] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 07:58:58,880] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:162819] [RANK:3] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 07:58:58,881] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:162822] [RANK:6] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 07:58:58,881] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:162821] [RANK:5] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 07:58:58,882] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:162820] [RANK:4] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 07:58:58,882] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:162823] [RANK:7] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 07:58:58,887] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:162817] [RANK:1] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 07:58:58,888] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:162818] [RANK:2] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 07:58:58,889] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:162819] [RANK:3] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 07:58:58,896] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:162821] [RANK:5] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 07:58:58,896] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:162822] [RANK:6] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 07:58:58,899] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:162820] [RANK:4] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 07:58:58,899] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:162823] [RANK:7] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 07:58:58,940] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:162816] [RANK:0] total_num_tokens: 15_537_156\u001b[39m\n",
      "[2024-10-23 07:58:59,188] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:162816] [RANK:0] `total_supervised_tokens: 7_583_970`\u001b[39m\n",
      "[2024-10-23 07:59:03,029] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "[2024-10-23 07:59:03,029] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:162816] [RANK:0] data_loader_len: 30\u001b[39m\n",
      "[2024-10-23 07:59:03,041] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:162816] [RANK:0] sample_packing_eff_est across ranks: [0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572]\u001b[39m\n",
      "[2024-10-23 07:59:03,042] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:162816] [RANK:0] sample_packing_eff_est: None\u001b[39m\n",
      "[2024-10-23 07:59:03,042] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:162816] [RANK:0] total_num_steps: 90\u001b[39m\n",
      "[2024-10-23 07:59:03,468] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:162816] [RANK:0] total_num_tokens: 79_721_158\u001b[39m\n",
      "[2024-10-23 07:59:05,134] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:162816] [RANK:0] `total_supervised_tokens: 39_365_516`\u001b[39m\n",
      "[2024-10-23 07:59:05,251] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [1225, 1226, 1226, 1226, 1226, 1226, 1226, 1226]\u001b[39m\n",
      "[2024-10-23 07:59:05,252] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:162816] [RANK:0] data_loader_len: 152\u001b[39m\n",
      "[2024-10-23 07:59:05,253] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:162816] [RANK:0] sample_packing_eff_est across ranks: [0.9930190443992615, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087]\u001b[39m\n",
      "[2024-10-23 07:59:05,253] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:162816] [RANK:0] sample_packing_eff_est: 1.0\u001b[39m\n",
      "[2024-10-23 07:59:05,253] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:162816] [RANK:0] total_num_steps: 456\u001b[39m\n",
      "[2024-10-23 07:59:05,285] [DEBUG] [axolotl.train.train:66] [PID:162816] [RANK:0] loading tokenizer... meta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39m\n",
      "[2024-10-23 07:59:05,857] [DEBUG] [axolotl.load_tokenizer:290] [PID:162818] [RANK:2] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:59:05,857] [DEBUG] [axolotl.load_tokenizer:291] [PID:162818] [RANK:2] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,857] [DEBUG] [axolotl.load_tokenizer:292] [PID:162818] [RANK:2] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,857] [DEBUG] [axolotl.load_tokenizer:293] [PID:162818] [RANK:2] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:59:05,858] [DEBUG] [axolotl.load_tokenizer:290] [PID:162823] [RANK:7] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:59:05,858] [DEBUG] [axolotl.load_tokenizer:291] [PID:162823] [RANK:7] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,858] [DEBUG] [axolotl.load_tokenizer:292] [PID:162823] [RANK:7] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,858] [DEBUG] [axolotl.load_tokenizer:293] [PID:162823] [RANK:7] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:59:05,896] [DEBUG] [axolotl.load_tokenizer:290] [PID:162817] [RANK:1] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:59:05,896] [DEBUG] [axolotl.load_tokenizer:291] [PID:162817] [RANK:1] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,896] [DEBUG] [axolotl.load_tokenizer:292] [PID:162817] [RANK:1] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,896] [DEBUG] [axolotl.load_tokenizer:293] [PID:162817] [RANK:1] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:59:05,896] [DEBUG] [axolotl.load_tokenizer:290] [PID:162820] [RANK:4] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:59:05,897] [DEBUG] [axolotl.load_tokenizer:291] [PID:162820] [RANK:4] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,897] [DEBUG] [axolotl.load_tokenizer:292] [PID:162820] [RANK:4] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,897] [DEBUG] [axolotl.load_tokenizer:293] [PID:162820] [RANK:4] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:59:05,905] [DEBUG] [axolotl.load_tokenizer:290] [PID:162816] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:59:05,906] [DEBUG] [axolotl.load_tokenizer:291] [PID:162816] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,906] [DEBUG] [axolotl.load_tokenizer:292] [PID:162816] [RANK:0] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,906] [DEBUG] [axolotl.load_tokenizer:293] [PID:162816] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:59:05,906] [DEBUG] [axolotl.train.train:98] [PID:162816] [RANK:0] loading model\u001b[39m\n",
      "[2024-10-23 07:59:05,942] [DEBUG] [axolotl.load_tokenizer:290] [PID:162822] [RANK:6] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:59:05,942] [DEBUG] [axolotl.load_tokenizer:291] [PID:162822] [RANK:6] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,942] [DEBUG] [axolotl.load_tokenizer:292] [PID:162822] [RANK:6] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,942] [DEBUG] [axolotl.load_tokenizer:293] [PID:162822] [RANK:6] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:59:05,949] [DEBUG] [axolotl.load_tokenizer:290] [PID:162819] [RANK:3] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:59:05,950] [DEBUG] [axolotl.load_tokenizer:291] [PID:162819] [RANK:3] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,950] [DEBUG] [axolotl.load_tokenizer:292] [PID:162819] [RANK:3] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:05,950] [DEBUG] [axolotl.load_tokenizer:293] [PID:162819] [RANK:3] UNK: None / None\u001b[39m\n",
      "[2024-10-23 07:59:06,051] [DEBUG] [axolotl.load_tokenizer:290] [PID:162821] [RANK:5] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 07:59:06,051] [DEBUG] [axolotl.load_tokenizer:291] [PID:162821] [RANK:5] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:06,051] [DEBUG] [axolotl.load_tokenizer:292] [PID:162821] [RANK:5] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 07:59:06,051] [DEBUG] [axolotl.load_tokenizer:293] [PID:162821] [RANK:5] UNK: None / None\u001b[39m\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:14<00:00,  3.71s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:14<00:00,  3.71s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:14<00:00,  3.71s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:14<00:00,  3.72s/it]\n",
      "[2024-10-23 07:59:21,465] [INFO] [axolotl.load_model:855] [PID:162816] [RANK:0] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 07:59:21,466] [INFO] [axolotl.load_model:855] [PID:162818] [RANK:2] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 07:59:21,471] [INFO] [axolotl.load_model:922] [PID:162816] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 07:59:21,471] [INFO] [axolotl.load_model:922] [PID:162818] [RANK:2] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 07:59:21,491] [INFO] [axolotl.load_model:855] [PID:162819] [RANK:3] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:15<00:00,  3.75s/it]\n",
      "[2024-10-23 07:59:21,497] [INFO] [axolotl.load_model:922] [PID:162819] [RANK:3] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 07:59:21,545] [INFO] [axolotl.load_model:855] [PID:162817] [RANK:1] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 07:59:21,551] [INFO] [axolotl.load_model:922] [PID:162817] [RANK:1] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 07:59:21,652] [INFO] [axolotl.load_model:855] [PID:162823] [RANK:7] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 07:59:21,657] [INFO] [axolotl.load_model:922] [PID:162823] [RANK:7] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:15<00:00,  3.85s/it]\n",
      "[2024-10-23 07:59:22,063] [INFO] [axolotl.load_model:855] [PID:162820] [RANK:4] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 07:59:22,069] [INFO] [axolotl.load_model:922] [PID:162820] [RANK:4] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:15<00:00,  3.90s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:15<00:00,  3.90s/it]\n",
      "[2024-10-23 07:59:22,232] [INFO] [axolotl.load_model:855] [PID:162822] [RANK:6] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 07:59:22,236] [INFO] [axolotl.load_model:922] [PID:162822] [RANK:6] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-10-23 07:59:22,327] [INFO] [axolotl.load_model:855] [PID:162821] [RANK:5] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 07:59:22,331] [INFO] [axolotl.load_model:922] [PID:162821] [RANK:5] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-10-23 07:59:22,433] [INFO] [axolotl.train.train:178] [PID:162816] [RANK:0] Starting trainer...\u001b[39m\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-10-23 07:59:23,651] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [1226, 1226, 1226, 1226, 1226, 1226, 1226, 1226]\u001b[39m\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n",
      "Using /home/hotaisle/.cache/torch_extensions/py312_cpu as PyTorch extensions root...\n",
      "Using /home/hotaisle/.cache/torch_extensions/py312_cpu as PyTorch extensions root...\n",
      "Emitting ninja build file /home/hotaisle/.cache/torch_extensions/py312_cpu/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Using /home/hotaisle/.cache/torch_extensions/py312_cpu as PyTorch extensions root...\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 3.213108539581299 seconds\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n",
      "Loading extension module cpu_adam...\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n",
      "\n",
      "Time to load cpu_adam op: 3.2814860343933105 seconds\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 3.3146250247955322 seconds\n",
      "Using /home/hotaisle/.cache/torch_extensions/py312_cpu as PyTorch extensions root...\n",
      "Emitting ninja build file /home/hotaisle/.cache/torch_extensions/py312_cpu/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 3.6121275424957275 seconds\n",
      "Using /home/hotaisle/.cache/torch_extensions/py312_cpu as PyTorch extensions root...\n",
      "Using /home/hotaisle/.cache/torch_extensions/py312_cpu as PyTorch extensions root...\n",
      "Emitting ninja build file /home/hotaisle/.cache/torch_extensions/py312_cpu/cpu_adam/build.ninja...\n",
      "Using /home/hotaisle/.cache/torch_extensions/py312_cpu as PyTorch extensions root...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Using /home/hotaisle/.cache/torch_extensions/py312_cpu as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 3.6909077167510986 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 3.751925468444824 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 3.761197090148926 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 3.766967535018921 seconds\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrandomfoo\u001b[0m (\u001b[33maugmxnt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/nvme1n1p1/MI300-testing/wandb/run-20241023_075955-8jqlicg3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmi300x-shisa-llama3.1-8b-v1-dsz2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/augmxnt/shisa-v2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/augmxnt/shisa-v2/runs/8jqlicg3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "[2024-10-23 07:59:56,731] [INFO] [axolotl.callbacks.on_train_begin:794] [PID:162816] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
      "  0%|                                                   | 0/456 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.1231, 'grad_norm': 3.810030937194824, 'learning_rate': 8e-08, 'epoch': 0.01}\n",
      "  0%|                                         | 1/456 [00:31<3:56:07, 31.14s/it][2024-10-23 08:00:27,881] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:43,  1.55s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:06<00:57,  2.13s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:09<01:03,  2.44s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:11<01:05,  2.60s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:06,  2.77s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:05,  2.85s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:03,  2.89s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:02,  2.96s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:28<01:06,  3.31s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:31<01:00,  3.20s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:34<00:55,  3.11s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:37<00:51,  3.06s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:39<00:48,  3.03s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:42<00:45,  3.01s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:45<00:41,  2.99s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:48<00:38,  3.00s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:52<00:39,  3.31s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:55<00:35,  3.22s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:59<00:31,  3.19s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:02<00:28,  3.13s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:05<00:25,  3.14s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:08<00:21,  3.11s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:11<00:18,  3.10s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:14<00:15,  3.04s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:17<00:12,  3.02s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:20<00:09,  3.02s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:24<00:06,  3.32s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:27<00:03,  3.23s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6680425405502319, 'eval_runtime': 93.2193, 'eval_samples_per_second': 100.805, 'eval_steps_per_second': 1.577, 'epoch': 0.01}\n",
      "  0%|                                         | 1/456 [02:04<3:56:07, 31.14s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:30<00:00,  3.15s/it]\u001b[A\n",
      "                                                                                \u001b[A[2024-10-23 08:02:16,948] [INFO] [axolotl.callbacks.on_step_end:128] [PID:162818] [RANK:2] GPU memory usage while training: 15.938GB (+138.339GB cache)\u001b[39m\n",
      "[2024-10-23 08:02:16,948] [INFO] [axolotl.callbacks.on_step_end:128] [PID:162822] [RANK:6] GPU memory usage while training: 15.938GB (+138.632GB cache)\u001b[39m\n",
      "[2024-10-23 08:02:16,948] [INFO] [axolotl.callbacks.on_step_end:128] [PID:162816] [RANK:0] GPU memory usage while training: 15.938GB (+144.210GB cache)\u001b[39m\n",
      "[2024-10-23 08:02:16,948] [INFO] [axolotl.callbacks.on_step_end:128] [PID:162817] [RANK:1] GPU memory usage while training: 15.938GB (+138.339GB cache)\u001b[39m\n",
      "[2024-10-23 08:02:16,948] [INFO] [axolotl.callbacks.on_step_end:128] [PID:162819] [RANK:3] GPU memory usage while training: 15.938GB (+138.339GB cache)\u001b[39m\n",
      "[2024-10-23 08:02:16,948] [INFO] [axolotl.callbacks.on_step_end:128] [PID:162820] [RANK:4] GPU memory usage while training: 15.938GB (+138.191GB cache)\u001b[39m\n",
      "[2024-10-23 08:02:16,948] [INFO] [axolotl.callbacks.on_step_end:128] [PID:162823] [RANK:7] GPU memory usage while training: 15.938GB (+142.363GB cache)\u001b[39m\n",
      "[2024-10-23 08:02:16,949] [INFO] [axolotl.callbacks.on_step_end:128] [PID:162821] [RANK:5] GPU memory usage while training: 15.938GB (+139.124GB cache)\u001b[39m\n",
      "{'loss': 1.1024, 'grad_norm': 3.8256967067718506, 'learning_rate': 1.6e-07, 'epoch': 0.01}\n",
      "{'loss': 1.0876, 'grad_norm': 3.781700611114502, 'learning_rate': 2.4e-07, 'epoch': 0.02}\n",
      "{'loss': 1.0526, 'grad_norm': 3.732663631439209, 'learning_rate': 3.2e-07, 'epoch': 0.03}\n",
      "{'loss': 1.0441, 'grad_norm': 3.6765546798706055, 'learning_rate': 4e-07, 'epoch': 0.03}\n",
      "{'loss': 1.056, 'grad_norm': 3.955108404159546, 'learning_rate': 4.8e-07, 'epoch': 0.04}\n",
      "{'loss': 1.0923, 'grad_norm': 3.716158628463745, 'learning_rate': 5.6e-07, 'epoch': 0.05}\n",
      "{'loss': 1.1012, 'grad_norm': 3.4639015197753906, 'learning_rate': 6.4e-07, 'epoch': 0.05}\n",
      "{'loss': 1.052, 'grad_norm': 3.161484479904175, 'learning_rate': 7.2e-07, 'epoch': 0.06}\n",
      "{'loss': 1.0862, 'grad_norm': 2.9174039363861084, 'learning_rate': 8e-07, 'epoch': 0.07}\n",
      "{'loss': 1.0807, 'grad_norm': 2.918055772781372, 'learning_rate': 8.799999999999999e-07, 'epoch': 0.07}\n",
      "{'loss': 1.0922, 'grad_norm': 1.8407869338989258, 'learning_rate': 9.6e-07, 'epoch': 0.08}\n",
      "{'loss': 1.0194, 'grad_norm': 1.8418670892715454, 'learning_rate': 1.04e-06, 'epoch': 0.09}\n",
      "{'loss': 1.0894, 'grad_norm': 1.7837848663330078, 'learning_rate': 1.12e-06, 'epoch': 0.09}\n",
      "{'loss': 1.058, 'grad_norm': 1.7200111150741577, 'learning_rate': 1.2e-06, 'epoch': 0.1}\n",
      "{'loss': 1.0723, 'grad_norm': 1.8001892566680908, 'learning_rate': 1.28e-06, 'epoch': 0.11}\n",
      "{'loss': 1.0018, 'grad_norm': 1.820277214050293, 'learning_rate': 1.3600000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 0.9846, 'grad_norm': 1.9088977575302124, 'learning_rate': 1.44e-06, 'epoch': 0.12}\n",
      "{'loss': 1.031, 'grad_norm': 1.645642638206482, 'learning_rate': 1.5199999999999998e-06, 'epoch': 0.12}\n",
      "{'loss': 1.0147, 'grad_norm': 1.3993452787399292, 'learning_rate': 1.6e-06, 'epoch': 0.13}\n",
      "{'loss': 1.0373, 'grad_norm': 1.090445637702942, 'learning_rate': 1.6799999999999998e-06, 'epoch': 0.14}\n",
      "{'loss': 0.9861, 'grad_norm': 1.035253882408142, 'learning_rate': 1.7599999999999999e-06, 'epoch': 0.14}\n",
      "{'loss': 1.0356, 'grad_norm': 1.4798890352249146, 'learning_rate': 1.84e-06, 'epoch': 0.15}\n",
      "{'loss': 1.1059, 'grad_norm': 1.5870823860168457, 'learning_rate': 1.92e-06, 'epoch': 0.16}\n",
      "{'loss': 1.0055, 'grad_norm': 1.2027863264083862, 'learning_rate': 2e-06, 'epoch': 0.16}\n",
      "{'loss': 0.9956, 'grad_norm': 0.9778658151626587, 'learning_rate': 2.08e-06, 'epoch': 0.17}\n",
      "{'loss': 0.993, 'grad_norm': 0.9367652535438538, 'learning_rate': 2.16e-06, 'epoch': 0.18}\n",
      "{'loss': 1.019, 'grad_norm': 0.9872676730155945, 'learning_rate': 2.24e-06, 'epoch': 0.18}\n",
      "{'loss': 0.952, 'grad_norm': 0.959820568561554, 'learning_rate': 2.32e-06, 'epoch': 0.19}\n",
      "{'loss': 0.9543, 'grad_norm': 1.117384433746338, 'learning_rate': 2.4e-06, 'epoch': 0.2}\n",
      "{'loss': 1.0244, 'grad_norm': 0.9002896547317505, 'learning_rate': 2.48e-06, 'epoch': 0.2}\n",
      "{'loss': 0.9949, 'grad_norm': 0.8733643293380737, 'learning_rate': 2.56e-06, 'epoch': 0.21}\n",
      "{'loss': 0.9887, 'grad_norm': 0.8464259505271912, 'learning_rate': 2.64e-06, 'epoch': 0.22}\n",
      "{'loss': 0.9684, 'grad_norm': 0.9330945611000061, 'learning_rate': 2.7200000000000002e-06, 'epoch': 0.22}\n",
      "{'loss': 0.9459, 'grad_norm': 0.9527033567428589, 'learning_rate': 2.8e-06, 'epoch': 0.23}\n",
      "{'loss': 0.9552, 'grad_norm': 0.8421740531921387, 'learning_rate': 2.88e-06, 'epoch': 0.24}\n",
      "{'loss': 0.9917, 'grad_norm': 0.8383418917655945, 'learning_rate': 2.96e-06, 'epoch': 0.24}\n",
      "{'loss': 0.9133, 'grad_norm': 0.8773941397666931, 'learning_rate': 3.0399999999999997e-06, 'epoch': 0.25}\n",
      "{'loss': 0.9011, 'grad_norm': 0.9128979444503784, 'learning_rate': 3.1199999999999998e-06, 'epoch': 0.26}\n",
      "{'loss': 0.9808, 'grad_norm': 0.8393082022666931, 'learning_rate': 3.2e-06, 'epoch': 0.26}\n",
      "{'loss': 0.9505, 'grad_norm': 0.7549347281455994, 'learning_rate': 3.2799999999999995e-06, 'epoch': 0.27}\n",
      "{'loss': 0.9398, 'grad_norm': 0.8433191776275635, 'learning_rate': 3.3599999999999996e-06, 'epoch': 0.28}\n",
      "{'loss': 0.9626, 'grad_norm': 0.8213455080986023, 'learning_rate': 3.4399999999999997e-06, 'epoch': 0.28}\n",
      "{'loss': 0.963, 'grad_norm': 0.7540872097015381, 'learning_rate': 3.5199999999999998e-06, 'epoch': 0.29}\n",
      "{'loss': 0.9991, 'grad_norm': 0.7856152057647705, 'learning_rate': 3.6e-06, 'epoch': 0.3}\n",
      "{'loss': 0.9262, 'grad_norm': 0.7865797877311707, 'learning_rate': 3.68e-06, 'epoch': 0.3}\n",
      "{'loss': 0.9423, 'grad_norm': 0.7676785588264465, 'learning_rate': 3.7599999999999996e-06, 'epoch': 0.31}\n",
      "{'loss': 0.9607, 'grad_norm': 0.7877618670463562, 'learning_rate': 3.84e-06, 'epoch': 0.32}\n",
      "{'loss': 0.9721, 'grad_norm': 0.7950922250747681, 'learning_rate': 3.92e-06, 'epoch': 0.32}\n",
      "{'loss': 0.936, 'grad_norm': 0.8668529987335205, 'learning_rate': 4e-06, 'epoch': 0.33}\n",
      "{'loss': 0.9546, 'grad_norm': 0.8412799835205078, 'learning_rate': 4.08e-06, 'epoch': 0.34}\n",
      "{'loss': 0.9308, 'grad_norm': 0.8452146053314209, 'learning_rate': 4.16e-06, 'epoch': 0.34}\n",
      "{'loss': 0.9311, 'grad_norm': 0.7863358855247498, 'learning_rate': 4.24e-06, 'epoch': 0.35}\n",
      "{'loss': 0.8688, 'grad_norm': 0.7595062851905823, 'learning_rate': 4.32e-06, 'epoch': 0.36}\n",
      "{'loss': 0.9472, 'grad_norm': 0.7383087277412415, 'learning_rate': 4.4e-06, 'epoch': 0.36}\n",
      "{'loss': 0.9139, 'grad_norm': 0.7316797375679016, 'learning_rate': 4.48e-06, 'epoch': 0.37}\n",
      "{'loss': 0.889, 'grad_norm': 0.7642449140548706, 'learning_rate': 4.5599999999999995e-06, 'epoch': 0.38}\n",
      "{'loss': 0.9684, 'grad_norm': 0.7423649430274963, 'learning_rate': 4.64e-06, 'epoch': 0.38}\n",
      "{'loss': 0.9366, 'grad_norm': 0.7491574883460999, 'learning_rate': 4.72e-06, 'epoch': 0.39}\n",
      "{'loss': 0.8288, 'grad_norm': 0.7115549445152283, 'learning_rate': 4.8e-06, 'epoch': 0.39}\n",
      "{'loss': 0.9609, 'grad_norm': 0.7544856071472168, 'learning_rate': 4.88e-06, 'epoch': 0.4}\n",
      "{'loss': 0.953, 'grad_norm': 0.7712090015411377, 'learning_rate': 4.96e-06, 'epoch': 0.41}\n",
      "{'loss': 0.9121, 'grad_norm': 0.7611212134361267, 'learning_rate': 5.04e-06, 'epoch': 0.41}\n",
      "{'loss': 0.859, 'grad_norm': 0.7384157180786133, 'learning_rate': 5.12e-06, 'epoch': 0.42}\n",
      "{'loss': 0.927, 'grad_norm': 0.7569328546524048, 'learning_rate': 5.2e-06, 'epoch': 0.43}\n",
      "{'loss': 0.8881, 'grad_norm': 0.7221905589103699, 'learning_rate': 5.28e-06, 'epoch': 0.43}\n",
      "{'loss': 0.8802, 'grad_norm': 0.7297026515007019, 'learning_rate': 5.36e-06, 'epoch': 0.44}\n",
      "{'loss': 0.9385, 'grad_norm': 0.7597461342811584, 'learning_rate': 5.4400000000000004e-06, 'epoch': 0.45}\n",
      "{'loss': 0.9127, 'grad_norm': 0.745927095413208, 'learning_rate': 5.52e-06, 'epoch': 0.45}\n",
      "{'loss': 0.8884, 'grad_norm': 0.7635666131973267, 'learning_rate': 5.6e-06, 'epoch': 0.46}\n",
      "{'loss': 0.9771, 'grad_norm': 0.7705156803131104, 'learning_rate': 5.68e-06, 'epoch': 0.47}\n",
      "{'loss': 0.9194, 'grad_norm': 0.7431849241256714, 'learning_rate': 5.76e-06, 'epoch': 0.47}\n",
      "{'loss': 0.8884, 'grad_norm': 0.7669069766998291, 'learning_rate': 5.84e-06, 'epoch': 0.48}\n",
      "{'loss': 0.8779, 'grad_norm': 0.729629397392273, 'learning_rate': 5.92e-06, 'epoch': 0.49}\n",
      "{'loss': 0.8309, 'grad_norm': 0.7204685211181641, 'learning_rate': 6e-06, 'epoch': 0.49}\n",
      "{'loss': 0.9516, 'grad_norm': 0.7914924025535583, 'learning_rate': 6.079999999999999e-06, 'epoch': 0.5}\n",
      " 17%|██████▋                                 | 76/456 [19:13<1:27:16, 13.78s/it][2024-10-23 08:19:10,617] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:02<00:41,  1.50s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:56,  2.11s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:08<01:02,  2.42s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:11<01:05,  2.62s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:14<01:06,  2.77s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:05,  2.86s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:22<01:11,  3.23s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:05,  3.13s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:27<01:01,  3.08s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:30<00:57,  3.03s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:33<00:53,  3.00s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:36<00:50,  2.99s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:39<00:47,  2.97s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:43<00:49,  3.27s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:46<00:44,  3.18s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:49<00:40,  3.12s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:52<00:36,  3.08s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:55<00:33,  3.06s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:58<00:30,  3.04s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:01<00:27,  3.01s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:04<00:24,  3.02s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:07<00:21,  3.00s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:10<00:17,  2.97s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:13<00:14,  3.00s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:16<00:12,  3.04s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:19<00:09,  3.04s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:22<00:06,  3.05s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:25<00:03,  3.09s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.5476101636886597, 'eval_runtime': 92.157, 'eval_samples_per_second': 101.967, 'eval_steps_per_second': 1.595, 'epoch': 0.5}\n",
      " 17%|██████▋                                 | 76/456 [20:46<1:27:16, 13.78s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:29<00:00,  3.06s/it]\u001b[A\n",
      "{'loss': 0.8507, 'grad_norm': 0.7545872926712036, 'learning_rate': 6.1599999999999995e-06, 'epoch': 0.51}\n",
      "{'loss': 0.9303, 'grad_norm': 0.8049891591072083, 'learning_rate': 6.2399999999999995e-06, 'epoch': 0.51}\n",
      "{'loss': 0.9248, 'grad_norm': 0.7563024759292603, 'learning_rate': 6.32e-06, 'epoch': 0.52}\n",
      "{'loss': 0.8219, 'grad_norm': 0.7156861424446106, 'learning_rate': 6.4e-06, 'epoch': 0.53}\n",
      "{'loss': 0.8984, 'grad_norm': 0.7379570007324219, 'learning_rate': 6.48e-06, 'epoch': 0.53}\n",
      "{'loss': 0.8892, 'grad_norm': 0.7088736295700073, 'learning_rate': 6.559999999999999e-06, 'epoch': 0.54}\n",
      "{'loss': 0.8557, 'grad_norm': 0.757376492023468, 'learning_rate': 6.639999999999999e-06, 'epoch': 0.55}\n",
      "{'loss': 0.8544, 'grad_norm': 0.6940219402313232, 'learning_rate': 6.719999999999999e-06, 'epoch': 0.55}\n",
      "{'loss': 0.9467, 'grad_norm': 0.8157735466957092, 'learning_rate': 6.799999999999999e-06, 'epoch': 0.56}\n",
      "{'loss': 0.846, 'grad_norm': 0.6906396150588989, 'learning_rate': 6.879999999999999e-06, 'epoch': 0.57}\n",
      "{'loss': 0.8805, 'grad_norm': 0.7677121162414551, 'learning_rate': 6.9599999999999994e-06, 'epoch': 0.57}\n",
      "{'loss': 0.8685, 'grad_norm': 0.752264678478241, 'learning_rate': 7.0399999999999995e-06, 'epoch': 0.58}\n",
      "{'loss': 0.8991, 'grad_norm': 1.3485857248306274, 'learning_rate': 7.12e-06, 'epoch': 0.59}\n",
      "{'loss': 0.8844, 'grad_norm': 0.7477499842643738, 'learning_rate': 7.2e-06, 'epoch': 0.59}\n",
      "{'loss': 0.8769, 'grad_norm': 0.79133141040802, 'learning_rate': 7.28e-06, 'epoch': 0.6}\n",
      "{'loss': 0.8531, 'grad_norm': 0.7101074457168579, 'learning_rate': 7.36e-06, 'epoch': 0.61}\n",
      "{'loss': 0.8531, 'grad_norm': 0.7226754426956177, 'learning_rate': 7.44e-06, 'epoch': 0.61}\n",
      "{'loss': 0.893, 'grad_norm': 0.774674654006958, 'learning_rate': 7.519999999999999e-06, 'epoch': 0.62}\n",
      "{'loss': 0.858, 'grad_norm': 0.7729532122612, 'learning_rate': 7.599999999999999e-06, 'epoch': 0.62}\n",
      "{'loss': 0.8711, 'grad_norm': 0.733489990234375, 'learning_rate': 7.68e-06, 'epoch': 0.63}\n",
      "{'loss': 0.9052, 'grad_norm': 0.7475902438163757, 'learning_rate': 7.76e-06, 'epoch': 0.64}\n",
      "{'loss': 0.8562, 'grad_norm': 0.7753591537475586, 'learning_rate': 7.84e-06, 'epoch': 0.64}\n",
      "{'loss': 0.8449, 'grad_norm': 0.7200084328651428, 'learning_rate': 7.92e-06, 'epoch': 0.65}\n",
      "{'loss': 0.8817, 'grad_norm': 0.7531960606575012, 'learning_rate': 8e-06, 'epoch': 0.66}\n",
      "{'loss': 0.8397, 'grad_norm': 0.7526192665100098, 'learning_rate': 7.97752808988764e-06, 'epoch': 0.66}\n",
      "{'loss': 0.8841, 'grad_norm': 0.7956262230873108, 'learning_rate': 7.95505617977528e-06, 'epoch': 0.67}\n",
      "{'loss': 0.8425, 'grad_norm': 0.7359262704849243, 'learning_rate': 7.93258426966292e-06, 'epoch': 0.68}\n",
      "{'loss': 0.9009, 'grad_norm': 0.8035740852355957, 'learning_rate': 7.910112359550562e-06, 'epoch': 0.68}\n",
      "{'loss': 0.8893, 'grad_norm': 0.769780158996582, 'learning_rate': 7.887640449438203e-06, 'epoch': 0.69}\n",
      "{'loss': 0.9019, 'grad_norm': 0.7420027852058411, 'learning_rate': 7.865168539325842e-06, 'epoch': 0.7}\n",
      "{'loss': 0.8816, 'grad_norm': 0.7733613848686218, 'learning_rate': 7.842696629213483e-06, 'epoch': 0.7}\n",
      "{'loss': 0.8469, 'grad_norm': 0.7275540232658386, 'learning_rate': 7.820224719101124e-06, 'epoch': 0.71}\n",
      "{'loss': 0.8715, 'grad_norm': 0.8217709064483643, 'learning_rate': 7.797752808988764e-06, 'epoch': 0.72}\n",
      "{'loss': 0.8475, 'grad_norm': 0.7384238839149475, 'learning_rate': 7.775280898876404e-06, 'epoch': 0.72}\n",
      "{'loss': 0.8865, 'grad_norm': 0.7946521639823914, 'learning_rate': 7.752808988764045e-06, 'epoch': 0.73}\n",
      "{'loss': 0.8424, 'grad_norm': 0.7093716263771057, 'learning_rate': 7.730337078651686e-06, 'epoch': 0.74}\n",
      "{'loss': 0.9066, 'grad_norm': 0.8557013869285583, 'learning_rate': 7.707865168539325e-06, 'epoch': 0.74}\n",
      "{'loss': 0.8701, 'grad_norm': 1.0007892847061157, 'learning_rate': 7.685393258426966e-06, 'epoch': 0.75}\n",
      "{'loss': 0.838, 'grad_norm': 0.7582030892372131, 'learning_rate': 7.662921348314607e-06, 'epoch': 0.76}\n",
      "{'loss': 0.8047, 'grad_norm': 0.76253741979599, 'learning_rate': 7.640449438202247e-06, 'epoch': 0.76}\n",
      "{'loss': 0.8823, 'grad_norm': 0.7306453585624695, 'learning_rate': 7.6179775280898875e-06, 'epoch': 0.77}\n",
      "{'loss': 0.8106, 'grad_norm': 0.7743456959724426, 'learning_rate': 7.595505617977528e-06, 'epoch': 0.78}\n",
      "{'loss': 0.8215, 'grad_norm': 0.7384151220321655, 'learning_rate': 7.5730337078651685e-06, 'epoch': 0.78}\n",
      "{'loss': 0.8593, 'grad_norm': 0.8296847939491272, 'learning_rate': 7.5505617977528086e-06, 'epoch': 0.79}\n",
      "{'loss': 0.8951, 'grad_norm': 0.760043740272522, 'learning_rate': 7.5280898876404495e-06, 'epoch': 0.8}\n",
      "{'loss': 0.8533, 'grad_norm': 0.7685165405273438, 'learning_rate': 7.5056179775280895e-06, 'epoch': 0.8}\n",
      "{'loss': 0.8278, 'grad_norm': 0.7866382002830505, 'learning_rate': 7.4831460674157305e-06, 'epoch': 0.81}\n",
      "{'loss': 0.9, 'grad_norm': 0.7775503396987915, 'learning_rate': 7.46067415730337e-06, 'epoch': 0.82}\n",
      "{'loss': 0.7931, 'grad_norm': 0.7363083958625793, 'learning_rate': 7.438202247191011e-06, 'epoch': 0.82}\n",
      "{'loss': 0.8819, 'grad_norm': 0.7932918667793274, 'learning_rate': 7.4157303370786515e-06, 'epoch': 0.83}\n",
      "{'loss': 0.8674, 'grad_norm': 0.7700286507606506, 'learning_rate': 7.3932584269662916e-06, 'epoch': 0.84}\n",
      "{'loss': 0.8313, 'grad_norm': 0.7235932946205139, 'learning_rate': 7.3707865168539325e-06, 'epoch': 0.84}\n",
      "{'loss': 0.8363, 'grad_norm': 0.7447603344917297, 'learning_rate': 7.3483146067415725e-06, 'epoch': 0.85}\n",
      "{'loss': 0.8762, 'grad_norm': 0.7466776967048645, 'learning_rate': 7.3258426966292134e-06, 'epoch': 0.86}\n",
      "{'loss': 0.8289, 'grad_norm': 0.6961992979049683, 'learning_rate': 7.3033707865168535e-06, 'epoch': 0.86}\n",
      "{'loss': 0.8233, 'grad_norm': 0.7198917865753174, 'learning_rate': 7.2808988764044944e-06, 'epoch': 0.87}\n",
      "{'loss': 0.9102, 'grad_norm': 0.7382868528366089, 'learning_rate': 7.2584269662921345e-06, 'epoch': 0.88}\n",
      "{'loss': 0.8524, 'grad_norm': 0.7352252006530762, 'learning_rate': 7.2359550561797746e-06, 'epoch': 0.88}\n",
      "{'loss': 0.8487, 'grad_norm': 0.7471747994422913, 'learning_rate': 7.2134831460674155e-06, 'epoch': 0.89}\n",
      "{'loss': 0.8588, 'grad_norm': 0.7518839836120605, 'learning_rate': 7.1910112359550555e-06, 'epoch': 0.89}\n",
      "{'loss': 0.877, 'grad_norm': 0.7949994802474976, 'learning_rate': 7.1685393258426964e-06, 'epoch': 0.9}\n",
      "{'loss': 0.8569, 'grad_norm': 0.7433763742446899, 'learning_rate': 7.1460674157303365e-06, 'epoch': 0.91}\n",
      "{'loss': 0.8687, 'grad_norm': 0.8083860874176025, 'learning_rate': 7.123595505617977e-06, 'epoch': 0.91}\n",
      "{'loss': 0.8472, 'grad_norm': 0.739102303981781, 'learning_rate': 7.1011235955056175e-06, 'epoch': 0.92}\n",
      "{'loss': 0.819, 'grad_norm': 0.7438095211982727, 'learning_rate': 7.078651685393258e-06, 'epoch': 0.93}\n",
      "{'loss': 0.8137, 'grad_norm': 0.7007432579994202, 'learning_rate': 7.056179775280899e-06, 'epoch': 0.93}\n",
      "{'loss': 0.8386, 'grad_norm': 0.7651185989379883, 'learning_rate': 7.0337078651685385e-06, 'epoch': 0.94}\n",
      "{'loss': 0.8225, 'grad_norm': 0.7162162065505981, 'learning_rate': 7.0112359550561794e-06, 'epoch': 0.95}\n",
      "{'loss': 0.8267, 'grad_norm': 0.7469370365142822, 'learning_rate': 6.9887640449438195e-06, 'epoch': 0.95}\n",
      "{'loss': 0.8677, 'grad_norm': 0.7470940351486206, 'learning_rate': 6.96629213483146e-06, 'epoch': 0.96}\n",
      "{'loss': 0.8668, 'grad_norm': 0.7541012167930603, 'learning_rate': 6.9438202247191005e-06, 'epoch': 0.97}\n",
      "{'loss': 0.7941, 'grad_norm': 0.7228174209594727, 'learning_rate': 6.921348314606741e-06, 'epoch': 0.97}\n",
      "{'loss': 0.8354, 'grad_norm': 0.7536389231681824, 'learning_rate': 6.898876404494382e-06, 'epoch': 0.98}\n",
      "{'loss': 0.8242, 'grad_norm': 0.7188332676887512, 'learning_rate': 6.876404494382022e-06, 'epoch': 0.99}\n",
      "{'loss': 0.8503, 'grad_norm': 0.7495570182800293, 'learning_rate': 6.853932584269663e-06, 'epoch': 0.99}\n",
      "{'loss': 0.8217, 'grad_norm': 0.6905661225318909, 'learning_rate': 6.8314606741573025e-06, 'epoch': 1.0}\n",
      " 33%|█████████████                          | 152/456 [38:12<1:09:19, 13.68s/it][2024-10-23 08:38:09,395] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:02<00:41,  1.47s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:57,  2.12s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:08<01:02,  2.42s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:11<01:04,  2.59s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:14<01:06,  2.76s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:13,  3.18s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:08,  3.12s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:04,  3.07s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:27<01:00,  3.03s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:30<00:57,  3.01s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:33<00:53,  2.98s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:36<00:50,  2.95s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:39<00:46,  2.93s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:42<00:44,  2.99s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:46<00:45,  3.28s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:49<00:40,  3.15s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:52<00:37,  3.09s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:55<00:33,  3.04s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:58<00:29,  2.98s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:01<00:26,  2.95s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:04<00:23,  2.97s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:07<00:21,  3.02s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:10<00:18,  3.03s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:14<00:16,  3.26s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:16<00:12,  3.16s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:19<00:09,  3.07s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:22<00:06,  3.01s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:26<00:03,  3.28s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.510165810585022, 'eval_runtime': 92.4894, 'eval_samples_per_second': 101.601, 'eval_steps_per_second': 1.589, 'epoch': 1.0}\n",
      " 33%|█████████████                          | 152/456 [39:45<1:09:19, 13.68s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:29<00:00,  3.14s/it]\u001b[A\n",
      "{'loss': 0.8451, 'grad_norm': 0.7721417546272278, 'learning_rate': 6.808988764044943e-06, 'epoch': 1.01}\n",
      "{'loss': 0.7571, 'grad_norm': 0.9648106098175049, 'learning_rate': 6.7865168539325835e-06, 'epoch': 1.01}\n",
      "{'loss': 0.7731, 'grad_norm': 0.7627851366996765, 'learning_rate': 6.764044943820224e-06, 'epoch': 1.01}\n",
      "{'loss': 0.7799, 'grad_norm': 0.8207029700279236, 'learning_rate': 6.7415730337078645e-06, 'epoch': 1.02}\n",
      "{'loss': 0.7944, 'grad_norm': 0.9544258117675781, 'learning_rate': 6.719101123595505e-06, 'epoch': 1.03}\n",
      "{'loss': 0.748, 'grad_norm': 0.8232325315475464, 'learning_rate': 6.696629213483146e-06, 'epoch': 1.03}\n",
      "{'loss': 0.7607, 'grad_norm': 0.7824453711509705, 'learning_rate': 6.674157303370786e-06, 'epoch': 1.04}\n",
      "{'loss': 0.7154, 'grad_norm': 0.8087050318717957, 'learning_rate': 6.651685393258427e-06, 'epoch': 1.05}\n",
      "{'loss': 0.7729, 'grad_norm': 0.8348264098167419, 'learning_rate': 6.6292134831460665e-06, 'epoch': 1.05}\n",
      "{'loss': 0.7615, 'grad_norm': 0.8208637237548828, 'learning_rate': 6.606741573033707e-06, 'epoch': 1.06}\n",
      "{'loss': 0.7721, 'grad_norm': 0.861496090888977, 'learning_rate': 6.5842696629213475e-06, 'epoch': 1.07}\n",
      "{'loss': 0.7419, 'grad_norm': 0.8037291765213013, 'learning_rate': 6.561797752808988e-06, 'epoch': 1.07}\n",
      "{'loss': 0.7429, 'grad_norm': 0.8940791487693787, 'learning_rate': 6.539325842696629e-06, 'epoch': 1.08}\n",
      "{'loss': 0.7391, 'grad_norm': 0.7521793842315674, 'learning_rate': 6.516853932584269e-06, 'epoch': 1.09}\n",
      "{'loss': 0.7515, 'grad_norm': 0.8571195602416992, 'learning_rate': 6.49438202247191e-06, 'epoch': 1.09}\n",
      "{'loss': 0.7466, 'grad_norm': 0.7828153967857361, 'learning_rate': 6.47191011235955e-06, 'epoch': 1.1}\n",
      "{'loss': 0.7338, 'grad_norm': 0.7707533240318298, 'learning_rate': 6.449438202247191e-06, 'epoch': 1.11}\n",
      "{'loss': 0.7523, 'grad_norm': 0.8595334887504578, 'learning_rate': 6.426966292134831e-06, 'epoch': 1.11}\n",
      "{'loss': 0.7492, 'grad_norm': 0.8076367378234863, 'learning_rate': 6.404494382022471e-06, 'epoch': 1.12}\n",
      "{'loss': 0.7211, 'grad_norm': 0.8143178820610046, 'learning_rate': 6.3820224719101114e-06, 'epoch': 1.12}\n",
      "{'loss': 0.6791, 'grad_norm': 0.7163950800895691, 'learning_rate': 6.359550561797752e-06, 'epoch': 1.13}\n",
      "{'loss': 0.746, 'grad_norm': 0.795738935470581, 'learning_rate': 6.337078651685393e-06, 'epoch': 1.14}\n",
      "{'loss': 0.7658, 'grad_norm': 0.7533068060874939, 'learning_rate': 6.314606741573033e-06, 'epoch': 1.14}\n",
      "{'loss': 0.7213, 'grad_norm': 0.7139503955841064, 'learning_rate': 6.292134831460674e-06, 'epoch': 1.15}\n",
      "{'loss': 0.7448, 'grad_norm': 0.7563740015029907, 'learning_rate': 6.269662921348314e-06, 'epoch': 1.16}\n",
      "{'loss': 0.7039, 'grad_norm': 0.7682527303695679, 'learning_rate': 6.247191011235955e-06, 'epoch': 1.16}\n",
      "{'loss': 0.7445, 'grad_norm': 0.7568464279174805, 'learning_rate': 6.224719101123595e-06, 'epoch': 1.17}\n",
      "{'loss': 0.7308, 'grad_norm': 0.7738968729972839, 'learning_rate': 6.202247191011235e-06, 'epoch': 1.18}\n",
      "{'loss': 0.7369, 'grad_norm': 0.7041671872138977, 'learning_rate': 6.179775280898876e-06, 'epoch': 1.18}\n",
      "{'loss': 0.7083, 'grad_norm': 0.7591180801391602, 'learning_rate': 6.157303370786516e-06, 'epoch': 1.19}\n",
      "{'loss': 0.7892, 'grad_norm': 0.7478256225585938, 'learning_rate': 6.134831460674157e-06, 'epoch': 1.2}\n",
      "{'loss': 0.7385, 'grad_norm': 0.7178580164909363, 'learning_rate': 6.112359550561797e-06, 'epoch': 1.2}\n",
      "{'loss': 0.7211, 'grad_norm': 0.7393736839294434, 'learning_rate': 6.089887640449438e-06, 'epoch': 1.21}\n",
      "{'loss': 0.7534, 'grad_norm': 0.7427972555160522, 'learning_rate': 6.067415730337078e-06, 'epoch': 1.22}\n",
      "{'loss': 0.8194, 'grad_norm': 0.7884901165962219, 'learning_rate': 6.044943820224719e-06, 'epoch': 1.22}\n",
      "{'loss': 0.7402, 'grad_norm': 0.6907145977020264, 'learning_rate': 6.022471910112359e-06, 'epoch': 1.23}\n",
      "{'loss': 0.7407, 'grad_norm': 0.7457485795021057, 'learning_rate': 6e-06, 'epoch': 1.24}\n",
      "{'loss': 0.6906, 'grad_norm': 0.7083614468574524, 'learning_rate': 5.97752808988764e-06, 'epoch': 1.24}\n",
      "{'loss': 0.6975, 'grad_norm': 0.7429161071777344, 'learning_rate': 5.95505617977528e-06, 'epoch': 1.25}\n",
      "{'loss': 0.7461, 'grad_norm': 0.7780029773712158, 'learning_rate': 5.932584269662921e-06, 'epoch': 1.26}\n",
      "{'loss': 0.7116, 'grad_norm': 0.7172408103942871, 'learning_rate': 5.910112359550561e-06, 'epoch': 1.26}\n",
      "{'loss': 0.698, 'grad_norm': 0.7364016771316528, 'learning_rate': 5.887640449438202e-06, 'epoch': 1.27}\n",
      "{'loss': 0.7865, 'grad_norm': 0.7899619340896606, 'learning_rate': 5.865168539325842e-06, 'epoch': 1.28}\n",
      "{'loss': 0.7181, 'grad_norm': 0.7075260281562805, 'learning_rate': 5.842696629213483e-06, 'epoch': 1.28}\n",
      "{'loss': 0.7454, 'grad_norm': 0.770408570766449, 'learning_rate': 5.820224719101123e-06, 'epoch': 1.29}\n",
      "{'loss': 0.7793, 'grad_norm': 0.764244019985199, 'learning_rate': 5.797752808988764e-06, 'epoch': 1.3}\n",
      "{'loss': 0.7828, 'grad_norm': 0.7821069359779358, 'learning_rate': 5.775280898876404e-06, 'epoch': 1.3}\n",
      "{'loss': 0.7942, 'grad_norm': 0.832664430141449, 'learning_rate': 5.752808988764044e-06, 'epoch': 1.31}\n",
      "{'loss': 0.7429, 'grad_norm': 0.7166633009910583, 'learning_rate': 5.730337078651685e-06, 'epoch': 1.32}\n",
      "{'loss': 0.7579, 'grad_norm': 0.7922773361206055, 'learning_rate': 5.707865168539325e-06, 'epoch': 1.32}\n",
      "{'loss': 0.6772, 'grad_norm': 0.6865745186805725, 'learning_rate': 5.685393258426966e-06, 'epoch': 1.33}\n",
      "{'loss': 0.7306, 'grad_norm': 0.741461992263794, 'learning_rate': 5.662921348314606e-06, 'epoch': 1.34}\n",
      "{'loss': 0.6755, 'grad_norm': 0.6916698813438416, 'learning_rate': 5.640449438202247e-06, 'epoch': 1.34}\n",
      "{'loss': 0.7063, 'grad_norm': 0.7289441823959351, 'learning_rate': 5.617977528089888e-06, 'epoch': 1.35}\n",
      "{'loss': 0.7738, 'grad_norm': 0.7164650559425354, 'learning_rate': 5.595505617977528e-06, 'epoch': 1.36}\n",
      "{'loss': 0.7266, 'grad_norm': 0.7513131499290466, 'learning_rate': 5.573033707865168e-06, 'epoch': 1.36}\n",
      "{'loss': 0.7565, 'grad_norm': 0.7638522386550903, 'learning_rate': 5.550561797752808e-06, 'epoch': 1.37}\n",
      "{'loss': 0.7387, 'grad_norm': 0.7181036472320557, 'learning_rate': 5.528089887640449e-06, 'epoch': 1.38}\n",
      "{'loss': 0.7197, 'grad_norm': 0.7851821184158325, 'learning_rate': 5.505617977528089e-06, 'epoch': 1.38}\n",
      "{'loss': 0.7148, 'grad_norm': 0.7289327383041382, 'learning_rate': 5.48314606741573e-06, 'epoch': 1.39}\n",
      "{'loss': 0.7431, 'grad_norm': 0.7680321931838989, 'learning_rate': 5.46067415730337e-06, 'epoch': 1.39}\n",
      "{'loss': 0.7817, 'grad_norm': 0.759449303150177, 'learning_rate': 5.438202247191011e-06, 'epoch': 1.4}\n",
      "{'loss': 0.7457, 'grad_norm': 0.8426921963691711, 'learning_rate': 5.415730337078652e-06, 'epoch': 1.41}\n",
      "{'loss': 0.7225, 'grad_norm': 0.7485631108283997, 'learning_rate': 5.393258426966292e-06, 'epoch': 1.41}\n",
      "{'loss': 0.7855, 'grad_norm': 0.8036215901374817, 'learning_rate': 5.370786516853933e-06, 'epoch': 1.42}\n",
      "{'loss': 0.7174, 'grad_norm': 0.6952613592147827, 'learning_rate': 5.348314606741572e-06, 'epoch': 1.43}\n",
      "{'loss': 0.7116, 'grad_norm': 0.8010755181312561, 'learning_rate': 5.325842696629213e-06, 'epoch': 1.43}\n",
      "{'loss': 0.7063, 'grad_norm': 0.72609543800354, 'learning_rate': 5.303370786516853e-06, 'epoch': 1.44}\n",
      "{'loss': 0.7516, 'grad_norm': 0.7618480324745178, 'learning_rate': 5.280898876404494e-06, 'epoch': 1.45}\n",
      "{'loss': 0.7483, 'grad_norm': 0.8208317756652832, 'learning_rate': 5.258426966292135e-06, 'epoch': 1.45}\n",
      "{'loss': 0.6766, 'grad_norm': 0.7306883931159973, 'learning_rate': 5.235955056179775e-06, 'epoch': 1.46}\n",
      "{'loss': 0.696, 'grad_norm': 0.7741121053695679, 'learning_rate': 5.213483146067416e-06, 'epoch': 1.47}\n",
      "{'loss': 0.7126, 'grad_norm': 0.7622103691101074, 'learning_rate': 5.191011235955056e-06, 'epoch': 1.47}\n",
      "{'loss': 0.7049, 'grad_norm': 0.7065834403038025, 'learning_rate': 5.168539325842697e-06, 'epoch': 1.48}\n",
      "{'loss': 0.7269, 'grad_norm': 0.7832694053649902, 'learning_rate': 5.146067415730336e-06, 'epoch': 1.49}\n",
      "{'loss': 0.7548, 'grad_norm': 0.7624778151512146, 'learning_rate': 5.123595505617977e-06, 'epoch': 1.49}\n",
      " 50%|████████████████████▌                    | 228/456 [58:22<52:07, 13.72s/it][2024-10-23 08:58:19,152] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:02<00:41,  1.48s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:56,  2.10s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:08<01:02,  2.41s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:12<01:13,  2.94s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:10,  2.94s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:07,  2.95s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:04,  2.94s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:01,  2.95s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:27<00:58,  2.94s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:30<00:56,  2.97s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:33<00:53,  2.99s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:36<00:51,  3.00s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:39<00:47,  2.99s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:42<00:45,  3.01s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:46<00:46,  3.30s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:49<00:41,  3.19s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:52<00:37,  3.13s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:55<00:34,  3.10s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:58<00:30,  3.06s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:01<00:27,  3.04s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:04<00:24,  3.04s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:07<00:21,  3.03s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:10<00:17,  3.00s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:14<00:16,  3.30s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:17<00:12,  3.20s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:20<00:09,  3.12s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:23<00:06,  3.05s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:26<00:03,  3.02s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.49684932827949524, 'eval_runtime': 93.0757, 'eval_samples_per_second': 100.961, 'eval_steps_per_second': 1.579, 'epoch': 1.49}\n",
      " 50%|████████████████████▌                    | 228/456 [59:55<52:07, 13.72s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:30<00:00,  2.98s/it]\u001b[A\n",
      "{'loss': 0.7615, 'grad_norm': 0.7859112024307251, 'learning_rate': 5.101123595505617e-06, 'epoch': 1.5}\n",
      "{'loss': 0.7032, 'grad_norm': 0.7395200729370117, 'learning_rate': 5.078651685393258e-06, 'epoch': 1.51}\n",
      "{'loss': 0.7428, 'grad_norm': 0.7796002626419067, 'learning_rate': 5.056179775280899e-06, 'epoch': 1.51}\n",
      "{'loss': 0.7396, 'grad_norm': 0.7847095727920532, 'learning_rate': 5.033707865168539e-06, 'epoch': 1.52}\n",
      "{'loss': 0.7372, 'grad_norm': 0.7530772089958191, 'learning_rate': 5.01123595505618e-06, 'epoch': 1.53}\n",
      "{'loss': 0.7044, 'grad_norm': 0.7366990447044373, 'learning_rate': 4.98876404494382e-06, 'epoch': 1.53}\n",
      "{'loss': 0.7073, 'grad_norm': 0.7449932098388672, 'learning_rate': 4.966292134831461e-06, 'epoch': 1.54}\n",
      "{'loss': 0.7117, 'grad_norm': 0.778118371963501, 'learning_rate': 4.9438202247191e-06, 'epoch': 1.55}\n",
      "{'loss': 0.7194, 'grad_norm': 0.7617346048355103, 'learning_rate': 4.921348314606741e-06, 'epoch': 1.55}\n",
      "{'loss': 0.7387, 'grad_norm': 0.757758378982544, 'learning_rate': 4.898876404494382e-06, 'epoch': 1.56}\n",
      "{'loss': 0.7189, 'grad_norm': 0.7479361295700073, 'learning_rate': 4.876404494382022e-06, 'epoch': 1.57}\n",
      "{'loss': 0.7635, 'grad_norm': 0.8323254585266113, 'learning_rate': 4.853932584269663e-06, 'epoch': 1.57}\n",
      "{'loss': 0.7154, 'grad_norm': 0.7330405712127686, 'learning_rate': 4.831460674157303e-06, 'epoch': 1.58}\n",
      "{'loss': 0.749, 'grad_norm': 0.7287293672561646, 'learning_rate': 4.808988764044944e-06, 'epoch': 1.59}\n",
      "{'loss': 0.6643, 'grad_norm': 0.764758825302124, 'learning_rate': 4.786516853932584e-06, 'epoch': 1.59}\n",
      "{'loss': 0.7288, 'grad_norm': 0.7315105199813843, 'learning_rate': 4.764044943820225e-06, 'epoch': 1.6}\n",
      "{'loss': 0.6898, 'grad_norm': 0.7464094161987305, 'learning_rate': 4.741573033707865e-06, 'epoch': 1.61}\n",
      "{'loss': 0.7036, 'grad_norm': 0.7318220734596252, 'learning_rate': 4.719101123595505e-06, 'epoch': 1.61}\n",
      "{'loss': 0.7068, 'grad_norm': 0.7149606347084045, 'learning_rate': 4.696629213483146e-06, 'epoch': 1.62}\n",
      "{'loss': 0.7466, 'grad_norm': 0.7591696977615356, 'learning_rate': 4.674157303370786e-06, 'epoch': 1.62}\n",
      "{'loss': 0.6922, 'grad_norm': 0.7303937673568726, 'learning_rate': 4.651685393258427e-06, 'epoch': 1.63}\n",
      "{'loss': 0.7056, 'grad_norm': 0.7085955739021301, 'learning_rate': 4.629213483146067e-06, 'epoch': 1.64}\n",
      "{'loss': 0.7044, 'grad_norm': 0.7338441610336304, 'learning_rate': 4.606741573033708e-06, 'epoch': 1.64}\n",
      "{'loss': 0.7236, 'grad_norm': 0.7246596813201904, 'learning_rate': 4.584269662921348e-06, 'epoch': 1.65}\n",
      "{'loss': 0.7439, 'grad_norm': 0.7216262221336365, 'learning_rate': 4.561797752808989e-06, 'epoch': 1.66}\n",
      "{'loss': 0.7573, 'grad_norm': 0.7591971755027771, 'learning_rate': 4.53932584269663e-06, 'epoch': 1.66}\n",
      "{'loss': 0.7253, 'grad_norm': 0.7396619319915771, 'learning_rate': 4.516853932584269e-06, 'epoch': 1.67}\n",
      "{'loss': 0.7234, 'grad_norm': 0.70351243019104, 'learning_rate': 4.49438202247191e-06, 'epoch': 1.68}\n",
      "{'loss': 0.716, 'grad_norm': 0.7016115188598633, 'learning_rate': 4.47191011235955e-06, 'epoch': 1.68}\n",
      "{'loss': 0.7048, 'grad_norm': 0.69784015417099, 'learning_rate': 4.449438202247191e-06, 'epoch': 1.69}\n",
      "{'loss': 0.7356, 'grad_norm': 0.7303882837295532, 'learning_rate': 4.426966292134831e-06, 'epoch': 1.7}\n",
      "{'loss': 0.7495, 'grad_norm': 0.7124550342559814, 'learning_rate': 4.404494382022472e-06, 'epoch': 1.7}\n",
      "{'loss': 0.7246, 'grad_norm': 0.7090986371040344, 'learning_rate': 4.382022471910112e-06, 'epoch': 1.71}\n",
      "{'loss': 0.7022, 'grad_norm': 0.6955261826515198, 'learning_rate': 4.359550561797753e-06, 'epoch': 1.72}\n",
      "{'loss': 0.7128, 'grad_norm': 0.742545485496521, 'learning_rate': 4.337078651685394e-06, 'epoch': 1.72}\n",
      "{'loss': 0.7274, 'grad_norm': 0.7051554322242737, 'learning_rate': 4.314606741573033e-06, 'epoch': 1.73}\n",
      "{'loss': 0.7392, 'grad_norm': 0.7441872358322144, 'learning_rate': 4.292134831460674e-06, 'epoch': 1.74}\n",
      "{'loss': 0.7084, 'grad_norm': 0.6978309154510498, 'learning_rate': 4.269662921348314e-06, 'epoch': 1.74}\n",
      "{'loss': 0.7019, 'grad_norm': 0.708449125289917, 'learning_rate': 4.247191011235955e-06, 'epoch': 1.75}\n",
      "{'loss': 0.6975, 'grad_norm': 0.7111445665359497, 'learning_rate': 4.224719101123595e-06, 'epoch': 1.76}\n",
      "{'loss': 0.7327, 'grad_norm': 0.7567662596702576, 'learning_rate': 4.202247191011236e-06, 'epoch': 1.76}\n",
      "{'loss': 0.7083, 'grad_norm': 0.7452116012573242, 'learning_rate': 4.179775280898877e-06, 'epoch': 1.77}\n",
      "{'loss': 0.7422, 'grad_norm': 0.7215219736099243, 'learning_rate': 4.157303370786517e-06, 'epoch': 1.78}\n",
      "{'loss': 0.7206, 'grad_norm': 0.7326419353485107, 'learning_rate': 4.134831460674158e-06, 'epoch': 1.78}\n",
      "{'loss': 0.7017, 'grad_norm': 0.7105246186256409, 'learning_rate': 4.112359550561798e-06, 'epoch': 1.79}\n",
      "{'loss': 0.7502, 'grad_norm': 0.7463326454162598, 'learning_rate': 4.089887640449438e-06, 'epoch': 1.8}\n",
      "{'loss': 0.7131, 'grad_norm': 0.7246641516685486, 'learning_rate': 4.067415730337078e-06, 'epoch': 1.8}\n",
      "{'loss': 0.7803, 'grad_norm': 0.7315199375152588, 'learning_rate': 4.044943820224719e-06, 'epoch': 1.81}\n",
      "{'loss': 0.6883, 'grad_norm': 0.6724773049354553, 'learning_rate': 4.022471910112359e-06, 'epoch': 1.82}\n",
      "{'loss': 0.7147, 'grad_norm': 0.7344335317611694, 'learning_rate': 4e-06, 'epoch': 1.82}\n",
      "{'loss': 0.7458, 'grad_norm': 0.7249424457550049, 'learning_rate': 3.97752808988764e-06, 'epoch': 1.83}\n",
      "{'loss': 0.6955, 'grad_norm': 0.7316385507583618, 'learning_rate': 3.955056179775281e-06, 'epoch': 1.84}\n",
      "{'loss': 0.6752, 'grad_norm': 0.6999800801277161, 'learning_rate': 3.932584269662921e-06, 'epoch': 1.84}\n",
      "{'loss': 0.7103, 'grad_norm': 0.7016620635986328, 'learning_rate': 3.910112359550562e-06, 'epoch': 1.85}\n",
      "{'loss': 0.763, 'grad_norm': 0.7226609587669373, 'learning_rate': 3.887640449438202e-06, 'epoch': 1.86}\n",
      "{'loss': 0.7216, 'grad_norm': 0.7165422439575195, 'learning_rate': 3.865168539325843e-06, 'epoch': 1.86}\n",
      "{'loss': 0.7119, 'grad_norm': 0.7211809158325195, 'learning_rate': 3.842696629213483e-06, 'epoch': 1.87}\n",
      "{'loss': 0.708, 'grad_norm': 0.7182952761650085, 'learning_rate': 3.820224719101124e-06, 'epoch': 1.88}\n",
      "{'loss': 0.7335, 'grad_norm': 0.7108514904975891, 'learning_rate': 3.797752808988764e-06, 'epoch': 1.88}\n",
      "{'loss': 0.7417, 'grad_norm': 0.699679434299469, 'learning_rate': 3.7752808988764043e-06, 'epoch': 1.89}\n",
      "{'loss': 0.7444, 'grad_norm': 0.7139597535133362, 'learning_rate': 3.7528089887640448e-06, 'epoch': 1.89}\n",
      "{'loss': 0.7073, 'grad_norm': 0.7172414660453796, 'learning_rate': 3.730337078651685e-06, 'epoch': 1.9}\n",
      "{'loss': 0.7437, 'grad_norm': 0.7155567407608032, 'learning_rate': 3.7078651685393257e-06, 'epoch': 1.91}\n",
      "{'loss': 0.7101, 'grad_norm': 0.7006486058235168, 'learning_rate': 3.6853932584269662e-06, 'epoch': 1.91}\n",
      "{'loss': 0.8131, 'grad_norm': 0.766124427318573, 'learning_rate': 3.6629213483146067e-06, 'epoch': 1.92}\n",
      "{'loss': 0.7157, 'grad_norm': 0.7475634813308716, 'learning_rate': 3.6404494382022472e-06, 'epoch': 1.93}\n",
      "{'loss': 0.6663, 'grad_norm': 0.6983497142791748, 'learning_rate': 3.6179775280898873e-06, 'epoch': 1.93}\n",
      "{'loss': 0.7492, 'grad_norm': 0.7190030217170715, 'learning_rate': 3.5955056179775278e-06, 'epoch': 1.94}\n",
      "{'loss': 0.7304, 'grad_norm': 0.7264803647994995, 'learning_rate': 3.5730337078651683e-06, 'epoch': 1.95}\n",
      "{'loss': 0.7429, 'grad_norm': 0.7493358850479126, 'learning_rate': 3.5505617977528087e-06, 'epoch': 1.95}\n",
      "{'loss': 0.7475, 'grad_norm': 0.7131369113922119, 'learning_rate': 3.5280898876404497e-06, 'epoch': 1.96}\n",
      "{'loss': 0.6827, 'grad_norm': 0.7118698358535767, 'learning_rate': 3.5056179775280897e-06, 'epoch': 1.97}\n",
      "{'loss': 0.7228, 'grad_norm': 0.6936861872673035, 'learning_rate': 3.48314606741573e-06, 'epoch': 1.97}\n",
      "{'loss': 0.7025, 'grad_norm': 0.7251715660095215, 'learning_rate': 3.4606741573033707e-06, 'epoch': 1.98}\n",
      "{'loss': 0.7362, 'grad_norm': 0.7283429503440857, 'learning_rate': 3.438202247191011e-06, 'epoch': 1.99}\n",
      "{'loss': 0.6959, 'grad_norm': 0.789775013923645, 'learning_rate': 3.4157303370786513e-06, 'epoch': 1.99}\n",
      " 67%|██████████████████████████             | 304/456 [1:17:27<34:54, 13.78s/it][2024-10-23 09:17:24,642] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:42,  1.50s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:56,  2.09s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:08<01:01,  2.38s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:11<01:04,  2.59s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:14<01:05,  2.75s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:10,  3.08s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:06,  3.02s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:02,  2.98s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:27<00:59,  2.98s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:30<00:56,  2.95s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:34<00:58,  3.24s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:37<00:53,  3.16s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:40<00:49,  3.08s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:42<00:45,  3.01s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:45<00:41,  2.97s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:48<00:38,  2.96s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:51<00:35,  2.96s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:54<00:32,  2.98s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:58<00:33,  3.31s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:01<00:28,  3.20s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:04<00:25,  3.14s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:07<00:21,  3.08s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:10<00:18,  3.04s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:13<00:15,  3.00s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:16<00:11,  2.99s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:19<00:08,  2.98s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:22<00:06,  3.02s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:25<00:03,  3.05s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4862593114376068, 'eval_runtime': 92.6749, 'eval_samples_per_second': 101.397, 'eval_steps_per_second': 1.586, 'epoch': 1.99}\n",
      " 67%|██████████████████████████             | 304/456 [1:19:00<34:54, 13.78s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:29<00:00,  3.33s/it]\u001b[A\n",
      "{'loss': 0.654, 'grad_norm': 0.7045432329177856, 'learning_rate': 3.3932584269662917e-06, 'epoch': 2.0}\n",
      "{'loss': 0.6677, 'grad_norm': 0.6913027167320251, 'learning_rate': 3.3707865168539322e-06, 'epoch': 2.01}\n",
      "{'loss': 0.6205, 'grad_norm': 1.2516858577728271, 'learning_rate': 3.348314606741573e-06, 'epoch': 2.01}\n",
      "{'loss': 0.631, 'grad_norm': 1.0696663856506348, 'learning_rate': 3.3258426966292136e-06, 'epoch': 2.01}\n",
      "{'loss': 0.6397, 'grad_norm': 0.8845438361167908, 'learning_rate': 3.3033707865168537e-06, 'epoch': 2.02}\n",
      "{'loss': 0.6519, 'grad_norm': 0.8306434154510498, 'learning_rate': 3.280898876404494e-06, 'epoch': 2.03}\n",
      "{'loss': 0.647, 'grad_norm': 0.9309403896331787, 'learning_rate': 3.2584269662921347e-06, 'epoch': 2.03}\n",
      "{'loss': 0.6537, 'grad_norm': 1.0243275165557861, 'learning_rate': 3.235955056179775e-06, 'epoch': 2.04}\n",
      "{'loss': 0.5975, 'grad_norm': 1.0343480110168457, 'learning_rate': 3.2134831460674156e-06, 'epoch': 2.05}\n",
      "{'loss': 0.6198, 'grad_norm': 0.9027402400970459, 'learning_rate': 3.1910112359550557e-06, 'epoch': 2.05}\n",
      "{'loss': 0.6292, 'grad_norm': 0.8868022561073303, 'learning_rate': 3.1685393258426966e-06, 'epoch': 2.06}\n",
      "{'loss': 0.6348, 'grad_norm': 1.0073564052581787, 'learning_rate': 3.146067415730337e-06, 'epoch': 2.07}\n",
      "{'loss': 0.638, 'grad_norm': 0.9593275785446167, 'learning_rate': 3.1235955056179776e-06, 'epoch': 2.07}\n",
      "{'loss': 0.6153, 'grad_norm': 0.8886165618896484, 'learning_rate': 3.1011235955056177e-06, 'epoch': 2.08}\n",
      "{'loss': 0.6009, 'grad_norm': 0.8376910090446472, 'learning_rate': 3.078651685393258e-06, 'epoch': 2.09}\n",
      "{'loss': 0.6371, 'grad_norm': 0.8444380164146423, 'learning_rate': 3.0561797752808986e-06, 'epoch': 2.09}\n",
      "{'loss': 0.6347, 'grad_norm': 0.9147853851318359, 'learning_rate': 3.033707865168539e-06, 'epoch': 2.1}\n",
      "{'loss': 0.6318, 'grad_norm': 0.8563600182533264, 'learning_rate': 3.0112359550561796e-06, 'epoch': 2.11}\n",
      "{'loss': 0.6322, 'grad_norm': 0.8528035283088684, 'learning_rate': 2.98876404494382e-06, 'epoch': 2.11}\n",
      "{'loss': 0.6157, 'grad_norm': 0.8158034682273865, 'learning_rate': 2.9662921348314606e-06, 'epoch': 2.12}\n",
      "{'loss': 0.6272, 'grad_norm': 0.8142435550689697, 'learning_rate': 2.943820224719101e-06, 'epoch': 2.12}\n",
      "{'loss': 0.6001, 'grad_norm': 0.8050946593284607, 'learning_rate': 2.9213483146067416e-06, 'epoch': 2.13}\n",
      "{'loss': 0.5934, 'grad_norm': 0.7534977793693542, 'learning_rate': 2.898876404494382e-06, 'epoch': 2.14}\n",
      "{'loss': 0.5988, 'grad_norm': 0.7903631329536438, 'learning_rate': 2.876404494382022e-06, 'epoch': 2.14}\n",
      "{'loss': 0.6076, 'grad_norm': 0.7415390610694885, 'learning_rate': 2.8539325842696626e-06, 'epoch': 2.15}\n",
      "{'loss': 0.587, 'grad_norm': 0.7696704268455505, 'learning_rate': 2.831460674157303e-06, 'epoch': 2.16}\n",
      "{'loss': 0.5995, 'grad_norm': 0.7984368801116943, 'learning_rate': 2.808988764044944e-06, 'epoch': 2.16}\n",
      "{'loss': 0.6587, 'grad_norm': 0.7723921537399292, 'learning_rate': 2.786516853932584e-06, 'epoch': 2.17}\n",
      "{'loss': 0.6494, 'grad_norm': 0.8271836638450623, 'learning_rate': 2.7640449438202246e-06, 'epoch': 2.18}\n",
      "{'loss': 0.6203, 'grad_norm': 0.7482278943061829, 'learning_rate': 2.741573033707865e-06, 'epoch': 2.18}\n",
      "{'loss': 0.5747, 'grad_norm': 0.7499688863754272, 'learning_rate': 2.7191011235955055e-06, 'epoch': 2.19}\n",
      "{'loss': 0.633, 'grad_norm': 0.7487247586250305, 'learning_rate': 2.696629213483146e-06, 'epoch': 2.2}\n",
      "{'loss': 0.6033, 'grad_norm': 0.7906697392463684, 'learning_rate': 2.674157303370786e-06, 'epoch': 2.2}\n",
      "{'loss': 0.6123, 'grad_norm': 0.7435545325279236, 'learning_rate': 2.6516853932584266e-06, 'epoch': 2.21}\n",
      "{'loss': 0.5964, 'grad_norm': 0.7936589121818542, 'learning_rate': 2.6292134831460675e-06, 'epoch': 2.22}\n",
      "{'loss': 0.6155, 'grad_norm': 0.7832732796669006, 'learning_rate': 2.606741573033708e-06, 'epoch': 2.22}\n",
      "{'loss': 0.6175, 'grad_norm': 0.7616626024246216, 'learning_rate': 2.5842696629213485e-06, 'epoch': 2.23}\n",
      "{'loss': 0.6322, 'grad_norm': 0.7397405505180359, 'learning_rate': 2.5617977528089885e-06, 'epoch': 2.24}\n",
      "{'loss': 0.6224, 'grad_norm': 0.7547144293785095, 'learning_rate': 2.539325842696629e-06, 'epoch': 2.24}\n",
      "{'loss': 0.6298, 'grad_norm': 0.7553250193595886, 'learning_rate': 2.5168539325842695e-06, 'epoch': 2.25}\n",
      "{'loss': 0.6381, 'grad_norm': 0.7588287591934204, 'learning_rate': 2.49438202247191e-06, 'epoch': 2.26}\n",
      "{'loss': 0.6344, 'grad_norm': 0.7451286911964417, 'learning_rate': 2.47191011235955e-06, 'epoch': 2.26}\n",
      "{'loss': 0.6104, 'grad_norm': 0.7622197270393372, 'learning_rate': 2.449438202247191e-06, 'epoch': 2.27}\n",
      "{'loss': 0.5925, 'grad_norm': 0.7431764006614685, 'learning_rate': 2.4269662921348315e-06, 'epoch': 2.28}\n",
      "{'loss': 0.5764, 'grad_norm': 0.7311068773269653, 'learning_rate': 2.404494382022472e-06, 'epoch': 2.28}\n",
      "{'loss': 0.6282, 'grad_norm': 0.7634266018867493, 'learning_rate': 2.3820224719101125e-06, 'epoch': 2.29}\n",
      "{'loss': 0.6444, 'grad_norm': 0.8883479833602905, 'learning_rate': 2.3595505617977525e-06, 'epoch': 2.3}\n",
      "{'loss': 0.6356, 'grad_norm': 0.7250047326087952, 'learning_rate': 2.337078651685393e-06, 'epoch': 2.3}\n",
      "{'loss': 0.5932, 'grad_norm': 0.7860133647918701, 'learning_rate': 2.3146067415730335e-06, 'epoch': 2.31}\n",
      "{'loss': 0.5969, 'grad_norm': 0.7239455580711365, 'learning_rate': 2.292134831460674e-06, 'epoch': 2.32}\n",
      "{'loss': 0.6031, 'grad_norm': 0.7537525296211243, 'learning_rate': 2.269662921348315e-06, 'epoch': 2.32}\n",
      "{'loss': 0.6261, 'grad_norm': 0.751832902431488, 'learning_rate': 2.247191011235955e-06, 'epoch': 2.33}\n",
      "{'loss': 0.619, 'grad_norm': 0.7451199293136597, 'learning_rate': 2.2247191011235954e-06, 'epoch': 2.34}\n",
      "{'loss': 0.5929, 'grad_norm': 0.7465813755989075, 'learning_rate': 2.202247191011236e-06, 'epoch': 2.34}\n",
      "{'loss': 0.6, 'grad_norm': 0.742750346660614, 'learning_rate': 2.1797752808988764e-06, 'epoch': 2.35}\n",
      "{'loss': 0.62, 'grad_norm': 0.7536427974700928, 'learning_rate': 2.1573033707865165e-06, 'epoch': 2.36}\n",
      "{'loss': 0.6195, 'grad_norm': 0.7778351902961731, 'learning_rate': 2.134831460674157e-06, 'epoch': 2.36}\n",
      "{'loss': 0.6084, 'grad_norm': 0.7631467580795288, 'learning_rate': 2.1123595505617975e-06, 'epoch': 2.37}\n",
      "{'loss': 0.6424, 'grad_norm': 0.755094587802887, 'learning_rate': 2.0898876404494384e-06, 'epoch': 2.38}\n",
      "{'loss': 0.6068, 'grad_norm': 0.7536702156066895, 'learning_rate': 2.067415730337079e-06, 'epoch': 2.38}\n",
      "{'loss': 0.6126, 'grad_norm': 0.7522385716438293, 'learning_rate': 2.044943820224719e-06, 'epoch': 2.39}\n",
      "{'loss': 0.5611, 'grad_norm': 0.7530955076217651, 'learning_rate': 2.0224719101123594e-06, 'epoch': 2.39}\n",
      "{'loss': 0.6106, 'grad_norm': 0.7607967853546143, 'learning_rate': 2e-06, 'epoch': 2.4}\n",
      "{'loss': 0.6472, 'grad_norm': 0.7918729782104492, 'learning_rate': 1.9775280898876404e-06, 'epoch': 2.41}\n",
      "{'loss': 0.6217, 'grad_norm': 0.7605706453323364, 'learning_rate': 1.955056179775281e-06, 'epoch': 2.41}\n",
      "{'loss': 0.5946, 'grad_norm': 0.7165352702140808, 'learning_rate': 1.9325842696629214e-06, 'epoch': 2.42}\n",
      "{'loss': 0.6139, 'grad_norm': 0.7367133498191833, 'learning_rate': 1.910112359550562e-06, 'epoch': 2.43}\n",
      "{'loss': 0.5754, 'grad_norm': 0.7494545578956604, 'learning_rate': 1.8876404494382021e-06, 'epoch': 2.43}\n",
      "{'loss': 0.618, 'grad_norm': 0.7575247287750244, 'learning_rate': 1.8651685393258424e-06, 'epoch': 2.44}\n",
      "{'loss': 0.6294, 'grad_norm': 0.7504178881645203, 'learning_rate': 1.8426966292134831e-06, 'epoch': 2.45}\n",
      "{'loss': 0.6143, 'grad_norm': 0.7315924763679504, 'learning_rate': 1.8202247191011236e-06, 'epoch': 2.45}\n",
      "{'loss': 0.6126, 'grad_norm': 0.7216473817825317, 'learning_rate': 1.7977528089887639e-06, 'epoch': 2.46}\n",
      "{'loss': 0.5782, 'grad_norm': 0.7224743962287903, 'learning_rate': 1.7752808988764044e-06, 'epoch': 2.47}\n",
      "{'loss': 0.5892, 'grad_norm': 0.7608299851417542, 'learning_rate': 1.7528089887640449e-06, 'epoch': 2.47}\n",
      "{'loss': 0.6325, 'grad_norm': 0.7542943954467773, 'learning_rate': 1.7303370786516853e-06, 'epoch': 2.48}\n",
      "{'loss': 0.6069, 'grad_norm': 0.7464587688446045, 'learning_rate': 1.7078651685393256e-06, 'epoch': 2.49}\n",
      " 83%|████████████████████████████████▌      | 380/456 [1:37:30<17:31, 13.83s/it][2024-10-23 09:37:27,247] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:02<00:40,  1.45s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:56,  2.08s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:08<01:01,  2.37s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:11<01:04,  2.60s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:14<01:05,  2.74s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:17<01:05,  2.85s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:20<01:03,  2.90s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:06,  3.19s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:27<01:01,  3.10s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:30<00:57,  3.03s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:33<00:53,  2.98s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:36<00:50,  2.96s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:39<00:47,  2.99s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:43<00:48,  3.26s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:46<00:44,  3.16s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:49<00:40,  3.08s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:51<00:36,  3.05s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:54<00:33,  3.01s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:57<00:30,  3.01s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:00<00:26,  2.98s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:04<00:26,  3.28s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:07<00:22,  3.16s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:10<00:18,  3.11s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:13<00:15,  3.08s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:16<00:12,  3.05s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:19<00:09,  3.01s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:22<00:06,  3.02s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:25<00:03,  3.00s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.49467039108276367, 'eval_runtime': 92.7215, 'eval_samples_per_second': 101.347, 'eval_steps_per_second': 1.585, 'epoch': 2.49}\n",
      " 83%|████████████████████████████████▌      | 380/456 [1:39:03<17:31, 13.83s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:29<00:00,  2.99s/it]\u001b[A\n",
      "{'loss': 0.6299, 'grad_norm': 0.7601841688156128, 'learning_rate': 1.6853932584269661e-06, 'epoch': 2.49}\n",
      "{'loss': 0.6026, 'grad_norm': 0.7359904050827026, 'learning_rate': 1.6629213483146068e-06, 'epoch': 2.5}\n",
      "{'loss': 0.6278, 'grad_norm': 0.7728983759880066, 'learning_rate': 1.640449438202247e-06, 'epoch': 2.51}\n",
      "{'loss': 0.6155, 'grad_norm': 0.7221293449401855, 'learning_rate': 1.6179775280898876e-06, 'epoch': 2.51}\n",
      "{'loss': 0.5941, 'grad_norm': 0.7198085188865662, 'learning_rate': 1.5955056179775279e-06, 'epoch': 2.52}\n",
      "{'loss': 0.6048, 'grad_norm': 0.75462806224823, 'learning_rate': 1.5730337078651686e-06, 'epoch': 2.53}\n",
      "{'loss': 0.6148, 'grad_norm': 0.7342898845672607, 'learning_rate': 1.5505617977528088e-06, 'epoch': 2.53}\n",
      "{'loss': 0.6001, 'grad_norm': 0.7068628072738647, 'learning_rate': 1.5280898876404493e-06, 'epoch': 2.54}\n",
      "{'loss': 0.6766, 'grad_norm': 0.8021420836448669, 'learning_rate': 1.5056179775280898e-06, 'epoch': 2.55}\n",
      "{'loss': 0.5913, 'grad_norm': 0.7627332210540771, 'learning_rate': 1.4831460674157303e-06, 'epoch': 2.55}\n",
      "{'loss': 0.612, 'grad_norm': 0.7309766411781311, 'learning_rate': 1.4606741573033708e-06, 'epoch': 2.56}\n",
      "{'loss': 0.5486, 'grad_norm': 0.7180399298667908, 'learning_rate': 1.438202247191011e-06, 'epoch': 2.57}\n",
      "{'loss': 0.5928, 'grad_norm': 0.7238849997520447, 'learning_rate': 1.4157303370786516e-06, 'epoch': 2.57}\n",
      "{'loss': 0.5936, 'grad_norm': 0.7019768357276917, 'learning_rate': 1.393258426966292e-06, 'epoch': 2.58}\n",
      "{'loss': 0.6675, 'grad_norm': 0.7928797006607056, 'learning_rate': 1.3707865168539325e-06, 'epoch': 2.59}\n",
      "{'loss': 0.665, 'grad_norm': 0.7769991755485535, 'learning_rate': 1.348314606741573e-06, 'epoch': 2.59}\n",
      "{'loss': 0.5817, 'grad_norm': 0.7434130907058716, 'learning_rate': 1.3258426966292133e-06, 'epoch': 2.6}\n",
      "{'loss': 0.6362, 'grad_norm': 0.7283146381378174, 'learning_rate': 1.303370786516854e-06, 'epoch': 2.61}\n",
      "{'loss': 0.5914, 'grad_norm': 0.7375020980834961, 'learning_rate': 1.2808988764044943e-06, 'epoch': 2.61}\n",
      "{'loss': 0.6291, 'grad_norm': 0.7452760934829712, 'learning_rate': 1.2584269662921348e-06, 'epoch': 2.62}\n",
      "{'loss': 0.5812, 'grad_norm': 0.6916828751564026, 'learning_rate': 1.235955056179775e-06, 'epoch': 2.62}\n",
      "{'loss': 0.6161, 'grad_norm': 0.7271521091461182, 'learning_rate': 1.2134831460674157e-06, 'epoch': 2.63}\n",
      "{'loss': 0.6214, 'grad_norm': 0.7616326212882996, 'learning_rate': 1.1910112359550562e-06, 'epoch': 2.64}\n",
      "{'loss': 0.6126, 'grad_norm': 0.7520641088485718, 'learning_rate': 1.1685393258426965e-06, 'epoch': 2.64}\n",
      "{'loss': 0.6414, 'grad_norm': 0.7459259033203125, 'learning_rate': 1.146067415730337e-06, 'epoch': 2.65}\n",
      "{'loss': 0.6034, 'grad_norm': 0.73582524061203, 'learning_rate': 1.1235955056179775e-06, 'epoch': 2.66}\n",
      "{'loss': 0.6101, 'grad_norm': 0.7363784313201904, 'learning_rate': 1.101123595505618e-06, 'epoch': 2.66}\n",
      "{'loss': 0.5995, 'grad_norm': 0.7683298587799072, 'learning_rate': 1.0786516853932582e-06, 'epoch': 2.67}\n",
      "{'loss': 0.5992, 'grad_norm': 0.7407833337783813, 'learning_rate': 1.0561797752808987e-06, 'epoch': 2.68}\n",
      "{'loss': 0.6039, 'grad_norm': 0.752851128578186, 'learning_rate': 1.0337078651685394e-06, 'epoch': 2.68}\n",
      "{'loss': 0.6036, 'grad_norm': 0.7297576665878296, 'learning_rate': 1.0112359550561797e-06, 'epoch': 2.69}\n",
      "{'loss': 0.6037, 'grad_norm': 0.7669467926025391, 'learning_rate': 9.887640449438202e-07, 'epoch': 2.7}\n",
      "{'loss': 0.6338, 'grad_norm': 0.71967613697052, 'learning_rate': 9.662921348314607e-07, 'epoch': 2.7}\n",
      "{'loss': 0.6222, 'grad_norm': 0.7299953699111938, 'learning_rate': 9.438202247191011e-07, 'epoch': 2.71}\n",
      "{'loss': 0.6212, 'grad_norm': 0.7524902820587158, 'learning_rate': 9.213483146067416e-07, 'epoch': 2.72}\n",
      "{'loss': 0.5902, 'grad_norm': 0.7396450638771057, 'learning_rate': 8.988764044943819e-07, 'epoch': 2.72}\n",
      "{'loss': 0.6, 'grad_norm': 0.7542722821235657, 'learning_rate': 8.764044943820224e-07, 'epoch': 2.73}\n",
      "{'loss': 0.612, 'grad_norm': 0.7341530323028564, 'learning_rate': 8.539325842696628e-07, 'epoch': 2.74}\n",
      "{'loss': 0.6125, 'grad_norm': 0.7437134385108948, 'learning_rate': 8.314606741573034e-07, 'epoch': 2.74}\n",
      "{'loss': 0.6081, 'grad_norm': 0.7320730686187744, 'learning_rate': 8.089887640449438e-07, 'epoch': 2.75}\n",
      "{'loss': 0.6057, 'grad_norm': 0.7354785799980164, 'learning_rate': 7.865168539325843e-07, 'epoch': 2.76}\n",
      "{'loss': 0.5909, 'grad_norm': 0.7244019508361816, 'learning_rate': 7.640449438202247e-07, 'epoch': 2.76}\n",
      "{'loss': 0.6171, 'grad_norm': 0.715572714805603, 'learning_rate': 7.415730337078651e-07, 'epoch': 2.77}\n",
      "{'loss': 0.6137, 'grad_norm': 0.7255869507789612, 'learning_rate': 7.191011235955055e-07, 'epoch': 2.78}\n",
      "{'loss': 0.5936, 'grad_norm': 0.7169371247291565, 'learning_rate': 6.96629213483146e-07, 'epoch': 2.78}\n",
      "{'loss': 0.6242, 'grad_norm': 0.7650127410888672, 'learning_rate': 6.741573033707865e-07, 'epoch': 2.79}\n",
      "{'loss': 0.6171, 'grad_norm': 0.7631711959838867, 'learning_rate': 6.51685393258427e-07, 'epoch': 2.8}\n",
      "{'loss': 0.5796, 'grad_norm': 0.7398171424865723, 'learning_rate': 6.292134831460674e-07, 'epoch': 2.8}\n",
      "{'loss': 0.6081, 'grad_norm': 0.7339519262313843, 'learning_rate': 6.067415730337079e-07, 'epoch': 2.81}\n",
      "{'loss': 0.6059, 'grad_norm': 0.7432180643081665, 'learning_rate': 5.842696629213483e-07, 'epoch': 2.82}\n",
      "{'loss': 0.6352, 'grad_norm': 0.7510831356048584, 'learning_rate': 5.617977528089887e-07, 'epoch': 2.82}\n",
      "{'loss': 0.6099, 'grad_norm': 0.722090482711792, 'learning_rate': 5.393258426966291e-07, 'epoch': 2.83}\n",
      "{'loss': 0.6272, 'grad_norm': 0.755976676940918, 'learning_rate': 5.168539325842697e-07, 'epoch': 2.84}\n",
      "{'loss': 0.6104, 'grad_norm': 0.7573722004890442, 'learning_rate': 4.943820224719101e-07, 'epoch': 2.84}\n",
      "{'loss': 0.6177, 'grad_norm': 0.7279070615768433, 'learning_rate': 4.7191011235955054e-07, 'epoch': 2.85}\n",
      "{'loss': 0.6227, 'grad_norm': 0.7353982925415039, 'learning_rate': 4.4943820224719097e-07, 'epoch': 2.86}\n",
      "{'loss': 0.6197, 'grad_norm': 0.7674352526664734, 'learning_rate': 4.269662921348314e-07, 'epoch': 2.86}\n",
      "{'loss': 0.5778, 'grad_norm': 0.6880993247032166, 'learning_rate': 4.044943820224719e-07, 'epoch': 2.87}\n",
      "{'loss': 0.6384, 'grad_norm': 0.7134144902229309, 'learning_rate': 3.8202247191011233e-07, 'epoch': 2.88}\n",
      "{'loss': 0.6509, 'grad_norm': 0.7374664545059204, 'learning_rate': 3.5955056179775277e-07, 'epoch': 2.88}\n",
      "{'loss': 0.5983, 'grad_norm': 0.7303089499473572, 'learning_rate': 3.3707865168539325e-07, 'epoch': 2.89}\n",
      "{'loss': 0.6142, 'grad_norm': 0.7170447111129761, 'learning_rate': 3.146067415730337e-07, 'epoch': 2.89}\n",
      "{'loss': 0.5913, 'grad_norm': 0.7439920902252197, 'learning_rate': 2.921348314606741e-07, 'epoch': 2.9}\n",
      "{'loss': 0.5873, 'grad_norm': 0.7156280875205994, 'learning_rate': 2.6966292134831456e-07, 'epoch': 2.91}\n",
      "{'loss': 0.6177, 'grad_norm': 0.7299496531486511, 'learning_rate': 2.4719101123595505e-07, 'epoch': 2.91}\n",
      "{'loss': 0.5757, 'grad_norm': 0.7358658313751221, 'learning_rate': 2.2471910112359549e-07, 'epoch': 2.92}\n",
      "{'loss': 0.6366, 'grad_norm': 0.7654982209205627, 'learning_rate': 2.0224719101123595e-07, 'epoch': 2.93}\n",
      "{'loss': 0.5805, 'grad_norm': 0.7295712232589722, 'learning_rate': 1.7977528089887638e-07, 'epoch': 2.93}\n",
      "{'loss': 0.5997, 'grad_norm': 0.730717658996582, 'learning_rate': 1.5730337078651685e-07, 'epoch': 2.94}\n",
      "{'loss': 0.6132, 'grad_norm': 0.7127988934516907, 'learning_rate': 1.3483146067415728e-07, 'epoch': 2.95}\n",
      "{'loss': 0.5918, 'grad_norm': 0.7235917448997498, 'learning_rate': 1.1235955056179774e-07, 'epoch': 2.95}\n",
      "{'loss': 0.6178, 'grad_norm': 0.6870617866516113, 'learning_rate': 8.988764044943819e-08, 'epoch': 2.96}\n",
      "{'loss': 0.5998, 'grad_norm': 0.7260863780975342, 'learning_rate': 6.741573033707864e-08, 'epoch': 2.97}\n",
      "{'loss': 0.6076, 'grad_norm': 0.7190686464309692, 'learning_rate': 4.4943820224719096e-08, 'epoch': 2.97}\n",
      "{'loss': 0.6447, 'grad_norm': 0.71013343334198, 'learning_rate': 2.2471910112359548e-08, 'epoch': 2.98}\n",
      "{'loss': 0.6497, 'grad_norm': 0.7165460586547852, 'learning_rate': 0.0, 'epoch': 2.99}\n",
      "100%|███████████████████████████████████████| 456/456 [1:56:38<00:00, 13.64s/it][2024-10-23 09:56:35,507] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:162816] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:42,  1.50s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:57,  2.12s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:08<01:02,  2.42s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:11<01:04,  2.59s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:13,  3.08s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:10,  3.06s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:05,  3.00s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:02,  2.96s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:27<00:58,  2.95s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:30<00:56,  2.95s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:33<00:53,  2.97s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:36<00:51,  3.03s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:39<00:47,  2.99s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:42<00:45,  3.01s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:46<00:46,  3.29s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:49<00:41,  3.19s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:52<00:37,  3.11s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:55<00:33,  3.05s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:58<00:30,  3.03s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:01<00:27,  3.00s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:04<00:24,  3.00s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:08<00:23,  3.30s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:11<00:19,  3.19s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:14<00:15,  3.10s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:17<00:12,  3.06s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:20<00:09,  3.03s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:23<00:05,  3.00s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:25<00:02,  2.96s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.49178823828697205, 'eval_runtime': 93.087, 'eval_samples_per_second': 100.949, 'eval_steps_per_second': 1.579, 'epoch': 2.99}\n",
      "100%|███████████████████████████████████████| 456/456 [1:58:11<00:00, 13.64s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:30<00:00,  3.30s/it]\u001b[A\n",
      "{'train_runtime': 7147.6613, 'train_samples_per_second': 74.936, 'train_steps_per_second': 0.064, 'train_loss': 0.755003271526412, 'epoch': 2.99}\n",
      "100%|███████████████████████████████████████| 456/456 [1:59:06<00:00, 15.67s/it]\n",
      "[2024-10-23 09:59:03,139] [INFO] [axolotl.train.train:195] [PID:162816] [RANK:0] Training Completed!!! Saving pre-trained model to ./outputs/basemodel-llama3-8b\u001b[39m\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mmi300x-shisa-llama3.1-8b-v1-dsz2\u001b[0m at: \u001b[34mhttps://wandb.ai/augmxnt/shisa-v2/runs/8jqlicg3\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35m../../../mnt/nvme1n1p1/MI300-testing/wandb/run-20241023_075955-8jqlicg3/logs\u001b[0m\n",
      "\u001b[0m[rank0]:[W1023 09:59:22.228219747 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m axolotl.cli.train mi300x-llama3.1-8b-fft.dsz2.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097c14ab-0deb-4a7e-9715-c63cd3337958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `8`\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "[2024-10-23 10:00:44,731] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 10:00:44,731] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 10:00:44,737] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 10:00:44,737] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 10:00:44,760] [INFO] [root.spawn:60] [PID:352189] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpdc7ycqbe/test.c -o /tmp/tmpdc7ycqbe/test.o\n",
      "[2024-10-23 10:00:44,760] [INFO] [root.spawn:60] [PID:352192] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpdki8z_ik/test.c -o /tmp/tmpdki8z_ik/test.o\n",
      "[2024-10-23 10:00:44,766] [INFO] [root.spawn:60] [PID:352188] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmp_w7ky9lk/test.c -o /tmp/tmp_w7ky9lk/test.o\n",
      "[2024-10-23 10:00:44,766] [INFO] [root.spawn:60] [PID:352190] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmp_m7i82an/test.c -o /tmp/tmp_m7i82an/test.o\n",
      "[2024-10-23 10:00:44,774] [INFO] [root.spawn:60] [PID:352189] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpdc7ycqbe/test.o -laio -o /tmp/tmpdc7ycqbe/a.out\n",
      "[2024-10-23 10:00:44,777] [INFO] [root.spawn:60] [PID:352192] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpdki8z_ik/test.o -laio -o /tmp/tmpdki8z_ik/a.out\n",
      "[2024-10-23 10:00:44,781] [INFO] [root.spawn:60] [PID:352190] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmp_m7i82an/test.o -laio -o /tmp/tmp_m7i82an/a.out\n",
      "[2024-10-23 10:00:44,781] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 10:00:44,782] [INFO] [root.spawn:60] [PID:352188] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmp_w7ky9lk/test.o -laio -o /tmp/tmp_w7ky9lk/a.out\n",
      "[2024-10-23 10:00:44,812] [INFO] [root.spawn:60] [PID:352187] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpypjlmxpg/test.c -o /tmp/tmpypjlmxpg/test.o\n",
      "[2024-10-23 10:00:44,825] [INFO] [root.spawn:60] [PID:352187] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpypjlmxpg/test.o -laio -o /tmp/tmpypjlmxpg/a.out\n",
      "[2024-10-23 10:00:44,886] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 10:00:44,918] [INFO] [root.spawn:60] [PID:352191] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmp3ybfw16c/test.c -o /tmp/tmp3ybfw16c/test.o\n",
      "[2024-10-23 10:00:44,933] [INFO] [root.spawn:60] [PID:352191] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmp3ybfw16c/test.o -laio -o /tmp/tmp3ybfw16c/a.out\n",
      "[2024-10-23 10:00:44,943] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 10:00:44,973] [INFO] [root.spawn:60] [PID:352193] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmp8qml6slw/test.c -o /tmp/tmp8qml6slw/test.o\n",
      "[2024-10-23 10:00:44,978] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 10:00:44,988] [INFO] [root.spawn:60] [PID:352193] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmp8qml6slw/test.o -laio -o /tmp/tmp8qml6slw/a.out\n",
      "[2024-10-23 10:00:45,008] [INFO] [root.spawn:60] [PID:352194] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpy69684on/test.c -o /tmp/tmpy69684on/test.o\n",
      "[2024-10-23 10:00:45,022] [INFO] [root.spawn:60] [PID:352194] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpy69684on/test.o -laio -o /tmp/tmpy69684on/a.out\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "[2024-10-23 10:00:45,920] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:352189] [RANK:2] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 10:00:45,921] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:352192] [RANK:5] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 10:00:45,923] [DEBUG] [axolotl.normalize_config:83] [PID:352189] [RANK:2] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 10:00:45,923] [DEBUG] [axolotl.normalize_config:83] [PID:352192] [RANK:5] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 10:00:45,927] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:352188] [RANK:1] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 10:00:45,928] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:352190] [RANK:3] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 10:00:45,930] [DEBUG] [axolotl.normalize_config:83] [PID:352188] [RANK:1] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 10:00:45,930] [DEBUG] [axolotl.normalize_config:83] [PID:352190] [RANK:3] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 10:00:46,036] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:352187] [RANK:0] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 10:00:46,039] [DEBUG] [axolotl.normalize_config:83] [PID:352187] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 10:00:46,101] [INFO] [axolotl.normalize_config:207] [PID:352192] [RANK:5] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 10:00:46,101] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:352192] [RANK:5] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 10:00:46,103] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 10:00:46,112] [INFO] [axolotl.normalize_config:207] [PID:352190] [RANK:3] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 10:00:46,112] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:352190] [RANK:3] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 10:00:46,113] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 10:00:46,116] [INFO] [axolotl.normalize_config:207] [PID:352188] [RANK:1] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 10:00:46,116] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:352188] [RANK:1] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 10:00:46,119] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 10:00:46,123] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:352193] [RANK:6] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 10:00:46,125] [INFO] [axolotl.normalize_config:207] [PID:352189] [RANK:2] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 10:00:46,125] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:352189] [RANK:2] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 10:00:46,125] [DEBUG] [axolotl.normalize_config:83] [PID:352193] [RANK:6] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 10:00:46,127] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 10:00:46,151] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:352191] [RANK:4] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 10:00:46,153] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:352194] [RANK:7] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 10:00:46,153] [DEBUG] [axolotl.normalize_config:83] [PID:352191] [RANK:4] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 10:00:46,155] [DEBUG] [axolotl.normalize_config:83] [PID:352194] [RANK:7] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 10:00:46,175] [INFO] [axolotl.normalize_config:207] [PID:352187] [RANK:0] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 10:00:46,175] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:352187] [RANK:0] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 10:00:46,177] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 10:00:46,177] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2024-10-23 10:00:46,257] [INFO] [axolotl.normalize_config:207] [PID:352193] [RANK:6] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 10:00:46,257] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:352193] [RANK:6] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 10:00:46,259] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 10:00:46,278] [INFO] [axolotl.normalize_config:207] [PID:352194] [RANK:7] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 10:00:46,279] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:352194] [RANK:7] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 10:00:46,280] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 10:00:46,281] [INFO] [axolotl.normalize_config:207] [PID:352191] [RANK:4] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 10:00:46,281] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:352191] [RANK:4] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 10:00:46,283] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 10:00:46,783] [DEBUG] [axolotl.load_tokenizer:290] [PID:352189] [RANK:2] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:46,783] [DEBUG] [axolotl.load_tokenizer:291] [PID:352189] [RANK:2] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,783] [DEBUG] [axolotl.load_tokenizer:292] [PID:352189] [RANK:2] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,783] [DEBUG] [axolotl.load_tokenizer:293] [PID:352189] [RANK:2] UNK: None / None\u001b[39m\n",
      "[rank2]:[W1023 10:00:46.890078348 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 10:00:46,805] [DEBUG] [axolotl.load_tokenizer:290] [PID:352190] [RANK:3] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:46,805] [DEBUG] [axolotl.load_tokenizer:291] [PID:352190] [RANK:3] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,805] [DEBUG] [axolotl.load_tokenizer:292] [PID:352190] [RANK:3] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,805] [DEBUG] [axolotl.load_tokenizer:293] [PID:352190] [RANK:3] UNK: None / None\u001b[39m\n",
      "[rank3]:[W1023 10:00:46.911760999 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 10:00:46,810] [DEBUG] [axolotl.load_tokenizer:290] [PID:352192] [RANK:5] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:46,810] [DEBUG] [axolotl.load_tokenizer:291] [PID:352192] [RANK:5] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,810] [DEBUG] [axolotl.load_tokenizer:292] [PID:352192] [RANK:5] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,810] [DEBUG] [axolotl.load_tokenizer:293] [PID:352192] [RANK:5] UNK: None / None\u001b[39m\n",
      "[rank5]:[W1023 10:00:46.916697732 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 10:00:46,906] [DEBUG] [axolotl.load_tokenizer:290] [PID:352188] [RANK:1] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:46,906] [DEBUG] [axolotl.load_tokenizer:291] [PID:352188] [RANK:1] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,906] [DEBUG] [axolotl.load_tokenizer:292] [PID:352188] [RANK:1] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,906] [DEBUG] [axolotl.load_tokenizer:293] [PID:352188] [RANK:1] UNK: None / None\u001b[39m\n",
      "[rank1]:[W1023 10:00:46.012487282 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 10:00:46,908] [DEBUG] [axolotl.load_tokenizer:290] [PID:352187] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:46,908] [DEBUG] [axolotl.load_tokenizer:291] [PID:352187] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,908] [DEBUG] [axolotl.load_tokenizer:292] [PID:352187] [RANK:0] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,908] [DEBUG] [axolotl.load_tokenizer:293] [PID:352187] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-10-23 10:00:46,909] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:352187] [RANK:0] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 10:00:46,915] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:352187] [RANK:0] Prepared dataset loaded from disk...\u001b[39m\n",
      "[rank0]:[W1023 10:00:46.042902469 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 10:00:46,989] [DEBUG] [axolotl.load_tokenizer:290] [PID:352194] [RANK:7] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:46,989] [DEBUG] [axolotl.load_tokenizer:291] [PID:352194] [RANK:7] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,989] [DEBUG] [axolotl.load_tokenizer:292] [PID:352194] [RANK:7] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:46,989] [DEBUG] [axolotl.load_tokenizer:293] [PID:352194] [RANK:7] UNK: None / None\u001b[39m\n",
      "[rank7]:[W1023 10:00:46.096204627 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 10:00:47,050] [DEBUG] [axolotl.load_tokenizer:290] [PID:352191] [RANK:4] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:47,050] [DEBUG] [axolotl.load_tokenizer:291] [PID:352191] [RANK:4] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:47,050] [DEBUG] [axolotl.load_tokenizer:292] [PID:352191] [RANK:4] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:47,050] [DEBUG] [axolotl.load_tokenizer:293] [PID:352191] [RANK:4] UNK: None / None\u001b[39m\n",
      "[rank4]:[W1023 10:00:47.156898978 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 10:00:47,060] [DEBUG] [axolotl.load_tokenizer:290] [PID:352193] [RANK:6] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:47,061] [DEBUG] [axolotl.load_tokenizer:291] [PID:352193] [RANK:6] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:47,061] [DEBUG] [axolotl.load_tokenizer:292] [PID:352193] [RANK:6] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:47,061] [DEBUG] [axolotl.load_tokenizer:293] [PID:352193] [RANK:6] UNK: None / None\u001b[39m\n",
      "[rank6]:[W1023 10:00:47.167365483 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 10:00:48,203] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:352193] [RANK:6] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 10:00:48,204] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:352189] [RANK:2] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 10:00:48,204] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:352194] [RANK:7] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 10:00:48,204] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:352192] [RANK:5] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 10:00:48,204] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:352191] [RANK:4] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 10:00:48,205] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:352188] [RANK:1] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 10:00:48,205] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:352190] [RANK:3] Loading prepared dataset from disk at last_run_prepared/0aa53633c446d584533a032a68222d60...\u001b[39m\n",
      "[2024-10-23 10:00:48,210] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:352193] [RANK:6] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 10:00:48,211] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:352189] [RANK:2] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 10:00:48,212] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:352192] [RANK:5] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 10:00:48,219] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:352194] [RANK:7] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 10:00:48,219] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:352191] [RANK:4] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 10:00:48,223] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:352190] [RANK:3] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 10:00:48,224] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:352188] [RANK:1] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 10:00:48,284] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:352187] [RANK:0] total_num_tokens: 15_537_156\u001b[39m\n",
      "[2024-10-23 10:00:48,433] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:352187] [RANK:0] `total_supervised_tokens: 7_583_970`\u001b[39m\n",
      "[2024-10-23 10:00:52,326] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "[2024-10-23 10:00:52,326] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:352187] [RANK:0] data_loader_len: 30\u001b[39m\n",
      "[2024-10-23 10:00:52,339] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:352187] [RANK:0] sample_packing_eff_est across ranks: [0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572, 0.9837269186973572]\u001b[39m\n",
      "[2024-10-23 10:00:52,339] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:352187] [RANK:0] sample_packing_eff_est: None\u001b[39m\n",
      "[2024-10-23 10:00:52,339] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:352187] [RANK:0] total_num_steps: 90\u001b[39m\n",
      "[2024-10-23 10:00:52,619] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:352187] [RANK:0] total_num_tokens: 79_721_158\u001b[39m\n",
      "[2024-10-23 10:00:54,002] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:352187] [RANK:0] `total_supervised_tokens: 39_365_516`\u001b[39m\n",
      "[2024-10-23 10:00:54,184] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [1227, 1226, 1226, 1226, 1226, 1226, 1226, 1226]\u001b[39m\n",
      "[2024-10-23 10:00:54,185] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:352187] [RANK:0] data_loader_len: 152\u001b[39m\n",
      "[2024-10-23 10:00:54,185] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:352187] [RANK:0] sample_packing_eff_est across ranks: [0.991400420665741, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087, 0.9922090768814087]\u001b[39m\n",
      "[2024-10-23 10:00:54,186] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:352187] [RANK:0] sample_packing_eff_est: 1.0\u001b[39m\n",
      "[2024-10-23 10:00:54,186] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:352187] [RANK:0] total_num_steps: 456\u001b[39m\n",
      "[2024-10-23 10:00:54,211] [DEBUG] [axolotl.train.train:66] [PID:352187] [RANK:0] loading tokenizer... meta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39m\n",
      "[2024-10-23 10:00:54,752] [DEBUG] [axolotl.load_tokenizer:290] [PID:352187] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:54,752] [DEBUG] [axolotl.load_tokenizer:291] [PID:352187] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,752] [DEBUG] [axolotl.load_tokenizer:292] [PID:352187] [RANK:0] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,752] [DEBUG] [axolotl.load_tokenizer:293] [PID:352187] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-10-23 10:00:54,752] [DEBUG] [axolotl.train.train:98] [PID:352187] [RANK:0] loading model\u001b[39m\n",
      "[2024-10-23 10:00:54,788] [DEBUG] [axolotl.load_tokenizer:290] [PID:352189] [RANK:2] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:54,788] [DEBUG] [axolotl.load_tokenizer:291] [PID:352189] [RANK:2] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,788] [DEBUG] [axolotl.load_tokenizer:292] [PID:352189] [RANK:2] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,788] [DEBUG] [axolotl.load_tokenizer:293] [PID:352189] [RANK:2] UNK: None / None\u001b[39m\n",
      "[2024-10-23 10:00:54,791] [DEBUG] [axolotl.load_tokenizer:290] [PID:352191] [RANK:4] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:54,791] [DEBUG] [axolotl.load_tokenizer:291] [PID:352191] [RANK:4] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,792] [DEBUG] [axolotl.load_tokenizer:292] [PID:352191] [RANK:4] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,792] [DEBUG] [axolotl.load_tokenizer:293] [PID:352191] [RANK:4] UNK: None / None\u001b[39m\n",
      "[2024-10-23 10:00:54,799] [DEBUG] [axolotl.load_tokenizer:290] [PID:352188] [RANK:1] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:54,800] [DEBUG] [axolotl.load_tokenizer:291] [PID:352188] [RANK:1] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,800] [DEBUG] [axolotl.load_tokenizer:292] [PID:352188] [RANK:1] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,800] [DEBUG] [axolotl.load_tokenizer:293] [PID:352188] [RANK:1] UNK: None / None\u001b[39m\n",
      "[2024-10-23 10:00:54,811] [DEBUG] [axolotl.load_tokenizer:290] [PID:352193] [RANK:6] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:54,812] [DEBUG] [axolotl.load_tokenizer:291] [PID:352193] [RANK:6] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,812] [DEBUG] [axolotl.load_tokenizer:292] [PID:352193] [RANK:6] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,812] [DEBUG] [axolotl.load_tokenizer:293] [PID:352193] [RANK:6] UNK: None / None\u001b[39m\n",
      "[2024-10-23 10:00:54,890] [DEBUG] [axolotl.load_tokenizer:290] [PID:352192] [RANK:5] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:54,890] [DEBUG] [axolotl.load_tokenizer:291] [PID:352192] [RANK:5] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,890] [DEBUG] [axolotl.load_tokenizer:292] [PID:352192] [RANK:5] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,890] [DEBUG] [axolotl.load_tokenizer:293] [PID:352192] [RANK:5] UNK: None / None\u001b[39m\n",
      "[2024-10-23 10:00:54,905] [DEBUG] [axolotl.load_tokenizer:290] [PID:352190] [RANK:3] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:54,905] [DEBUG] [axolotl.load_tokenizer:291] [PID:352190] [RANK:3] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,905] [DEBUG] [axolotl.load_tokenizer:292] [PID:352190] [RANK:3] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,905] [DEBUG] [axolotl.load_tokenizer:293] [PID:352190] [RANK:3] UNK: None / None\u001b[39m\n",
      "[2024-10-23 10:00:54,906] [DEBUG] [axolotl.load_tokenizer:290] [PID:352194] [RANK:7] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 10:00:54,906] [DEBUG] [axolotl.load_tokenizer:291] [PID:352194] [RANK:7] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,906] [DEBUG] [axolotl.load_tokenizer:292] [PID:352194] [RANK:7] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 10:00:54,906] [DEBUG] [axolotl.load_tokenizer:293] [PID:352194] [RANK:7] UNK: None / None\u001b[39m\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:08<00:00,  2.12s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:08<00:00,  2.10s/it]\n",
      "[2024-10-23 10:01:03,920] [INFO] [axolotl.load_model:855] [PID:352191] [RANK:4] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 10:01:03,924] [INFO] [axolotl.load_model:922] [PID:352191] [RANK:4] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 10:01:04,000] [INFO] [axolotl.load_model:855] [PID:352187] [RANK:0] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 10:01:04,004] [INFO] [axolotl.load_model:922] [PID:352187] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:08<00:00,  2.17s/it]\n",
      "[2024-10-23 10:01:04,346] [INFO] [axolotl.load_model:855] [PID:352190] [RANK:3] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 10:01:04,351] [INFO] [axolotl.load_model:922] [PID:352190] [RANK:3] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:08<00:00,  2.24s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:08<00:00,  2.23s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09<00:00,  2.25s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09<00:00,  2.30s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09<00:00,  2.29s/it]\n",
      "[2024-10-23 10:01:04,532] [INFO] [axolotl.load_model:855] [PID:352192] [RANK:5] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 10:01:04,538] [INFO] [axolotl.load_model:922] [PID:352192] [RANK:5] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 10:01:04,584] [INFO] [axolotl.load_model:855] [PID:352193] [RANK:6] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 10:01:04,588] [INFO] [axolotl.load_model:922] [PID:352193] [RANK:6] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 10:01:04,630] [INFO] [axolotl.load_model:855] [PID:352189] [RANK:2] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 10:01:04,634] [INFO] [axolotl.load_model:922] [PID:352189] [RANK:2] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 10:01:04,656] [INFO] [axolotl.load_model:855] [PID:352188] [RANK:1] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 10:01:04,660] [INFO] [axolotl.load_model:855] [PID:352194] [RANK:7] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-10-23 10:01:04,661] [INFO] [axolotl.load_model:922] [PID:352188] [RANK:1] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 10:01:04,664] [INFO] [axolotl.load_model:922] [PID:352194] [RANK:7] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-10-23 10:01:04,972] [INFO] [axolotl.train.train:178] [PID:352187] [RANK:0] Starting trainer...\u001b[39m\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-10-23 10:01:06,098] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [1226, 1226, 1226, 1226, 1226, 1226, 1226, 1226]\u001b[39m\n",
      "[2024-10-23 10:01:06,445] [WARNING] [engine.py:1232:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrandomfoo\u001b[0m (\u001b[33maugmxnt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/nvme1n1p1/MI300-testing/wandb/run-20241023_100110-u7aqh88l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmi300x-shisa-llama3.1-8b-v1-dsz3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/augmxnt/shisa-v2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/augmxnt/shisa-v2/runs/u7aqh88l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "[2024-10-23 10:01:10,813] [INFO] [axolotl.callbacks.on_train_begin:794] [PID:352187] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
      "  0%|                                                   | 0/456 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.1231, 'grad_norm': 3.810771708481832, 'learning_rate': 8e-08, 'epoch': 0.01}\n",
      "  0%|                                         | 1/456 [00:28<3:33:39, 28.17s/it][2024-10-23 10:01:39,000] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:02<00:38,  1.39s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:55,  2.04s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:08<01:02,  2.38s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:11<01:06,  2.66s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:14<01:06,  2.78s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:06,  2.91s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:05,  2.98s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:39<02:43,  7.77s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:42<02:06,  6.32s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:45<01:41,  5.32s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:48<01:23,  4.62s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:51<01:10,  4.14s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:54<01:01,  3.84s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:57<00:53,  3.60s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [01:00<00:47,  3.42s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [01:04<00:42,  3.30s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [01:06<00:38,  3.21s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [01:10<00:34,  3.15s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [01:13<00:31,  3.11s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:16<00:27,  3.09s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:19<00:24,  3.07s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:22<00:21,  3.09s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:25<00:18,  3.13s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:28<00:15,  3.17s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:31<00:12,  3.17s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:35<00:09,  3.20s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:38<00:06,  3.21s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:41<00:03,  3.20s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6680425405502319, 'eval_runtime': 108.1712, 'eval_samples_per_second': 86.872, 'eval_steps_per_second': 1.359, 'epoch': 0.01}\n",
      "  0%|                                         | 1/456 [02:16<3:33:39, 28.17s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.21s/it]\u001b[A\n",
      "                                                                                \u001b[A[2024-10-23 10:03:41,315] [INFO] [axolotl.callbacks.on_step_end:128] [PID:352194] [RANK:7] GPU memory usage while training: 7.516GB (+140.554GB cache)\u001b[39m\n",
      "[2024-10-23 10:03:41,316] [INFO] [axolotl.callbacks.on_step_end:128] [PID:352188] [RANK:1] GPU memory usage while training: 7.516GB (+140.554GB cache)\u001b[39m\n",
      "[2024-10-23 10:03:41,316] [INFO] [axolotl.callbacks.on_step_end:128] [PID:352189] [RANK:2] GPU memory usage while training: 7.516GB (+139.685GB cache)\u001b[39m\n",
      "[2024-10-23 10:03:41,316] [INFO] [axolotl.callbacks.on_step_end:128] [PID:352187] [RANK:0] GPU memory usage while training: 7.516GB (+140.445GB cache)\u001b[39m\n",
      "[2024-10-23 10:03:41,316] [INFO] [axolotl.callbacks.on_step_end:128] [PID:352192] [RANK:5] GPU memory usage while training: 7.516GB (+140.554GB cache)\u001b[39m\n",
      "[2024-10-23 10:03:41,316] [INFO] [axolotl.callbacks.on_step_end:128] [PID:352191] [RANK:4] GPU memory usage while training: 7.516GB (+140.445GB cache)\u001b[39m\n",
      "  0%|▏                                       | 2/456 [02:30<10:32:15, 83.56s/it][2024-10-23 10:03:41,317] [INFO] [axolotl.callbacks.on_step_end:128] [PID:352190] [RANK:3] GPU memory usage while training: 7.516GB (+140.226GB cache)\u001b[39m\n",
      "[2024-10-23 10:03:41,319] [INFO] [axolotl.callbacks.on_step_end:128] [PID:352193] [RANK:6] GPU memory usage while training: 7.516GB (+139.685GB cache)\u001b[39m\n",
      "{'loss': 1.1024, 'grad_norm': 3.8260986193265154, 'learning_rate': 1.6e-07, 'epoch': 0.01}\n",
      "{'loss': 1.0876, 'grad_norm': 3.7916908960381206, 'learning_rate': 2.4e-07, 'epoch': 0.02}\n",
      "{'loss': 1.0527, 'grad_norm': 3.731657248141128, 'learning_rate': 3.2e-07, 'epoch': 0.03}\n",
      "{'loss': 1.0441, 'grad_norm': 3.6802431909679156, 'learning_rate': 4e-07, 'epoch': 0.03}\n",
      "{'loss': 1.0559, 'grad_norm': 3.958100466283791, 'learning_rate': 4.8e-07, 'epoch': 0.04}\n",
      "{'loss': 1.0924, 'grad_norm': 3.7182157351371776, 'learning_rate': 5.6e-07, 'epoch': 0.05}\n",
      "{'loss': 1.1011, 'grad_norm': 3.4613368865243164, 'learning_rate': 6.4e-07, 'epoch': 0.05}\n",
      "{'loss': 1.052, 'grad_norm': 3.154375914237655, 'learning_rate': 7.2e-07, 'epoch': 0.06}\n",
      "{'loss': 1.086, 'grad_norm': 2.9309316070070595, 'learning_rate': 8e-07, 'epoch': 0.07}\n",
      "{'loss': 1.0805, 'grad_norm': 2.8958249919259416, 'learning_rate': 8.799999999999999e-07, 'epoch': 0.07}\n",
      "{'loss': 1.0922, 'grad_norm': 1.843016399541072, 'learning_rate': 9.6e-07, 'epoch': 0.08}\n",
      "{'loss': 1.0193, 'grad_norm': 1.8439227017431772, 'learning_rate': 1.04e-06, 'epoch': 0.09}\n",
      "{'loss': 1.0895, 'grad_norm': 1.7930692790844964, 'learning_rate': 1.12e-06, 'epoch': 0.09}\n",
      "{'loss': 1.0575, 'grad_norm': 1.7077764715446717, 'learning_rate': 1.2e-06, 'epoch': 0.1}\n",
      "{'loss': 1.0724, 'grad_norm': 1.7989319488125692, 'learning_rate': 1.28e-06, 'epoch': 0.11}\n",
      "{'loss': 1.0016, 'grad_norm': 1.8055652303683145, 'learning_rate': 1.3600000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 0.9844, 'grad_norm': 1.895403077654944, 'learning_rate': 1.44e-06, 'epoch': 0.12}\n",
      "{'loss': 1.0307, 'grad_norm': 1.6341187810705928, 'learning_rate': 1.5199999999999998e-06, 'epoch': 0.12}\n",
      "{'loss': 1.0144, 'grad_norm': 1.389261850884466, 'learning_rate': 1.6e-06, 'epoch': 0.13}\n",
      "{'loss': 1.0368, 'grad_norm': 1.068855674433568, 'learning_rate': 1.6799999999999998e-06, 'epoch': 0.14}\n",
      "{'loss': 0.9858, 'grad_norm': 1.0420875687289528, 'learning_rate': 1.7599999999999999e-06, 'epoch': 0.14}\n",
      "{'loss': 1.0352, 'grad_norm': 1.4655738805528604, 'learning_rate': 1.84e-06, 'epoch': 0.15}\n",
      "{'loss': 1.1055, 'grad_norm': 1.569497497585117, 'learning_rate': 1.92e-06, 'epoch': 0.16}\n",
      "{'loss': 1.0051, 'grad_norm': 1.188458118217756, 'learning_rate': 2e-06, 'epoch': 0.16}\n",
      "{'loss': 0.9953, 'grad_norm': 0.9677397384409262, 'learning_rate': 2.08e-06, 'epoch': 0.17}\n",
      "{'loss': 0.9925, 'grad_norm': 0.9435339697491455, 'learning_rate': 2.16e-06, 'epoch': 0.18}\n",
      "{'loss': 1.0187, 'grad_norm': 0.9857424494564165, 'learning_rate': 2.24e-06, 'epoch': 0.18}\n",
      "{'loss': 0.9518, 'grad_norm': 0.9689667995138942, 'learning_rate': 2.32e-06, 'epoch': 0.19}\n",
      "{'loss': 0.954, 'grad_norm': 1.120399354260397, 'learning_rate': 2.4e-06, 'epoch': 0.2}\n",
      "{'loss': 1.024, 'grad_norm': 0.8953462553464734, 'learning_rate': 2.48e-06, 'epoch': 0.2}\n",
      "{'loss': 0.9946, 'grad_norm': 0.8622578696947535, 'learning_rate': 2.56e-06, 'epoch': 0.21}\n",
      "{'loss': 0.9884, 'grad_norm': 0.8555010979749452, 'learning_rate': 2.64e-06, 'epoch': 0.22}\n",
      "{'loss': 0.968, 'grad_norm': 0.94300638007051, 'learning_rate': 2.7200000000000002e-06, 'epoch': 0.22}\n",
      "{'loss': 0.9456, 'grad_norm': 0.9486961053990846, 'learning_rate': 2.8e-06, 'epoch': 0.23}\n",
      "{'loss': 0.9548, 'grad_norm': 0.8357745900334946, 'learning_rate': 2.88e-06, 'epoch': 0.24}\n",
      "{'loss': 0.9912, 'grad_norm': 0.8383600117050769, 'learning_rate': 2.96e-06, 'epoch': 0.24}\n",
      "{'loss': 0.913, 'grad_norm': 0.885716752169551, 'learning_rate': 3.0399999999999997e-06, 'epoch': 0.25}\n",
      "{'loss': 0.9007, 'grad_norm': 0.9073250960379063, 'learning_rate': 3.1199999999999998e-06, 'epoch': 0.26}\n",
      "{'loss': 0.9803, 'grad_norm': 0.8269454778457094, 'learning_rate': 3.2e-06, 'epoch': 0.26}\n",
      "{'loss': 0.9502, 'grad_norm': 0.7582888516608502, 'learning_rate': 3.2799999999999995e-06, 'epoch': 0.27}\n",
      "{'loss': 0.9394, 'grad_norm': 0.858741092582963, 'learning_rate': 3.3599999999999996e-06, 'epoch': 0.28}\n",
      "{'loss': 0.9621, 'grad_norm': 0.8144898440328608, 'learning_rate': 3.4399999999999997e-06, 'epoch': 0.28}\n",
      "{'loss': 0.9625, 'grad_norm': 0.7463067224948884, 'learning_rate': 3.5199999999999998e-06, 'epoch': 0.29}\n",
      "{'loss': 0.9987, 'grad_norm': 0.7815322043812235, 'learning_rate': 3.6e-06, 'epoch': 0.3}\n",
      "{'loss': 0.9256, 'grad_norm': 0.8761346991990605, 'learning_rate': 3.68e-06, 'epoch': 0.3}\n",
      "{'loss': 0.9419, 'grad_norm': 0.7689253322847045, 'learning_rate': 3.7599999999999996e-06, 'epoch': 0.31}\n",
      "{'loss': 0.9601, 'grad_norm': 0.7818199237324256, 'learning_rate': 3.84e-06, 'epoch': 0.32}\n",
      "{'loss': 0.9718, 'grad_norm': 0.7995643273251641, 'learning_rate': 3.92e-06, 'epoch': 0.32}\n",
      "{'loss': 0.9356, 'grad_norm': 0.871460370138328, 'learning_rate': 4e-06, 'epoch': 0.33}\n",
      "{'loss': 0.954, 'grad_norm': 0.8495186389093514, 'learning_rate': 4.08e-06, 'epoch': 0.34}\n",
      "{'loss': 0.9303, 'grad_norm': 0.8485314427746022, 'learning_rate': 4.16e-06, 'epoch': 0.34}\n",
      "{'loss': 0.9307, 'grad_norm': 0.8023910780185567, 'learning_rate': 4.24e-06, 'epoch': 0.35}\n",
      "{'loss': 0.8684, 'grad_norm': 0.7585710567146507, 'learning_rate': 4.32e-06, 'epoch': 0.36}\n",
      "{'loss': 0.9468, 'grad_norm': 0.7439745222897229, 'learning_rate': 4.4e-06, 'epoch': 0.36}\n",
      "{'loss': 0.9135, 'grad_norm': 0.7346812553889026, 'learning_rate': 4.48e-06, 'epoch': 0.37}\n",
      "{'loss': 0.8886, 'grad_norm': 0.759352410702518, 'learning_rate': 4.5599999999999995e-06, 'epoch': 0.38}\n",
      "{'loss': 0.9679, 'grad_norm': 0.7424205839364665, 'learning_rate': 4.64e-06, 'epoch': 0.38}\n",
      "{'loss': 0.9361, 'grad_norm': 0.7481675433521283, 'learning_rate': 4.72e-06, 'epoch': 0.39}\n",
      "{'loss': 0.8284, 'grad_norm': 0.7249748629054433, 'learning_rate': 4.8e-06, 'epoch': 0.39}\n",
      "{'loss': 0.9606, 'grad_norm': 0.7578522969085868, 'learning_rate': 4.88e-06, 'epoch': 0.4}\n",
      "{'loss': 0.9525, 'grad_norm': 0.753257376491397, 'learning_rate': 4.96e-06, 'epoch': 0.41}\n",
      "{'loss': 0.9117, 'grad_norm': 0.7826956283503463, 'learning_rate': 5.04e-06, 'epoch': 0.41}\n",
      "{'loss': 0.8587, 'grad_norm': 0.7455496552024637, 'learning_rate': 5.12e-06, 'epoch': 0.42}\n",
      "{'loss': 0.9264, 'grad_norm': 0.7640617049574896, 'learning_rate': 5.2e-06, 'epoch': 0.43}\n",
      "{'loss': 0.8878, 'grad_norm': 0.7326064050897986, 'learning_rate': 5.28e-06, 'epoch': 0.43}\n",
      "{'loss': 0.8797, 'grad_norm': 0.7309398724215206, 'learning_rate': 5.36e-06, 'epoch': 0.44}\n",
      "{'loss': 0.938, 'grad_norm': 0.7521749114763088, 'learning_rate': 5.4400000000000004e-06, 'epoch': 0.45}\n",
      "{'loss': 0.9122, 'grad_norm': 0.7275812718372016, 'learning_rate': 5.52e-06, 'epoch': 0.45}\n",
      "{'loss': 0.888, 'grad_norm': 0.7594045197552621, 'learning_rate': 5.6e-06, 'epoch': 0.46}\n",
      "{'loss': 0.9766, 'grad_norm': 0.7692187401158344, 'learning_rate': 5.68e-06, 'epoch': 0.47}\n",
      "{'loss': 0.9191, 'grad_norm': 0.7461473413770735, 'learning_rate': 5.76e-06, 'epoch': 0.47}\n",
      "{'loss': 0.8878, 'grad_norm': 0.7587100205615985, 'learning_rate': 5.84e-06, 'epoch': 0.48}\n",
      "{'loss': 0.8774, 'grad_norm': 0.7394747845328686, 'learning_rate': 5.92e-06, 'epoch': 0.49}\n",
      "{'loss': 0.8303, 'grad_norm': 0.7226137789700355, 'learning_rate': 6e-06, 'epoch': 0.49}\n",
      "{'loss': 0.9512, 'grad_norm': 0.7890724588772259, 'learning_rate': 6.079999999999999e-06, 'epoch': 0.5}\n",
      " 17%|██████▋                                 | 76/456 [17:33<1:17:06, 12.18s/it][2024-10-23 10:18:43,922] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:42,  1.52s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:06<00:58,  2.15s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:09<01:04,  2.48s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:12<01:07,  2.69s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:08,  2.85s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:07,  2.94s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:06,  3.03s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:05,  3.10s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:28<01:02,  3.14s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:31<00:59,  3.13s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:34<00:56,  3.16s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:37<00:53,  3.17s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:40<00:50,  3.18s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:44<00:47,  3.18s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:47<00:44,  3.20s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:50<00:41,  3.20s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:53<00:38,  3.21s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:57<00:35,  3.22s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [01:00<00:32,  3.20s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:03<00:29,  3.23s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:06<00:25,  3.19s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:09<00:22,  3.19s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:13<00:19,  3.20s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:16<00:16,  3.22s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:19<00:12,  3.22s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:22<00:09,  3.21s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:25<00:06,  3.21s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:29<00:03,  3.21s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.5473420023918152, 'eval_runtime': 95.395, 'eval_samples_per_second': 98.506, 'eval_steps_per_second': 1.541, 'epoch': 0.5}\n",
      " 17%|██████▋                                 | 76/456 [19:08<1:17:06, 12.18s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:32<00:00,  3.21s/it]\u001b[A\n",
      "{'loss': 0.8503, 'grad_norm': 0.7372192537742464, 'learning_rate': 6.1599999999999995e-06, 'epoch': 0.51}\n",
      "{'loss': 0.9298, 'grad_norm': 0.7986343878925285, 'learning_rate': 6.2399999999999995e-06, 'epoch': 0.51}\n",
      "{'loss': 0.9244, 'grad_norm': 0.7512840661318971, 'learning_rate': 6.32e-06, 'epoch': 0.52}\n",
      "{'loss': 0.8215, 'grad_norm': 0.6912220793430848, 'learning_rate': 6.4e-06, 'epoch': 0.53}\n",
      "{'loss': 0.8981, 'grad_norm': 0.7446427153411692, 'learning_rate': 6.48e-06, 'epoch': 0.53}\n",
      "{'loss': 0.8886, 'grad_norm': 0.7179744768971975, 'learning_rate': 6.559999999999999e-06, 'epoch': 0.54}\n",
      "{'loss': 0.8552, 'grad_norm': 0.7265990218124267, 'learning_rate': 6.639999999999999e-06, 'epoch': 0.55}\n",
      "{'loss': 0.8541, 'grad_norm': 0.6921891300380257, 'learning_rate': 6.719999999999999e-06, 'epoch': 0.55}\n",
      "{'loss': 0.9464, 'grad_norm': 0.8312927685743973, 'learning_rate': 6.799999999999999e-06, 'epoch': 0.56}\n",
      "{'loss': 0.8455, 'grad_norm': 0.6907948076287518, 'learning_rate': 6.879999999999999e-06, 'epoch': 0.57}\n",
      "{'loss': 0.88, 'grad_norm': 0.7676862108228534, 'learning_rate': 6.9599999999999994e-06, 'epoch': 0.57}\n",
      "{'loss': 0.8681, 'grad_norm': 0.7506113099077681, 'learning_rate': 7.0399999999999995e-06, 'epoch': 0.58}\n",
      "{'loss': 0.8987, 'grad_norm': 1.3489515718605838, 'learning_rate': 7.12e-06, 'epoch': 0.59}\n",
      "{'loss': 0.884, 'grad_norm': 0.7437532835439662, 'learning_rate': 7.2e-06, 'epoch': 0.59}\n",
      "{'loss': 0.8763, 'grad_norm': 0.7896650387770089, 'learning_rate': 7.28e-06, 'epoch': 0.6}\n",
      "{'loss': 0.8528, 'grad_norm': 0.7279241638532741, 'learning_rate': 7.36e-06, 'epoch': 0.61}\n",
      "{'loss': 0.8526, 'grad_norm': 0.717545559651297, 'learning_rate': 7.44e-06, 'epoch': 0.61}\n",
      "{'loss': 0.8927, 'grad_norm': 0.7836993488360582, 'learning_rate': 7.519999999999999e-06, 'epoch': 0.62}\n",
      "{'loss': 0.8576, 'grad_norm': 0.767390879431632, 'learning_rate': 7.599999999999999e-06, 'epoch': 0.62}\n",
      "{'loss': 0.8707, 'grad_norm': 0.731796130942584, 'learning_rate': 7.68e-06, 'epoch': 0.63}\n",
      "{'loss': 0.9047, 'grad_norm': 0.7521904202850461, 'learning_rate': 7.76e-06, 'epoch': 0.64}\n",
      "{'loss': 0.8558, 'grad_norm': 0.7707379978168465, 'learning_rate': 7.84e-06, 'epoch': 0.64}\n",
      "{'loss': 0.8445, 'grad_norm': 0.7291115429841633, 'learning_rate': 7.92e-06, 'epoch': 0.65}\n",
      "{'loss': 0.8814, 'grad_norm': 0.7584376751423608, 'learning_rate': 8e-06, 'epoch': 0.66}\n",
      "{'loss': 0.8395, 'grad_norm': 0.7596139414332818, 'learning_rate': 7.97752808988764e-06, 'epoch': 0.66}\n",
      "{'loss': 0.8834, 'grad_norm': 0.793004555454223, 'learning_rate': 7.95505617977528e-06, 'epoch': 0.67}\n",
      "{'loss': 0.8421, 'grad_norm': 0.7357948127448019, 'learning_rate': 7.93258426966292e-06, 'epoch': 0.68}\n",
      "{'loss': 0.9006, 'grad_norm': 0.8111073639511072, 'learning_rate': 7.910112359550562e-06, 'epoch': 0.68}\n",
      "{'loss': 0.8888, 'grad_norm': 0.764054822489099, 'learning_rate': 7.887640449438203e-06, 'epoch': 0.69}\n",
      "{'loss': 0.9016, 'grad_norm': 0.746765823299203, 'learning_rate': 7.865168539325842e-06, 'epoch': 0.7}\n",
      "{'loss': 0.8814, 'grad_norm': 0.7771805816430373, 'learning_rate': 7.842696629213483e-06, 'epoch': 0.7}\n",
      "{'loss': 0.8466, 'grad_norm': 0.7307827058077363, 'learning_rate': 7.820224719101124e-06, 'epoch': 0.71}\n",
      "{'loss': 0.871, 'grad_norm': 0.816104075957893, 'learning_rate': 7.797752808988764e-06, 'epoch': 0.72}\n",
      "{'loss': 0.8472, 'grad_norm': 0.7376232199161638, 'learning_rate': 7.775280898876404e-06, 'epoch': 0.72}\n",
      "{'loss': 0.8862, 'grad_norm': 0.8024087974785326, 'learning_rate': 7.752808988764045e-06, 'epoch': 0.73}\n",
      "{'loss': 0.842, 'grad_norm': 0.7151206526456709, 'learning_rate': 7.730337078651686e-06, 'epoch': 0.74}\n",
      "{'loss': 0.9063, 'grad_norm': 0.8610681602003647, 'learning_rate': 7.707865168539325e-06, 'epoch': 0.74}\n",
      "{'loss': 0.8699, 'grad_norm': 0.7908881711939605, 'learning_rate': 7.685393258426966e-06, 'epoch': 0.75}\n",
      "{'loss': 0.8379, 'grad_norm': 0.774899031949836, 'learning_rate': 7.662921348314607e-06, 'epoch': 0.76}\n",
      "{'loss': 0.8043, 'grad_norm': 0.76325896908252, 'learning_rate': 7.640449438202247e-06, 'epoch': 0.76}\n",
      "{'loss': 0.8818, 'grad_norm': 0.7316761495269156, 'learning_rate': 7.6179775280898875e-06, 'epoch': 0.77}\n",
      "{'loss': 0.8102, 'grad_norm': 0.7608076675268945, 'learning_rate': 7.595505617977528e-06, 'epoch': 0.78}\n",
      "{'loss': 0.8213, 'grad_norm': 0.7534213301944283, 'learning_rate': 7.5730337078651685e-06, 'epoch': 0.78}\n",
      "{'loss': 0.859, 'grad_norm': 0.820222311326712, 'learning_rate': 7.5505617977528086e-06, 'epoch': 0.79}\n",
      "{'loss': 0.8947, 'grad_norm': 0.7541571238412579, 'learning_rate': 7.5280898876404495e-06, 'epoch': 0.8}\n",
      "{'loss': 0.853, 'grad_norm': 0.7699395569842381, 'learning_rate': 7.5056179775280895e-06, 'epoch': 0.8}\n",
      "{'loss': 0.8273, 'grad_norm': 0.7729444656515329, 'learning_rate': 7.4831460674157305e-06, 'epoch': 0.81}\n",
      "{'loss': 0.8996, 'grad_norm': 0.7864295989192702, 'learning_rate': 7.46067415730337e-06, 'epoch': 0.82}\n",
      "{'loss': 0.7927, 'grad_norm': 0.7345098147482317, 'learning_rate': 7.438202247191011e-06, 'epoch': 0.82}\n",
      "{'loss': 0.8817, 'grad_norm': 0.8015087236980445, 'learning_rate': 7.4157303370786515e-06, 'epoch': 0.83}\n",
      "{'loss': 0.867, 'grad_norm': 0.7837113757748967, 'learning_rate': 7.3932584269662916e-06, 'epoch': 0.84}\n",
      "{'loss': 0.8307, 'grad_norm': 0.7266542644912418, 'learning_rate': 7.3707865168539325e-06, 'epoch': 0.84}\n",
      "{'loss': 0.8359, 'grad_norm': 0.7372572638307947, 'learning_rate': 7.3483146067415725e-06, 'epoch': 0.85}\n",
      "{'loss': 0.8758, 'grad_norm': 0.7519591151610783, 'learning_rate': 7.3258426966292134e-06, 'epoch': 0.86}\n",
      "{'loss': 0.8284, 'grad_norm': 0.7147514790018671, 'learning_rate': 7.3033707865168535e-06, 'epoch': 0.86}\n",
      "{'loss': 0.8228, 'grad_norm': 0.7153554467591513, 'learning_rate': 7.2808988764044944e-06, 'epoch': 0.87}\n",
      "{'loss': 0.9096, 'grad_norm': 0.7488154215206033, 'learning_rate': 7.2584269662921345e-06, 'epoch': 0.88}\n",
      "{'loss': 0.852, 'grad_norm': 0.7493489323970631, 'learning_rate': 7.2359550561797746e-06, 'epoch': 0.88}\n",
      "{'loss': 0.8482, 'grad_norm': 0.7510143101082732, 'learning_rate': 7.2134831460674155e-06, 'epoch': 0.89}\n",
      "{'loss': 0.8583, 'grad_norm': 0.7567225526755837, 'learning_rate': 7.1910112359550555e-06, 'epoch': 0.89}\n",
      "{'loss': 0.8764, 'grad_norm': 0.7751532584476819, 'learning_rate': 7.1685393258426964e-06, 'epoch': 0.9}\n",
      "{'loss': 0.8564, 'grad_norm': 0.7598195822238963, 'learning_rate': 7.1460674157303365e-06, 'epoch': 0.91}\n",
      "{'loss': 0.8685, 'grad_norm': 0.8181077008493015, 'learning_rate': 7.123595505617977e-06, 'epoch': 0.91}\n",
      "{'loss': 0.8464, 'grad_norm': 0.7396141512250535, 'learning_rate': 7.1011235955056175e-06, 'epoch': 0.92}\n",
      "{'loss': 0.8184, 'grad_norm': 0.7634583560979008, 'learning_rate': 7.078651685393258e-06, 'epoch': 0.93}\n",
      "{'loss': 0.8132, 'grad_norm': 0.7021302157586693, 'learning_rate': 7.056179775280899e-06, 'epoch': 0.93}\n",
      "{'loss': 0.8381, 'grad_norm': 0.7537567979209557, 'learning_rate': 7.0337078651685385e-06, 'epoch': 0.94}\n",
      "{'loss': 0.822, 'grad_norm': 0.7088889814636217, 'learning_rate': 7.0112359550561794e-06, 'epoch': 0.95}\n",
      "{'loss': 0.8262, 'grad_norm': 0.7291142649236749, 'learning_rate': 6.9887640449438195e-06, 'epoch': 0.95}\n",
      "{'loss': 0.8675, 'grad_norm': 0.7636937452543093, 'learning_rate': 6.96629213483146e-06, 'epoch': 0.96}\n",
      "{'loss': 0.8661, 'grad_norm': 0.7441137406861623, 'learning_rate': 6.9438202247191005e-06, 'epoch': 0.97}\n",
      "{'loss': 0.7937, 'grad_norm': 0.7401539991645653, 'learning_rate': 6.921348314606741e-06, 'epoch': 0.97}\n",
      "{'loss': 0.835, 'grad_norm': 0.7579125213682495, 'learning_rate': 6.898876404494382e-06, 'epoch': 0.98}\n",
      "{'loss': 0.8237, 'grad_norm': 0.7254043144825405, 'learning_rate': 6.876404494382022e-06, 'epoch': 0.99}\n",
      "{'loss': 0.8496, 'grad_norm': 0.7460450687653096, 'learning_rate': 6.853932584269663e-06, 'epoch': 0.99}\n",
      "{'loss': 0.8209, 'grad_norm': 0.6841250069126119, 'learning_rate': 6.8314606741573025e-06, 'epoch': 1.0}\n",
      " 33%|█████████████                          | 152/456 [34:38<1:01:56, 12.23s/it][2024-10-23 10:35:49,607] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:02<00:41,  1.49s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:06<00:57,  2.13s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:09<01:04,  2.47s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:12<01:06,  2.66s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:08,  2.84s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:07,  2.94s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:06,  3.03s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:04,  3.08s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:28<01:02,  3.11s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:31<00:59,  3.13s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:34<00:56,  3.15s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:37<00:53,  3.16s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:40<00:50,  3.17s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:43<00:47,  3.19s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:47<00:44,  3.19s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:50<00:41,  3.18s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:53<00:38,  3.20s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:56<00:35,  3.20s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:59<00:31,  3.20s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:03<00:28,  3.20s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:06<00:25,  3.18s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:09<00:22,  3.20s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:12<00:19,  3.19s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:15<00:15,  3.20s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:19<00:12,  3.19s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:22<00:09,  3.20s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:25<00:06,  3.19s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:28<00:03,  3.19s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.5098647475242615, 'eval_runtime': 94.9402, 'eval_samples_per_second': 98.978, 'eval_steps_per_second': 1.548, 'epoch': 1.0}\n",
      " 33%|█████████████                          | 152/456 [36:13<1:01:56, 12.23s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:32<00:00,  3.19s/it]\u001b[A\n",
      "{'loss': 0.8447, 'grad_norm': 0.7874496446445536, 'learning_rate': 6.808988764044943e-06, 'epoch': 1.01}\n",
      "{'loss': 0.7549, 'grad_norm': 0.9691800149620527, 'learning_rate': 6.7865168539325835e-06, 'epoch': 1.01}\n",
      "{'loss': 0.7708, 'grad_norm': 0.7814060243063493, 'learning_rate': 6.764044943820224e-06, 'epoch': 1.01}\n",
      "{'loss': 0.7773, 'grad_norm': 0.832264202251566, 'learning_rate': 6.7415730337078645e-06, 'epoch': 1.02}\n",
      "{'loss': 0.7922, 'grad_norm': 0.9695994536347405, 'learning_rate': 6.719101123595505e-06, 'epoch': 1.03}\n",
      "{'loss': 0.7455, 'grad_norm': 0.8335491578821862, 'learning_rate': 6.696629213483146e-06, 'epoch': 1.03}\n",
      "{'loss': 0.7582, 'grad_norm': 0.7990789777539773, 'learning_rate': 6.674157303370786e-06, 'epoch': 1.04}\n",
      "{'loss': 0.7131, 'grad_norm': 0.809830218042035, 'learning_rate': 6.651685393258427e-06, 'epoch': 1.05}\n",
      "{'loss': 0.7705, 'grad_norm': 0.8634814805298324, 'learning_rate': 6.6292134831460665e-06, 'epoch': 1.05}\n",
      "{'loss': 0.7589, 'grad_norm': 0.8188858579205187, 'learning_rate': 6.606741573033707e-06, 'epoch': 1.06}\n",
      "{'loss': 0.7695, 'grad_norm': 0.8813331113318444, 'learning_rate': 6.5842696629213475e-06, 'epoch': 1.07}\n",
      "{'loss': 0.7396, 'grad_norm': 0.820758706887482, 'learning_rate': 6.561797752808988e-06, 'epoch': 1.07}\n",
      "{'loss': 0.7404, 'grad_norm': 0.9087691223031434, 'learning_rate': 6.539325842696629e-06, 'epoch': 1.08}\n",
      "{'loss': 0.7365, 'grad_norm': 0.7599654822677044, 'learning_rate': 6.516853932584269e-06, 'epoch': 1.09}\n",
      "{'loss': 0.7491, 'grad_norm': 0.8701795054613273, 'learning_rate': 6.49438202247191e-06, 'epoch': 1.09}\n",
      "{'loss': 0.7445, 'grad_norm': 0.7980260867739232, 'learning_rate': 6.47191011235955e-06, 'epoch': 1.1}\n",
      "{'loss': 0.7311, 'grad_norm': 0.7664721295944471, 'learning_rate': 6.449438202247191e-06, 'epoch': 1.11}\n",
      "{'loss': 0.7497, 'grad_norm': 0.8661118545563987, 'learning_rate': 6.426966292134831e-06, 'epoch': 1.11}\n",
      "{'loss': 0.747, 'grad_norm': 0.8192841278774414, 'learning_rate': 6.404494382022471e-06, 'epoch': 1.12}\n",
      "{'loss': 0.7187, 'grad_norm': 0.826517495106486, 'learning_rate': 6.3820224719101114e-06, 'epoch': 1.12}\n",
      "{'loss': 0.6765, 'grad_norm': 0.7166952935745698, 'learning_rate': 6.359550561797752e-06, 'epoch': 1.13}\n",
      "{'loss': 0.7438, 'grad_norm': 0.7929669095347613, 'learning_rate': 6.337078651685393e-06, 'epoch': 1.14}\n",
      "{'loss': 0.7629, 'grad_norm': 0.7472842581793508, 'learning_rate': 6.314606741573033e-06, 'epoch': 1.14}\n",
      "{'loss': 0.7185, 'grad_norm': 0.7229976775150636, 'learning_rate': 6.292134831460674e-06, 'epoch': 1.15}\n",
      "{'loss': 0.7427, 'grad_norm': 0.7624064121913919, 'learning_rate': 6.269662921348314e-06, 'epoch': 1.16}\n",
      "{'loss': 0.7017, 'grad_norm': 0.7611496980950165, 'learning_rate': 6.247191011235955e-06, 'epoch': 1.16}\n",
      "{'loss': 0.7421, 'grad_norm': 0.7657817458501563, 'learning_rate': 6.224719101123595e-06, 'epoch': 1.17}\n",
      "{'loss': 0.7283, 'grad_norm': 0.7674739567165874, 'learning_rate': 6.202247191011235e-06, 'epoch': 1.18}\n",
      "{'loss': 0.7345, 'grad_norm': 0.7037733500218617, 'learning_rate': 6.179775280898876e-06, 'epoch': 1.18}\n",
      "{'loss': 0.7059, 'grad_norm': 0.7634577784126684, 'learning_rate': 6.157303370786516e-06, 'epoch': 1.19}\n",
      "{'loss': 0.7867, 'grad_norm': 0.7373693267593507, 'learning_rate': 6.134831460674157e-06, 'epoch': 1.2}\n",
      "{'loss': 0.7363, 'grad_norm': 0.7274642252471294, 'learning_rate': 6.112359550561797e-06, 'epoch': 1.2}\n",
      "{'loss': 0.7186, 'grad_norm': 0.7503599365286906, 'learning_rate': 6.089887640449438e-06, 'epoch': 1.21}\n",
      "{'loss': 0.751, 'grad_norm': 0.7336354574900313, 'learning_rate': 6.067415730337078e-06, 'epoch': 1.22}\n",
      "{'loss': 0.8169, 'grad_norm': 0.79383848182482, 'learning_rate': 6.044943820224719e-06, 'epoch': 1.22}\n",
      "{'loss': 0.7379, 'grad_norm': 0.6989796976151044, 'learning_rate': 6.022471910112359e-06, 'epoch': 1.23}\n",
      "{'loss': 0.7379, 'grad_norm': 0.7392357462095633, 'learning_rate': 6e-06, 'epoch': 1.24}\n",
      "{'loss': 0.688, 'grad_norm': 0.7147943262718479, 'learning_rate': 5.97752808988764e-06, 'epoch': 1.24}\n",
      "{'loss': 0.6948, 'grad_norm': 0.7455802718678751, 'learning_rate': 5.95505617977528e-06, 'epoch': 1.25}\n",
      "{'loss': 0.7433, 'grad_norm': 0.7761627881751397, 'learning_rate': 5.932584269662921e-06, 'epoch': 1.26}\n",
      "{'loss': 0.7094, 'grad_norm': 0.7192830555267613, 'learning_rate': 5.910112359550561e-06, 'epoch': 1.26}\n",
      "{'loss': 0.6957, 'grad_norm': 0.7438917773098161, 'learning_rate': 5.887640449438202e-06, 'epoch': 1.27}\n",
      "{'loss': 0.784, 'grad_norm': 0.791446380558024, 'learning_rate': 5.865168539325842e-06, 'epoch': 1.28}\n",
      "{'loss': 0.7157, 'grad_norm': 0.6937894725438258, 'learning_rate': 5.842696629213483e-06, 'epoch': 1.28}\n",
      "{'loss': 0.7431, 'grad_norm': 0.7863312786211315, 'learning_rate': 5.820224719101123e-06, 'epoch': 1.29}\n",
      "{'loss': 0.7767, 'grad_norm': 0.7518677659728272, 'learning_rate': 5.797752808988764e-06, 'epoch': 1.3}\n",
      "{'loss': 0.7805, 'grad_norm': 0.7871418315328399, 'learning_rate': 5.775280898876404e-06, 'epoch': 1.3}\n",
      "{'loss': 0.7919, 'grad_norm': 0.7869156170617494, 'learning_rate': 5.752808988764044e-06, 'epoch': 1.31}\n",
      "{'loss': 0.7405, 'grad_norm': 0.7364367955454887, 'learning_rate': 5.730337078651685e-06, 'epoch': 1.32}\n",
      "{'loss': 0.7556, 'grad_norm': 0.7783727364347539, 'learning_rate': 5.707865168539325e-06, 'epoch': 1.32}\n",
      "{'loss': 0.6747, 'grad_norm': 0.6838198219378016, 'learning_rate': 5.685393258426966e-06, 'epoch': 1.33}\n",
      "{'loss': 0.728, 'grad_norm': 0.7551285857992495, 'learning_rate': 5.662921348314606e-06, 'epoch': 1.34}\n",
      "{'loss': 0.6732, 'grad_norm': 0.6873741028401594, 'learning_rate': 5.640449438202247e-06, 'epoch': 1.34}\n",
      "{'loss': 0.7038, 'grad_norm': 0.7276876849276535, 'learning_rate': 5.617977528089888e-06, 'epoch': 1.35}\n",
      "{'loss': 0.7712, 'grad_norm': 0.7225729917908318, 'learning_rate': 5.595505617977528e-06, 'epoch': 1.36}\n",
      "{'loss': 0.7242, 'grad_norm': 0.7541299865658769, 'learning_rate': 5.573033707865168e-06, 'epoch': 1.36}\n",
      "{'loss': 0.7542, 'grad_norm': 0.7765826277836966, 'learning_rate': 5.550561797752808e-06, 'epoch': 1.37}\n",
      "{'loss': 0.7364, 'grad_norm': 0.7117826139898387, 'learning_rate': 5.528089887640449e-06, 'epoch': 1.38}\n",
      "{'loss': 0.7176, 'grad_norm': 0.7633663005895445, 'learning_rate': 5.505617977528089e-06, 'epoch': 1.38}\n",
      "{'loss': 0.7124, 'grad_norm': 0.724085821512088, 'learning_rate': 5.48314606741573e-06, 'epoch': 1.39}\n",
      "{'loss': 0.7409, 'grad_norm': 0.7741718848809743, 'learning_rate': 5.46067415730337e-06, 'epoch': 1.39}\n",
      "{'loss': 0.7792, 'grad_norm': 0.7690025368075061, 'learning_rate': 5.438202247191011e-06, 'epoch': 1.4}\n",
      "{'loss': 0.7434, 'grad_norm': 0.844504837685552, 'learning_rate': 5.415730337078652e-06, 'epoch': 1.41}\n",
      "{'loss': 0.7203, 'grad_norm': 0.7474417723892038, 'learning_rate': 5.393258426966292e-06, 'epoch': 1.41}\n",
      "{'loss': 0.783, 'grad_norm': 0.7874845272867692, 'learning_rate': 5.370786516853933e-06, 'epoch': 1.42}\n",
      "{'loss': 0.7153, 'grad_norm': 0.7150448849058206, 'learning_rate': 5.348314606741572e-06, 'epoch': 1.43}\n",
      "{'loss': 0.709, 'grad_norm': 0.8095253230832646, 'learning_rate': 5.325842696629213e-06, 'epoch': 1.43}\n",
      "{'loss': 0.7039, 'grad_norm': 0.7186090507275792, 'learning_rate': 5.303370786516853e-06, 'epoch': 1.44}\n",
      "{'loss': 0.7491, 'grad_norm': 0.7853731601037572, 'learning_rate': 5.280898876404494e-06, 'epoch': 1.45}\n",
      "{'loss': 0.7456, 'grad_norm': 0.8115084093304856, 'learning_rate': 5.258426966292135e-06, 'epoch': 1.45}\n",
      "{'loss': 0.6742, 'grad_norm': 0.7264664390698442, 'learning_rate': 5.235955056179775e-06, 'epoch': 1.46}\n",
      "{'loss': 0.694, 'grad_norm': 0.7937045790750961, 'learning_rate': 5.213483146067416e-06, 'epoch': 1.47}\n",
      "{'loss': 0.7106, 'grad_norm': 0.7681526528116378, 'learning_rate': 5.191011235955056e-06, 'epoch': 1.47}\n",
      "{'loss': 0.7026, 'grad_norm': 0.708608177394353, 'learning_rate': 5.168539325842697e-06, 'epoch': 1.48}\n",
      "{'loss': 0.7245, 'grad_norm': 0.8102272323648564, 'learning_rate': 5.146067415730336e-06, 'epoch': 1.49}\n",
      "{'loss': 0.7521, 'grad_norm': 0.7615531149974121, 'learning_rate': 5.123595505617977e-06, 'epoch': 1.49}\n",
      " 50%|████████████████████▌                    | 228/456 [52:25<46:54, 12.34s/it][2024-10-23 10:53:36,423] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:42,  1.52s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:06<01:02,  2.30s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:09<01:07,  2.59s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:12<01:08,  2.75s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:09,  2.91s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:08,  3.00s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:22<01:07,  3.05s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:25<01:05,  3.12s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:28<01:02,  3.14s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:31<01:00,  3.17s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:35<00:57,  3.20s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:38<00:54,  3.20s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:41<00:51,  3.20s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:44<00:48,  3.22s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:47<00:45,  3.22s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:51<00:41,  3.21s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:54<00:38,  3.23s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:57<00:35,  3.22s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [01:00<00:32,  3.22s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:04<00:28,  3.21s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:07<00:25,  3.21s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:10<00:22,  3.22s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:13<00:19,  3.24s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:16<00:16,  3.22s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:20<00:12,  3.21s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:23<00:09,  3.20s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:26<00:06,  3.20s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:29<00:03,  3.21s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.49671027064323425, 'eval_runtime': 96.1259, 'eval_samples_per_second': 97.757, 'eval_steps_per_second': 1.529, 'epoch': 1.49}\n",
      " 50%|████████████████████▌                    | 228/456 [54:01<46:54, 12.34s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:33<00:00,  3.22s/it]\u001b[A\n",
      "{'loss': 0.7593, 'grad_norm': 0.801502498291269, 'learning_rate': 5.101123595505617e-06, 'epoch': 1.5}\n",
      "{'loss': 0.7008, 'grad_norm': 0.7387909027278787, 'learning_rate': 5.078651685393258e-06, 'epoch': 1.51}\n",
      "{'loss': 0.7402, 'grad_norm': 0.7896491274634744, 'learning_rate': 5.056179775280899e-06, 'epoch': 1.51}\n",
      "{'loss': 0.7375, 'grad_norm': 0.790098018900482, 'learning_rate': 5.033707865168539e-06, 'epoch': 1.52}\n",
      "{'loss': 0.735, 'grad_norm': 0.7550718460350687, 'learning_rate': 5.01123595505618e-06, 'epoch': 1.53}\n",
      "{'loss': 0.7021, 'grad_norm': 0.7455646322151411, 'learning_rate': 4.98876404494382e-06, 'epoch': 1.53}\n",
      "{'loss': 0.7049, 'grad_norm': 0.7590919703304295, 'learning_rate': 4.966292134831461e-06, 'epoch': 1.54}\n",
      "{'loss': 0.7096, 'grad_norm': 0.726450682477385, 'learning_rate': 4.9438202247191e-06, 'epoch': 1.55}\n",
      "{'loss': 0.717, 'grad_norm': 0.7543233835355488, 'learning_rate': 4.921348314606741e-06, 'epoch': 1.55}\n",
      "{'loss': 0.7362, 'grad_norm': 0.7637271325689238, 'learning_rate': 4.898876404494382e-06, 'epoch': 1.56}\n",
      "{'loss': 0.7164, 'grad_norm': 0.7587172059711974, 'learning_rate': 4.876404494382022e-06, 'epoch': 1.57}\n",
      "{'loss': 0.7609, 'grad_norm': 0.8647307556541535, 'learning_rate': 4.853932584269663e-06, 'epoch': 1.57}\n",
      "{'loss': 0.713, 'grad_norm': 0.7313599598321358, 'learning_rate': 4.831460674157303e-06, 'epoch': 1.58}\n",
      "{'loss': 0.7465, 'grad_norm': 0.7336841606584125, 'learning_rate': 4.808988764044944e-06, 'epoch': 1.59}\n",
      "{'loss': 0.662, 'grad_norm': 0.7685223191346255, 'learning_rate': 4.786516853932584e-06, 'epoch': 1.59}\n",
      "{'loss': 0.7263, 'grad_norm': 0.7293807665341764, 'learning_rate': 4.764044943820225e-06, 'epoch': 1.6}\n",
      "{'loss': 0.6873, 'grad_norm': 0.7449571652681378, 'learning_rate': 4.741573033707865e-06, 'epoch': 1.61}\n",
      "{'loss': 0.7012, 'grad_norm': 0.738089743561302, 'learning_rate': 4.719101123595505e-06, 'epoch': 1.61}\n",
      "{'loss': 0.7046, 'grad_norm': 0.7186133967573085, 'learning_rate': 4.696629213483146e-06, 'epoch': 1.62}\n",
      "{'loss': 0.7443, 'grad_norm': 0.7604964439239463, 'learning_rate': 4.674157303370786e-06, 'epoch': 1.62}\n",
      "{'loss': 0.69, 'grad_norm': 0.7466784164271889, 'learning_rate': 4.651685393258427e-06, 'epoch': 1.63}\n",
      "{'loss': 0.7034, 'grad_norm': 0.7143441981891242, 'learning_rate': 4.629213483146067e-06, 'epoch': 1.64}\n",
      "{'loss': 0.7023, 'grad_norm': 0.7433409134192012, 'learning_rate': 4.606741573033708e-06, 'epoch': 1.64}\n",
      "{'loss': 0.7216, 'grad_norm': 0.7263224766162746, 'learning_rate': 4.584269662921348e-06, 'epoch': 1.65}\n",
      "{'loss': 0.7419, 'grad_norm': 0.729209441862534, 'learning_rate': 4.561797752808989e-06, 'epoch': 1.66}\n",
      "{'loss': 0.7548, 'grad_norm': 1.0032601075577698, 'learning_rate': 4.53932584269663e-06, 'epoch': 1.66}\n",
      "{'loss': 0.7233, 'grad_norm': 0.7414082559231047, 'learning_rate': 4.516853932584269e-06, 'epoch': 1.67}\n",
      "{'loss': 0.7211, 'grad_norm': 0.7155057593448108, 'learning_rate': 4.49438202247191e-06, 'epoch': 1.68}\n",
      "{'loss': 0.7135, 'grad_norm': 0.7069003905138056, 'learning_rate': 4.47191011235955e-06, 'epoch': 1.68}\n",
      "{'loss': 0.7023, 'grad_norm': 0.6931139158286145, 'learning_rate': 4.449438202247191e-06, 'epoch': 1.69}\n",
      "{'loss': 0.7335, 'grad_norm': 0.7469401049495572, 'learning_rate': 4.426966292134831e-06, 'epoch': 1.7}\n",
      "{'loss': 0.747, 'grad_norm': 0.7187957130538345, 'learning_rate': 4.404494382022472e-06, 'epoch': 1.7}\n",
      "{'loss': 0.7223, 'grad_norm': 0.7207409693938756, 'learning_rate': 4.382022471910112e-06, 'epoch': 1.71}\n",
      "{'loss': 0.7001, 'grad_norm': 0.6989463855207156, 'learning_rate': 4.359550561797753e-06, 'epoch': 1.72}\n",
      "{'loss': 0.7108, 'grad_norm': 0.71913566937206, 'learning_rate': 4.337078651685394e-06, 'epoch': 1.72}\n",
      "{'loss': 0.7252, 'grad_norm': 0.705892710603001, 'learning_rate': 4.314606741573033e-06, 'epoch': 1.73}\n",
      "{'loss': 0.7367, 'grad_norm': 0.7499779581243269, 'learning_rate': 4.292134831460674e-06, 'epoch': 1.74}\n",
      "{'loss': 0.7063, 'grad_norm': 0.7091602179859248, 'learning_rate': 4.269662921348314e-06, 'epoch': 1.74}\n",
      "{'loss': 0.6996, 'grad_norm': 0.7302321627206866, 'learning_rate': 4.247191011235955e-06, 'epoch': 1.75}\n",
      "{'loss': 0.6952, 'grad_norm': 0.7365069999671849, 'learning_rate': 4.224719101123595e-06, 'epoch': 1.76}\n",
      "{'loss': 0.7304, 'grad_norm': 0.8299133771904467, 'learning_rate': 4.202247191011236e-06, 'epoch': 1.76}\n",
      "{'loss': 0.7061, 'grad_norm': 0.7508510413941819, 'learning_rate': 4.179775280898877e-06, 'epoch': 1.77}\n",
      "{'loss': 0.7399, 'grad_norm': 0.7298645729096228, 'learning_rate': 4.157303370786517e-06, 'epoch': 1.78}\n",
      "{'loss': 0.7183, 'grad_norm': 0.7340129596254519, 'learning_rate': 4.134831460674158e-06, 'epoch': 1.78}\n",
      "{'loss': 0.6995, 'grad_norm': 0.7164250744006887, 'learning_rate': 4.112359550561798e-06, 'epoch': 1.79}\n",
      "{'loss': 0.7479, 'grad_norm': 0.7662435037727376, 'learning_rate': 4.089887640449438e-06, 'epoch': 1.8}\n",
      "{'loss': 0.7109, 'grad_norm': 0.7142668706180507, 'learning_rate': 4.067415730337078e-06, 'epoch': 1.8}\n",
      "{'loss': 0.7778, 'grad_norm': 0.72640838013744, 'learning_rate': 4.044943820224719e-06, 'epoch': 1.81}\n",
      "{'loss': 0.686, 'grad_norm': 0.6870613525528412, 'learning_rate': 4.022471910112359e-06, 'epoch': 1.82}\n",
      "{'loss': 0.7125, 'grad_norm': 0.7406835218706672, 'learning_rate': 4e-06, 'epoch': 1.82}\n",
      "{'loss': 0.7437, 'grad_norm': 0.7251190314510593, 'learning_rate': 3.97752808988764e-06, 'epoch': 1.83}\n",
      "{'loss': 0.6932, 'grad_norm': 0.7295517579002566, 'learning_rate': 3.955056179775281e-06, 'epoch': 1.84}\n",
      "{'loss': 0.6731, 'grad_norm': 0.6976706964147684, 'learning_rate': 3.932584269662921e-06, 'epoch': 1.84}\n",
      "{'loss': 0.708, 'grad_norm': 0.7000848943675382, 'learning_rate': 3.910112359550562e-06, 'epoch': 1.85}\n",
      "{'loss': 0.7607, 'grad_norm': 0.7262010668522498, 'learning_rate': 3.887640449438202e-06, 'epoch': 1.86}\n",
      "{'loss': 0.7191, 'grad_norm': 0.7094408151545614, 'learning_rate': 3.865168539325843e-06, 'epoch': 1.86}\n",
      "{'loss': 0.7094, 'grad_norm': 0.7300937370704903, 'learning_rate': 3.842696629213483e-06, 'epoch': 1.87}\n",
      "{'loss': 0.7054, 'grad_norm': 0.7214485168307381, 'learning_rate': 3.820224719101124e-06, 'epoch': 1.88}\n",
      "{'loss': 0.7308, 'grad_norm': 0.7200959821962417, 'learning_rate': 3.797752808988764e-06, 'epoch': 1.88}\n",
      "{'loss': 0.7392, 'grad_norm': 0.7047626433066684, 'learning_rate': 3.7752808988764043e-06, 'epoch': 1.89}\n",
      "{'loss': 0.7419, 'grad_norm': 0.7197535301673379, 'learning_rate': 3.7528089887640448e-06, 'epoch': 1.89}\n",
      "{'loss': 0.7045, 'grad_norm': 0.7235563390771271, 'learning_rate': 3.730337078651685e-06, 'epoch': 1.9}\n",
      "{'loss': 0.7414, 'grad_norm': 0.7255392456011474, 'learning_rate': 3.7078651685393257e-06, 'epoch': 1.91}\n",
      "{'loss': 0.7078, 'grad_norm': 0.7086431664516866, 'learning_rate': 3.6853932584269662e-06, 'epoch': 1.91}\n",
      "{'loss': 0.8104, 'grad_norm': 0.760543851324406, 'learning_rate': 3.6629213483146067e-06, 'epoch': 1.92}\n",
      "{'loss': 0.7131, 'grad_norm': 0.7450402173139782, 'learning_rate': 3.6404494382022472e-06, 'epoch': 1.93}\n",
      "{'loss': 0.6636, 'grad_norm': 0.700267974757636, 'learning_rate': 3.6179775280898873e-06, 'epoch': 1.93}\n",
      "{'loss': 0.7467, 'grad_norm': 0.7183330323897164, 'learning_rate': 3.5955056179775278e-06, 'epoch': 1.94}\n",
      "{'loss': 0.7278, 'grad_norm': 0.7285242964427351, 'learning_rate': 3.5730337078651683e-06, 'epoch': 1.95}\n",
      "{'loss': 0.7407, 'grad_norm': 0.7443064535444929, 'learning_rate': 3.5505617977528087e-06, 'epoch': 1.95}\n",
      "{'loss': 0.7449, 'grad_norm': 0.7053253523272177, 'learning_rate': 3.5280898876404497e-06, 'epoch': 1.96}\n",
      "{'loss': 0.6802, 'grad_norm': 0.704962655108248, 'learning_rate': 3.5056179775280897e-06, 'epoch': 1.97}\n",
      "{'loss': 0.7204, 'grad_norm': 0.6948930850956732, 'learning_rate': 3.48314606741573e-06, 'epoch': 1.97}\n",
      "{'loss': 0.6998, 'grad_norm': 0.727048456026724, 'learning_rate': 3.4606741573033707e-06, 'epoch': 1.98}\n",
      "{'loss': 0.7335, 'grad_norm': 0.7153439665517332, 'learning_rate': 3.438202247191011e-06, 'epoch': 1.99}\n",
      "{'loss': 0.6933, 'grad_norm': 0.7839157398887435, 'learning_rate': 3.4157303370786513e-06, 'epoch': 1.99}\n",
      " 67%|██████████████████████████             | 304/456 [1:09:36<30:57, 12.22s/it][2024-10-23 11:10:47,783] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:43,  1.56s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:06<00:58,  2.18s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:09<01:05,  2.53s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:12<01:08,  2.73s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:08,  2.86s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:06,  2.91s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:06,  3.01s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:24<01:04,  3.08s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:28<01:02,  3.12s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:31<00:59,  3.14s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:34<00:57,  3.17s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:37<00:54,  3.18s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:41<00:51,  3.19s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:44<00:47,  3.19s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:47<00:44,  3.19s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:50<00:41,  3.21s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:53<00:38,  3.19s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:57<00:35,  3.20s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [01:00<00:32,  3.20s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:03<00:28,  3.22s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:06<00:25,  3.21s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:09<00:22,  3.22s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:13<00:19,  3.21s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:16<00:16,  3.24s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:19<00:12,  3.20s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:22<00:09,  3.21s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:25<00:06,  3.21s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:29<00:03,  3.25s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4857330024242401, 'eval_runtime': 95.5638, 'eval_samples_per_second': 98.332, 'eval_steps_per_second': 1.538, 'epoch': 1.99}\n",
      " 67%|██████████████████████████             | 304/456 [1:11:12<30:57, 12.22s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:32<00:00,  3.20s/it]\u001b[A\n",
      "{'loss': 0.6516, 'grad_norm': 0.6954316269944836, 'learning_rate': 3.3932584269662917e-06, 'epoch': 2.0}\n",
      "{'loss': 0.6655, 'grad_norm': 0.6956866870288062, 'learning_rate': 3.3707865168539322e-06, 'epoch': 2.01}\n",
      "{'loss': 0.6137, 'grad_norm': 1.2761347589013885, 'learning_rate': 3.348314606741573e-06, 'epoch': 2.01}\n",
      "{'loss': 0.6242, 'grad_norm': 1.06694490876118, 'learning_rate': 3.3258426966292136e-06, 'epoch': 2.01}\n",
      "{'loss': 0.6325, 'grad_norm': 0.8986578943941972, 'learning_rate': 3.3033707865168537e-06, 'epoch': 2.02}\n",
      "{'loss': 0.6444, 'grad_norm': 0.8721284758349289, 'learning_rate': 3.280898876404494e-06, 'epoch': 2.03}\n",
      "{'loss': 0.6388, 'grad_norm': 0.9483174723662628, 'learning_rate': 3.2584269662921347e-06, 'epoch': 2.03}\n",
      "{'loss': 0.6465, 'grad_norm': 1.0596614645000015, 'learning_rate': 3.235955056179775e-06, 'epoch': 2.04}\n",
      "{'loss': 0.5904, 'grad_norm': 1.050169859764206, 'learning_rate': 3.2134831460674156e-06, 'epoch': 2.05}\n",
      "{'loss': 0.6124, 'grad_norm': 0.908250160398795, 'learning_rate': 3.1910112359550557e-06, 'epoch': 2.05}\n",
      "{'loss': 0.622, 'grad_norm': 0.9202815943933262, 'learning_rate': 3.1685393258426966e-06, 'epoch': 2.06}\n",
      "{'loss': 0.627, 'grad_norm': 1.0297737198582924, 'learning_rate': 3.146067415730337e-06, 'epoch': 2.07}\n",
      "{'loss': 0.6302, 'grad_norm': 0.9399968323769229, 'learning_rate': 3.1235955056179776e-06, 'epoch': 2.07}\n",
      "{'loss': 0.6083, 'grad_norm': 0.9043403223243559, 'learning_rate': 3.1011235955056177e-06, 'epoch': 2.08}\n",
      "{'loss': 0.5934, 'grad_norm': 0.838664237033886, 'learning_rate': 3.078651685393258e-06, 'epoch': 2.09}\n",
      "{'loss': 0.6294, 'grad_norm': 0.8706647624507747, 'learning_rate': 3.0561797752808986e-06, 'epoch': 2.09}\n",
      "{'loss': 0.6273, 'grad_norm': 0.9418539105403309, 'learning_rate': 3.033707865168539e-06, 'epoch': 2.1}\n",
      "{'loss': 0.624, 'grad_norm': 0.8746181285007885, 'learning_rate': 3.0112359550561796e-06, 'epoch': 2.11}\n",
      "{'loss': 0.6242, 'grad_norm': 0.855751085128202, 'learning_rate': 2.98876404494382e-06, 'epoch': 2.11}\n",
      "{'loss': 0.6085, 'grad_norm': 0.8443902190000575, 'learning_rate': 2.9662921348314606e-06, 'epoch': 2.12}\n",
      "{'loss': 0.6198, 'grad_norm': 0.8307820135785795, 'learning_rate': 2.943820224719101e-06, 'epoch': 2.12}\n",
      "{'loss': 0.5928, 'grad_norm': 0.8014731940011083, 'learning_rate': 2.9213483146067416e-06, 'epoch': 2.13}\n",
      "{'loss': 0.5857, 'grad_norm': 0.7625822197228154, 'learning_rate': 2.898876404494382e-06, 'epoch': 2.14}\n",
      "{'loss': 0.5916, 'grad_norm': 0.7949752691077944, 'learning_rate': 2.876404494382022e-06, 'epoch': 2.14}\n",
      "{'loss': 0.6006, 'grad_norm': 0.7590104617869482, 'learning_rate': 2.8539325842696626e-06, 'epoch': 2.15}\n",
      "{'loss': 0.5796, 'grad_norm': 0.7815465446950062, 'learning_rate': 2.831460674157303e-06, 'epoch': 2.16}\n",
      "{'loss': 0.5921, 'grad_norm': 0.8200021561011155, 'learning_rate': 2.808988764044944e-06, 'epoch': 2.16}\n",
      "{'loss': 0.6504, 'grad_norm': 0.7658458787216678, 'learning_rate': 2.786516853932584e-06, 'epoch': 2.17}\n",
      "{'loss': 0.6416, 'grad_norm': 0.8436703331357372, 'learning_rate': 2.7640449438202246e-06, 'epoch': 2.18}\n",
      "{'loss': 0.6126, 'grad_norm': 0.7356669594473343, 'learning_rate': 2.741573033707865e-06, 'epoch': 2.18}\n",
      "{'loss': 0.567, 'grad_norm': 0.7605069786219737, 'learning_rate': 2.7191011235955055e-06, 'epoch': 2.19}\n",
      "{'loss': 0.6253, 'grad_norm': 0.7511353562505695, 'learning_rate': 2.696629213483146e-06, 'epoch': 2.2}\n",
      "{'loss': 0.5957, 'grad_norm': 0.7955143932649704, 'learning_rate': 2.674157303370786e-06, 'epoch': 2.2}\n",
      "{'loss': 0.6047, 'grad_norm': 0.7532820466247834, 'learning_rate': 2.6516853932584266e-06, 'epoch': 2.21}\n",
      "{'loss': 0.5891, 'grad_norm': 0.7966484649867016, 'learning_rate': 2.6292134831460675e-06, 'epoch': 2.22}\n",
      "{'loss': 0.6077, 'grad_norm': 0.8026171097230261, 'learning_rate': 2.606741573033708e-06, 'epoch': 2.22}\n",
      "{'loss': 0.61, 'grad_norm': 0.7844420687365323, 'learning_rate': 2.5842696629213485e-06, 'epoch': 2.23}\n",
      "{'loss': 0.6242, 'grad_norm': 0.731041175445342, 'learning_rate': 2.5617977528089885e-06, 'epoch': 2.24}\n",
      "{'loss': 0.6146, 'grad_norm': 0.7678016806172425, 'learning_rate': 2.539325842696629e-06, 'epoch': 2.24}\n",
      "{'loss': 0.6226, 'grad_norm': 0.7834319155633873, 'learning_rate': 2.5168539325842695e-06, 'epoch': 2.25}\n",
      "{'loss': 0.6305, 'grad_norm': 0.7697386967513836, 'learning_rate': 2.49438202247191e-06, 'epoch': 2.26}\n",
      "{'loss': 0.6265, 'grad_norm': 0.7502528216830435, 'learning_rate': 2.47191011235955e-06, 'epoch': 2.26}\n",
      "{'loss': 0.6029, 'grad_norm': 0.7671600127841377, 'learning_rate': 2.449438202247191e-06, 'epoch': 2.27}\n",
      "{'loss': 0.5852, 'grad_norm': 0.7464226430782719, 'learning_rate': 2.4269662921348315e-06, 'epoch': 2.28}\n",
      "{'loss': 0.5694, 'grad_norm': 0.7463332892287874, 'learning_rate': 2.404494382022472e-06, 'epoch': 2.28}\n",
      "{'loss': 0.6209, 'grad_norm': 0.7875881431290993, 'learning_rate': 2.3820224719101125e-06, 'epoch': 2.29}\n",
      "{'loss': 0.6368, 'grad_norm': 0.7548943304145239, 'learning_rate': 2.3595505617977525e-06, 'epoch': 2.3}\n",
      "{'loss': 0.6277, 'grad_norm': 0.7342689361999043, 'learning_rate': 2.337078651685393e-06, 'epoch': 2.3}\n",
      "{'loss': 0.5854, 'grad_norm': 0.7542060014156846, 'learning_rate': 2.3146067415730335e-06, 'epoch': 2.31}\n",
      "{'loss': 0.5892, 'grad_norm': 0.7330252365983032, 'learning_rate': 2.292134831460674e-06, 'epoch': 2.32}\n",
      "{'loss': 0.5957, 'grad_norm': 0.7659585145911424, 'learning_rate': 2.269662921348315e-06, 'epoch': 2.32}\n",
      "{'loss': 0.6187, 'grad_norm': 0.7642193224523235, 'learning_rate': 2.247191011235955e-06, 'epoch': 2.33}\n",
      "{'loss': 0.6111, 'grad_norm': 0.7278781651663468, 'learning_rate': 2.2247191011235954e-06, 'epoch': 2.34}\n",
      "{'loss': 0.5849, 'grad_norm': 0.7480305890493392, 'learning_rate': 2.202247191011236e-06, 'epoch': 2.34}\n",
      "{'loss': 0.5923, 'grad_norm': 0.7604859453860037, 'learning_rate': 2.1797752808988764e-06, 'epoch': 2.35}\n",
      "{'loss': 0.6127, 'grad_norm': 0.7507985748952607, 'learning_rate': 2.1573033707865165e-06, 'epoch': 2.36}\n",
      "{'loss': 0.6116, 'grad_norm': 0.763064916552549, 'learning_rate': 2.134831460674157e-06, 'epoch': 2.36}\n",
      "{'loss': 0.6009, 'grad_norm': 0.761751169761414, 'learning_rate': 2.1123595505617975e-06, 'epoch': 2.37}\n",
      "{'loss': 0.6345, 'grad_norm': 0.7607523255110151, 'learning_rate': 2.0898876404494384e-06, 'epoch': 2.38}\n",
      "{'loss': 0.5995, 'grad_norm': 0.7539950708131081, 'learning_rate': 2.067415730337079e-06, 'epoch': 2.38}\n",
      "{'loss': 0.6048, 'grad_norm': 0.7569958648351892, 'learning_rate': 2.044943820224719e-06, 'epoch': 2.39}\n",
      "{'loss': 0.5539, 'grad_norm': 0.7363073580663706, 'learning_rate': 2.0224719101123594e-06, 'epoch': 2.39}\n",
      "{'loss': 0.6027, 'grad_norm': 0.7635886023046098, 'learning_rate': 2e-06, 'epoch': 2.4}\n",
      "{'loss': 0.6397, 'grad_norm': 0.7848526682360822, 'learning_rate': 1.9775280898876404e-06, 'epoch': 2.41}\n",
      "{'loss': 0.6139, 'grad_norm': 0.7645753633491734, 'learning_rate': 1.955056179775281e-06, 'epoch': 2.41}\n",
      "{'loss': 0.5871, 'grad_norm': 0.7301978761624748, 'learning_rate': 1.9325842696629214e-06, 'epoch': 2.42}\n",
      "{'loss': 0.6063, 'grad_norm': 0.76278521908292, 'learning_rate': 1.910112359550562e-06, 'epoch': 2.43}\n",
      "{'loss': 0.5683, 'grad_norm': 0.7436515401341489, 'learning_rate': 1.8876404494382021e-06, 'epoch': 2.43}\n",
      "{'loss': 0.6106, 'grad_norm': 0.7620378564892817, 'learning_rate': 1.8651685393258424e-06, 'epoch': 2.44}\n",
      "{'loss': 0.6217, 'grad_norm': 0.7761065199043305, 'learning_rate': 1.8426966292134831e-06, 'epoch': 2.45}\n",
      "{'loss': 0.6062, 'grad_norm': 0.7318871449954066, 'learning_rate': 1.8202247191011236e-06, 'epoch': 2.45}\n",
      "{'loss': 0.6048, 'grad_norm': 0.7256476106306338, 'learning_rate': 1.7977528089887639e-06, 'epoch': 2.46}\n",
      "{'loss': 0.5704, 'grad_norm': 0.7483723111427676, 'learning_rate': 1.7752808988764044e-06, 'epoch': 2.47}\n",
      "{'loss': 0.5814, 'grad_norm': 0.7690489072352491, 'learning_rate': 1.7528089887640449e-06, 'epoch': 2.47}\n",
      "{'loss': 0.625, 'grad_norm': 0.7401805992506866, 'learning_rate': 1.7303370786516853e-06, 'epoch': 2.48}\n",
      "{'loss': 0.5991, 'grad_norm': 0.742520560495412, 'learning_rate': 1.7078651685393256e-06, 'epoch': 2.49}\n",
      " 83%|████████████████████████████████▌      | 380/456 [1:27:26<15:36, 12.33s/it][2024-10-23 11:28:36,893] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:43,  1.55s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:06<01:01,  2.27s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:09<01:06,  2.55s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:12<01:08,  2.76s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:10,  2.94s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:08,  2.99s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:22<01:07,  3.06s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:25<01:05,  3.11s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:28<01:02,  3.14s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:31<01:00,  3.16s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:34<00:57,  3.17s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:38<00:54,  3.18s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:41<00:50,  3.19s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:44<00:48,  3.20s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:47<00:44,  3.21s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:51<00:42,  3.24s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:54<00:38,  3.20s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:57<00:35,  3.18s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [01:00<00:32,  3.20s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:03<00:28,  3.20s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:06<00:25,  3.18s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:10<00:22,  3.19s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:13<00:19,  3.20s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:16<00:15,  3.19s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:19<00:12,  3.19s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:22<00:09,  3.20s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:26<00:06,  3.20s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:29<00:03,  3.21s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4950709044933319, 'eval_runtime': 95.7222, 'eval_samples_per_second': 98.169, 'eval_steps_per_second': 1.536, 'epoch': 2.49}\n",
      " 83%|████████████████████████████████▌      | 380/456 [1:29:01<15:36, 12.33s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:32<00:00,  3.21s/it]\u001b[A\n",
      "{'loss': 0.6222, 'grad_norm': 0.769192602261731, 'learning_rate': 1.6853932584269661e-06, 'epoch': 2.49}\n",
      "{'loss': 0.5949, 'grad_norm': 0.7486025222262372, 'learning_rate': 1.6629213483146068e-06, 'epoch': 2.5}\n",
      "{'loss': 0.6197, 'grad_norm': 0.7822282073797828, 'learning_rate': 1.640449438202247e-06, 'epoch': 2.51}\n",
      "{'loss': 0.6078, 'grad_norm': 0.7333642101416673, 'learning_rate': 1.6179775280898876e-06, 'epoch': 2.51}\n",
      "{'loss': 0.5865, 'grad_norm': 0.7284255315117839, 'learning_rate': 1.5955056179775279e-06, 'epoch': 2.52}\n",
      "{'loss': 0.5975, 'grad_norm': 0.767630892906374, 'learning_rate': 1.5730337078651686e-06, 'epoch': 2.53}\n",
      "{'loss': 0.6071, 'grad_norm': 0.7305700635145412, 'learning_rate': 1.5505617977528088e-06, 'epoch': 2.53}\n",
      "{'loss': 0.5929, 'grad_norm': 0.7067155128363519, 'learning_rate': 1.5280898876404493e-06, 'epoch': 2.54}\n",
      "{'loss': 0.6682, 'grad_norm': 0.7991783484117934, 'learning_rate': 1.5056179775280898e-06, 'epoch': 2.55}\n",
      "{'loss': 0.5841, 'grad_norm': 0.7434132845520498, 'learning_rate': 1.4831460674157303e-06, 'epoch': 2.55}\n",
      "{'loss': 0.6043, 'grad_norm': 0.7291876511199236, 'learning_rate': 1.4606741573033708e-06, 'epoch': 2.56}\n",
      "{'loss': 0.541, 'grad_norm': 0.7001465716608999, 'learning_rate': 1.438202247191011e-06, 'epoch': 2.57}\n",
      "{'loss': 0.5854, 'grad_norm': 0.7170511191658483, 'learning_rate': 1.4157303370786516e-06, 'epoch': 2.57}\n",
      "{'loss': 0.5863, 'grad_norm': 0.7029301250348988, 'learning_rate': 1.393258426966292e-06, 'epoch': 2.58}\n",
      "{'loss': 0.6596, 'grad_norm': 0.7981056340938802, 'learning_rate': 1.3707865168539325e-06, 'epoch': 2.59}\n",
      "{'loss': 0.6572, 'grad_norm': 0.7732781868261183, 'learning_rate': 1.348314606741573e-06, 'epoch': 2.59}\n",
      "{'loss': 0.5741, 'grad_norm': 0.7426629663544843, 'learning_rate': 1.3258426966292133e-06, 'epoch': 2.6}\n",
      "{'loss': 0.6282, 'grad_norm': 0.7304693403630081, 'learning_rate': 1.303370786516854e-06, 'epoch': 2.61}\n",
      "{'loss': 0.584, 'grad_norm': 0.7387816092213164, 'learning_rate': 1.2808988764044943e-06, 'epoch': 2.61}\n",
      "{'loss': 0.6212, 'grad_norm': 0.7486266897828916, 'learning_rate': 1.2584269662921348e-06, 'epoch': 2.62}\n",
      "{'loss': 0.5737, 'grad_norm': 0.696107415522966, 'learning_rate': 1.235955056179775e-06, 'epoch': 2.62}\n",
      "{'loss': 0.6085, 'grad_norm': 0.7322931798690524, 'learning_rate': 1.2134831460674157e-06, 'epoch': 2.63}\n",
      "{'loss': 0.6137, 'grad_norm': 0.7551162663281781, 'learning_rate': 1.1910112359550562e-06, 'epoch': 2.64}\n",
      "{'loss': 0.6049, 'grad_norm': 0.7542460237035016, 'learning_rate': 1.1685393258426965e-06, 'epoch': 2.64}\n",
      "{'loss': 0.6333, 'grad_norm': 0.8376895893849522, 'learning_rate': 1.146067415730337e-06, 'epoch': 2.65}\n",
      "{'loss': 0.596, 'grad_norm': 0.7384704685332419, 'learning_rate': 1.1235955056179775e-06, 'epoch': 2.66}\n",
      "{'loss': 0.6024, 'grad_norm': 0.7300967637453983, 'learning_rate': 1.101123595505618e-06, 'epoch': 2.66}\n",
      "{'loss': 0.5922, 'grad_norm': 0.7532678563834629, 'learning_rate': 1.0786516853932582e-06, 'epoch': 2.67}\n",
      "{'loss': 0.5919, 'grad_norm': 0.7501983067220386, 'learning_rate': 1.0561797752808987e-06, 'epoch': 2.68}\n",
      "{'loss': 0.5962, 'grad_norm': 0.7474021891530954, 'learning_rate': 1.0337078651685394e-06, 'epoch': 2.68}\n",
      "{'loss': 0.5962, 'grad_norm': 0.74282564980373, 'learning_rate': 1.0112359550561797e-06, 'epoch': 2.69}\n",
      "{'loss': 0.5963, 'grad_norm': 0.7575022555568688, 'learning_rate': 9.887640449438202e-07, 'epoch': 2.7}\n",
      "{'loss': 0.626, 'grad_norm': 0.7186635670126479, 'learning_rate': 9.662921348314607e-07, 'epoch': 2.7}\n",
      "{'loss': 0.6144, 'grad_norm': 0.7359316533407129, 'learning_rate': 9.438202247191011e-07, 'epoch': 2.71}\n",
      "{'loss': 0.6129, 'grad_norm': 0.7555907725716032, 'learning_rate': 9.213483146067416e-07, 'epoch': 2.72}\n",
      "{'loss': 0.5826, 'grad_norm': 0.7408780785069518, 'learning_rate': 8.988764044943819e-07, 'epoch': 2.72}\n",
      "{'loss': 0.5928, 'grad_norm': 0.7609913482516913, 'learning_rate': 8.764044943820224e-07, 'epoch': 2.73}\n",
      "{'loss': 0.6039, 'grad_norm': 0.7308254753760953, 'learning_rate': 8.539325842696628e-07, 'epoch': 2.74}\n",
      "{'loss': 0.6045, 'grad_norm': 0.7462255579911603, 'learning_rate': 8.314606741573034e-07, 'epoch': 2.74}\n",
      "{'loss': 0.6002, 'grad_norm': 0.7481335019034456, 'learning_rate': 8.089887640449438e-07, 'epoch': 2.75}\n",
      "{'loss': 0.5982, 'grad_norm': 0.7534006459520023, 'learning_rate': 7.865168539325843e-07, 'epoch': 2.76}\n",
      "{'loss': 0.5837, 'grad_norm': 0.7184345825066046, 'learning_rate': 7.640449438202247e-07, 'epoch': 2.76}\n",
      "{'loss': 0.6093, 'grad_norm': 0.7160358402694792, 'learning_rate': 7.415730337078651e-07, 'epoch': 2.77}\n",
      "{'loss': 0.606, 'grad_norm': 0.7281551496246059, 'learning_rate': 7.191011235955055e-07, 'epoch': 2.78}\n",
      "{'loss': 0.5859, 'grad_norm': 0.7353814097434197, 'learning_rate': 6.96629213483146e-07, 'epoch': 2.78}\n",
      "{'loss': 0.6163, 'grad_norm': 0.7647073064375087, 'learning_rate': 6.741573033707865e-07, 'epoch': 2.79}\n",
      "{'loss': 0.6092, 'grad_norm': 0.7493871987987468, 'learning_rate': 6.51685393258427e-07, 'epoch': 2.8}\n",
      "{'loss': 0.5722, 'grad_norm': 0.7345626204266769, 'learning_rate': 6.292134831460674e-07, 'epoch': 2.8}\n",
      "{'loss': 0.6007, 'grad_norm': 0.8528473746567569, 'learning_rate': 6.067415730337079e-07, 'epoch': 2.81}\n",
      "{'loss': 0.5983, 'grad_norm': 0.7447220462571293, 'learning_rate': 5.842696629213483e-07, 'epoch': 2.82}\n",
      "{'loss': 0.6272, 'grad_norm': 0.748458601143566, 'learning_rate': 5.617977528089887e-07, 'epoch': 2.82}\n",
      "{'loss': 0.6022, 'grad_norm': 0.721024961700694, 'learning_rate': 5.393258426966291e-07, 'epoch': 2.83}\n",
      "{'loss': 0.6191, 'grad_norm': 0.7591820267396197, 'learning_rate': 5.168539325842697e-07, 'epoch': 2.84}\n",
      "{'loss': 0.6024, 'grad_norm': 0.7454736730261524, 'learning_rate': 4.943820224719101e-07, 'epoch': 2.84}\n",
      "{'loss': 0.6098, 'grad_norm': 0.734128359849883, 'learning_rate': 4.7191011235955054e-07, 'epoch': 2.85}\n",
      "{'loss': 0.615, 'grad_norm': 0.7464367046548726, 'learning_rate': 4.4943820224719097e-07, 'epoch': 2.86}\n",
      "{'loss': 0.612, 'grad_norm': 0.7695443623014275, 'learning_rate': 4.269662921348314e-07, 'epoch': 2.86}\n",
      "{'loss': 0.57, 'grad_norm': 0.6947852086875753, 'learning_rate': 4.044943820224719e-07, 'epoch': 2.87}\n",
      "{'loss': 0.6304, 'grad_norm': 0.7201456068830473, 'learning_rate': 3.8202247191011233e-07, 'epoch': 2.88}\n",
      "{'loss': 0.6426, 'grad_norm': 0.7355273065678466, 'learning_rate': 3.5955056179775277e-07, 'epoch': 2.88}\n",
      "{'loss': 0.5903, 'grad_norm': 0.736783954721387, 'learning_rate': 3.3707865168539325e-07, 'epoch': 2.89}\n",
      "{'loss': 0.6065, 'grad_norm': 0.7214108418104308, 'learning_rate': 3.146067415730337e-07, 'epoch': 2.89}\n",
      "{'loss': 0.5833, 'grad_norm': 0.7406109724203518, 'learning_rate': 2.921348314606741e-07, 'epoch': 2.9}\n",
      "{'loss': 0.5797, 'grad_norm': 0.7233390287756246, 'learning_rate': 2.6966292134831456e-07, 'epoch': 2.91}\n",
      "{'loss': 0.6097, 'grad_norm': 0.7355055245973687, 'learning_rate': 2.4719101123595505e-07, 'epoch': 2.91}\n",
      "{'loss': 0.5682, 'grad_norm': 0.7276947490747592, 'learning_rate': 2.2471910112359549e-07, 'epoch': 2.92}\n",
      "{'loss': 0.6285, 'grad_norm': 0.7651380420591971, 'learning_rate': 2.0224719101123595e-07, 'epoch': 2.93}\n",
      "{'loss': 0.5728, 'grad_norm': 0.7244951861650655, 'learning_rate': 1.7977528089887638e-07, 'epoch': 2.93}\n",
      "{'loss': 0.5923, 'grad_norm': 0.7397876794612505, 'learning_rate': 1.5730337078651685e-07, 'epoch': 2.94}\n",
      "{'loss': 0.6053, 'grad_norm': 0.7231396416513075, 'learning_rate': 1.3483146067415728e-07, 'epoch': 2.95}\n",
      "{'loss': 0.5838, 'grad_norm': 0.7269494008072824, 'learning_rate': 1.1235955056179774e-07, 'epoch': 2.95}\n",
      "{'loss': 0.6101, 'grad_norm': 0.6911870844629924, 'learning_rate': 8.988764044943819e-08, 'epoch': 2.96}\n",
      "{'loss': 0.5921, 'grad_norm': 0.7153736213917022, 'learning_rate': 6.741573033707864e-08, 'epoch': 2.97}\n",
      "{'loss': 0.5999, 'grad_norm': 0.7229622603483001, 'learning_rate': 4.4943820224719096e-08, 'epoch': 2.97}\n",
      "{'loss': 0.6367, 'grad_norm': 0.7206360005043175, 'learning_rate': 2.2471910112359548e-08, 'epoch': 2.98}\n",
      "{'loss': 0.6417, 'grad_norm': 0.7170075527267686, 'learning_rate': 0.0, 'epoch': 2.99}\n",
      "100%|███████████████████████████████████████| 456/456 [1:44:35<00:00, 12.57s/it][2024-10-23 11:45:46,623] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:352187] [RANK:0] gather_len_batches: [241, 241, 241, 241, 241, 241, 241, 241]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:03<00:43,  1.55s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:06<00:58,  2.16s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:09<01:05,  2.51s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:12<01:08,  2.73s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:15<01:09,  2.88s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:18<01:08,  2.96s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:21<01:07,  3.05s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:25<01:04,  3.08s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:28<01:02,  3.13s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:31<00:59,  3.15s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:34<00:56,  3.16s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:37<00:53,  3.17s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:41<00:50,  3.18s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:44<00:48,  3.20s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:47<00:44,  3.21s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:50<00:41,  3.21s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:53<00:38,  3.20s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:57<00:35,  3.20s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [01:00<00:31,  3.20s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:03<00:28,  3.21s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:06<00:25,  3.21s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:10<00:22,  3.26s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:13<00:19,  3.20s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [01:16<00:15,  3.20s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [01:19<00:12,  3.19s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [01:22<00:09,  3.21s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [01:26<00:06,  3.21s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [01:29<00:03,  3.20s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.49186819791793823, 'eval_runtime': 95.5497, 'eval_samples_per_second': 98.347, 'eval_steps_per_second': 1.538, 'epoch': 2.99}\n",
      "100%|███████████████████████████████████████| 456/456 [1:46:11<00:00, 12.57s/it]\n",
      "100%|███████████████████████████████████████████| 30/30 [01:32<00:00,  3.20s/it]\u001b[A\n",
      "{'train_runtime': 6414.7816, 'train_samples_per_second': 83.498, 'train_steps_per_second': 0.071, 'train_loss': 0.7515598506781093, 'epoch': 2.99}\n",
      "100%|███████████████████████████████████████| 456/456 [1:46:53<00:00, 14.06s/it]\n",
      "[2024-10-23 11:48:04,392] [INFO] [axolotl.train.train:195] [PID:352187] [RANK:0] Training Completed!!! Saving pre-trained model to ./outputs/basemodel-llama3-8b\u001b[39m\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mmi300x-shisa-llama3.1-8b-v1-dsz3\u001b[0m at: \u001b[34mhttps://wandb.ai/augmxnt/shisa-v2/runs/u7aqh88l\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35m../../../mnt/nvme1n1p1/MI300-testing/wandb/run-20241023_100110-u7aqh88l/logs\u001b[0m\n",
      "\u001b[0m\n",
      "real\t107m59.473s\n",
      "user\t1239m59.191s\n",
      "sys\t33m42.536s\n"
     ]
    }
   ],
   "source": [
    "!time accelerate launch -m axolotl.cli.train mi300x-llama3.1-8b-fft.dsz3.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b2765-bf9d-41c2-a644-5b59042445c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `8`\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:28: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_bwd\n",
      "[2024-10-23 12:25:39,907] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 12:25:39,910] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 12:25:39,937] [INFO] [root.spawn:60] [PID:440518] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmp5qxgxoon/test.c -o /tmp/tmp5qxgxoon/test.o\n",
      "[2024-10-23 12:25:39,939] [INFO] [root.spawn:60] [PID:440523] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpv55yp2ia/test.c -o /tmp/tmpv55yp2ia/test.o\n",
      "[2024-10-23 12:25:39,949] [INFO] [root.spawn:60] [PID:440518] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmp5qxgxoon/test.o -laio -o /tmp/tmp5qxgxoon/a.out\n",
      "[2024-10-23 12:25:39,952] [INFO] [root.spawn:60] [PID:440523] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpv55yp2ia/test.o -laio -o /tmp/tmpv55yp2ia/a.out\n",
      "[2024-10-23 12:25:40,006] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 12:25:40,035] [INFO] [root.spawn:60] [PID:440519] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpyyf2hj_o/test.c -o /tmp/tmpyyf2hj_o/test.o\n",
      "[2024-10-23 12:25:40,053] [INFO] [root.spawn:60] [PID:440519] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpyyf2hj_o/test.o -laio -o /tmp/tmpyyf2hj_o/a.out\n",
      "[2024-10-23 12:25:40,148] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 12:25:40,149] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 12:25:40,159] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 12:25:40,172] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 12:25:40,177] [INFO] [root.spawn:60] [PID:440520] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpsh5hz0qw/test.c -o /tmp/tmpsh5hz0qw/test.o\n",
      "[2024-10-23 12:25:40,179] [INFO] [root.spawn:60] [PID:440517] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmp2nr5dfpm/test.c -o /tmp/tmp2nr5dfpm/test.o\n",
      "[2024-10-23 12:25:40,189] [INFO] [root.spawn:60] [PID:440524] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmprfkyk58i/test.c -o /tmp/tmprfkyk58i/test.o\n",
      "[2024-10-23 12:25:40,192] [INFO] [root.spawn:60] [PID:440520] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpsh5hz0qw/test.o -laio -o /tmp/tmpsh5hz0qw/a.out\n",
      "[2024-10-23 12:25:40,192] [INFO] [root.spawn:60] [PID:440517] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmp2nr5dfpm/test.o -laio -o /tmp/tmp2nr5dfpm/a.out\n",
      "[2024-10-23 12:25:40,202] [INFO] [root.spawn:60] [PID:440521] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpx3g42etf/test.c -o /tmp/tmpx3g42etf/test.o\n",
      "[2024-10-23 12:25:40,202] [INFO] [root.spawn:60] [PID:440524] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmprfkyk58i/test.o -laio -o /tmp/tmprfkyk58i/a.out\n",
      "[2024-10-23 12:25:40,214] [INFO] [root.spawn:60] [PID:440521] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpx3g42etf/test.o -laio -o /tmp/tmpx3g42etf/a.out\n",
      "[2024-10-23 12:25:40,245] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-10-23 12:25:40,279] [INFO] [root.spawn:60] [PID:440522] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -O2 -isystem /home/hotaisle/miniforge3/envs/axolotl/include -fPIC -c /tmp/tmpbhv76jn_/test.c -o /tmp/tmpbhv76jn_/test.o\n",
      "[2024-10-23 12:25:40,295] [INFO] [root.spawn:60] [PID:440522] gcc -pthread -B /home/hotaisle/miniforge3/envs/axolotl/compiler_compat /tmp/tmpbhv76jn_/test.o -laio -o /tmp/tmpbhv76jn_/a.out\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "[2024-10-23 12:25:41,103] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:440523] [RANK:6] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 12:25:41,104] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:440518] [RANK:1] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 12:25:41,105] [DEBUG] [axolotl.normalize_config:83] [PID:440523] [RANK:6] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 12:25:41,106] [DEBUG] [axolotl.normalize_config:83] [PID:440518] [RANK:1] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "[2024-10-23 12:25:41,189] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:440519] [RANK:2] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 12:25:41,192] [DEBUG] [axolotl.normalize_config:83] [PID:440519] [RANK:2] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "/mnt/nvme1n1p1/MI300-testing/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "[2024-10-23 12:25:41,250] [INFO] [axolotl.normalize_config:207] [PID:440518] [RANK:1] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 12:25:41,250] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:440518] [RANK:1] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 12:25:41,253] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 12:25:41,262] [INFO] [axolotl.normalize_config:207] [PID:440523] [RANK:6] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 12:25:41,262] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:440523] [RANK:6] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 12:25:41,264] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 12:25:41,284] [INFO] [axolotl.normalize_config:207] [PID:440519] [RANK:2] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 12:25:41,284] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:440519] [RANK:2] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 12:25:41,286] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "[2024-10-23 12:25:41,333] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:440520] [RANK:3] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 12:25:41,334] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:440517] [RANK:0] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 12:25:41,335] [DEBUG] [axolotl.normalize_config:83] [PID:440520] [RANK:3] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 12:25:41,336] [DEBUG] [axolotl.normalize_config:83] [PID:440517] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 12:25:41,338] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:440524] [RANK:7] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 12:25:41,341] [DEBUG] [axolotl.normalize_config:83] [PID:440524] [RANK:7] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 12:25:41,386] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:440521] [RANK:4] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 12:25:41,389] [DEBUG] [axolotl.normalize_config:83] [PID:440521] [RANK:4] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 12:25:41,409] [INFO] [axolotl.normalize_config:207] [PID:440517] [RANK:0] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 12:25:41,410] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:440517] [RANK:0] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 12:25:41,411] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 12:25:41,411] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2024-10-23 12:25:41,418] [INFO] [axolotl.normalize_config:207] [PID:440520] [RANK:3] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 12:25:41,418] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:440520] [RANK:3] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 12:25:41,419] [INFO] [axolotl.normalize_config:207] [PID:440524] [RANK:7] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 12:25:41,419] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:440524] [RANK:7] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 12:25:41,419] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 12:25:41,421] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 12:25:41,547] [INFO] [axolotl.utils.config.models.input.check_eval_packing:1044] [PID:440522] [RANK:5] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-10-23 12:25:41,550] [DEBUG] [axolotl.normalize_config:83] [PID:440522] [RANK:5] bf16 support detected, enabling for this configuration.\u001b[39m\n",
      "[2024-10-23 12:25:41,559] [INFO] [axolotl.normalize_config:207] [PID:440521] [RANK:4] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 12:25:41,559] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:440521] [RANK:4] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 12:25:41,561] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 12:25:41,633] [INFO] [axolotl.normalize_config:207] [PID:440522] [RANK:5] GPU memory usage baseline: 0.000GB ()\u001b[39m\n",
      "[2024-10-23 12:25:41,633] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:440522] [RANK:5] updating dataset augmxnt/ultra-orca-boros-en-ja-v1 with `conversation: ChatTemplate.llama3` to match your chat_template\u001b[39m\n",
      "[2024-10-23 12:25:41,635] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-10-23 12:25:41,790] [DEBUG] [axolotl.load_tokenizer:290] [PID:440518] [RANK:1] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:41,790] [DEBUG] [axolotl.load_tokenizer:291] [PID:440518] [RANK:1] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:41,790] [DEBUG] [axolotl.load_tokenizer:292] [PID:440518] [RANK:1] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:41,790] [DEBUG] [axolotl.load_tokenizer:293] [PID:440518] [RANK:1] UNK: None / None\u001b[39m\n",
      "[rank1]:[W1023 12:25:41.897158624 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 12:25:41,911] [DEBUG] [axolotl.load_tokenizer:290] [PID:440523] [RANK:6] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:41,911] [DEBUG] [axolotl.load_tokenizer:291] [PID:440523] [RANK:6] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:41,911] [DEBUG] [axolotl.load_tokenizer:292] [PID:440523] [RANK:6] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:41,911] [DEBUG] [axolotl.load_tokenizer:293] [PID:440523] [RANK:6] UNK: None / None\u001b[39m\n",
      "[rank6]:[W1023 12:25:41.017806001 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 12:25:41,932] [DEBUG] [axolotl.load_tokenizer:290] [PID:440519] [RANK:2] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:41,932] [DEBUG] [axolotl.load_tokenizer:291] [PID:440519] [RANK:2] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:41,932] [DEBUG] [axolotl.load_tokenizer:292] [PID:440519] [RANK:2] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:41,932] [DEBUG] [axolotl.load_tokenizer:293] [PID:440519] [RANK:2] UNK: None / None\u001b[39m\n",
      "[rank2]:[W1023 12:25:41.039085241 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 12:25:41,978] [DEBUG] [axolotl.load_tokenizer:290] [PID:440520] [RANK:3] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:41,978] [DEBUG] [axolotl.load_tokenizer:291] [PID:440520] [RANK:3] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:41,978] [DEBUG] [axolotl.load_tokenizer:292] [PID:440520] [RANK:3] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:41,978] [DEBUG] [axolotl.load_tokenizer:293] [PID:440520] [RANK:3] UNK: None / None\u001b[39m\n",
      "[rank3]:[W1023 12:25:41.084778139 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 12:25:42,007] [DEBUG] [axolotl.load_tokenizer:290] [PID:440517] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:42,007] [DEBUG] [axolotl.load_tokenizer:291] [PID:440517] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:42,007] [DEBUG] [axolotl.load_tokenizer:292] [PID:440517] [RANK:0] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:42,007] [DEBUG] [axolotl.load_tokenizer:293] [PID:440517] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-10-23 12:25:42,008] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:440517] [RANK:0] Loading prepared dataset from disk at last_run_prepared/429f10bc8fbda011ddb592b7cc867a88...\u001b[39m\n",
      "[2024-10-23 12:25:42,014] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:440517] [RANK:0] Prepared dataset loaded from disk...\u001b[39m\n",
      "[rank0]:[W1023 12:25:42.141657401 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 12:25:42,046] [DEBUG] [axolotl.load_tokenizer:290] [PID:440524] [RANK:7] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:42,046] [DEBUG] [axolotl.load_tokenizer:291] [PID:440524] [RANK:7] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:42,046] [DEBUG] [axolotl.load_tokenizer:292] [PID:440524] [RANK:7] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:42,046] [DEBUG] [axolotl.load_tokenizer:293] [PID:440524] [RANK:7] UNK: None / None\u001b[39m\n",
      "[rank7]:[W1023 12:25:42.152777311 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 12:25:42,177] [DEBUG] [axolotl.load_tokenizer:290] [PID:440522] [RANK:5] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:42,177] [DEBUG] [axolotl.load_tokenizer:291] [PID:440522] [RANK:5] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:42,177] [DEBUG] [axolotl.load_tokenizer:292] [PID:440522] [RANK:5] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:42,177] [DEBUG] [axolotl.load_tokenizer:293] [PID:440522] [RANK:5] UNK: None / None\u001b[39m\n",
      "[rank5]:[W1023 12:25:42.284144471 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 12:25:42,180] [DEBUG] [axolotl.load_tokenizer:290] [PID:440521] [RANK:4] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:42,180] [DEBUG] [axolotl.load_tokenizer:291] [PID:440521] [RANK:4] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:42,180] [DEBUG] [axolotl.load_tokenizer:292] [PID:440521] [RANK:4] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:42,180] [DEBUG] [axolotl.load_tokenizer:293] [PID:440521] [RANK:4] UNK: None / None\u001b[39m\n",
      "[rank4]:[W1023 12:25:42.286375931 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[2024-10-23 12:25:43,328] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:440521] [RANK:4] Loading prepared dataset from disk at last_run_prepared/429f10bc8fbda011ddb592b7cc867a88...\u001b[39m\n",
      "[2024-10-23 12:25:43,328] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:440518] [RANK:1] Loading prepared dataset from disk at last_run_prepared/429f10bc8fbda011ddb592b7cc867a88...\u001b[39m\n",
      "[2024-10-23 12:25:43,328] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:440520] [RANK:3] Loading prepared dataset from disk at last_run_prepared/429f10bc8fbda011ddb592b7cc867a88...\u001b[39m\n",
      "[2024-10-23 12:25:43,328] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:440523] [RANK:6] Loading prepared dataset from disk at last_run_prepared/429f10bc8fbda011ddb592b7cc867a88...\u001b[39m\n",
      "[2024-10-23 12:25:43,328] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:440522] [RANK:5] Loading prepared dataset from disk at last_run_prepared/429f10bc8fbda011ddb592b7cc867a88...\u001b[39m\n",
      "[2024-10-23 12:25:43,329] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:440524] [RANK:7] Loading prepared dataset from disk at last_run_prepared/429f10bc8fbda011ddb592b7cc867a88...\u001b[39m\n",
      "[2024-10-23 12:25:43,329] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:440519] [RANK:2] Loading prepared dataset from disk at last_run_prepared/429f10bc8fbda011ddb592b7cc867a88...\u001b[39m\n",
      "[2024-10-23 12:25:43,335] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:440521] [RANK:4] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 12:25:43,335] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:440520] [RANK:3] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 12:25:43,335] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:440522] [RANK:5] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 12:25:43,335] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:440518] [RANK:1] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 12:25:43,343] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:440524] [RANK:7] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 12:25:43,346] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:440519] [RANK:2] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 12:25:43,348] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:440523] [RANK:6] Prepared dataset loaded from disk...\u001b[39m\n",
      "[2024-10-23 12:25:43,400] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:440517] [RANK:0] total_num_tokens: 15_001_173\u001b[39m\n",
      "[2024-10-23 12:25:43,553] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:440517] [RANK:0] `total_supervised_tokens: 7_316_759`\u001b[39m\n",
      "[2024-10-23 12:25:47,508] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:440517] [RANK:0] gather_len_batches: [471, 471, 472, 471, 471, 471, 471, 471]\u001b[39m\n",
      "[2024-10-23 12:25:47,509] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:440517] [RANK:0] data_loader_len: 58\u001b[39m\n",
      "[2024-10-23 12:25:47,530] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:440517] [RANK:0] sample_packing_eff_est across ranks: [0.9719734191894531, 0.9719734191894531, 0.9699141383171082, 0.9719734191894531, 0.9719734191894531, 0.9719734191894531, 0.9719734191894531, 0.9719734191894531]\u001b[39m\n",
      "[2024-10-23 12:25:47,531] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:440517] [RANK:0] sample_packing_eff_est: None\u001b[39m\n",
      "[2024-10-23 12:25:47,531] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:440517] [RANK:0] total_num_steps: 174\u001b[39m\n",
      "[2024-10-23 12:25:47,853] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:440517] [RANK:0] total_num_tokens: 78_013_440\u001b[39m\n",
      "[2024-10-23 12:25:49,227] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:440517] [RANK:0] `total_supervised_tokens: 38_676_186`\u001b[39m\n",
      "[2024-10-23 12:25:49,316] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:440517] [RANK:0] gather_len_batches: [2413, 2414, 2414, 2415, 2414, 2415, 2415, 2416]\u001b[39m\n",
      "[2024-10-23 12:25:49,316] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:440517] [RANK:0] data_loader_len: 301\u001b[39m\n",
      "[2024-10-23 12:25:49,317] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:440517] [RANK:0] sample_packing_eff_est across ranks: [0.9866478443145752, 0.9862391352653503, 0.9862391352653503, 0.9858307242393494, 0.9862391352653503, 0.9858307242393494, 0.9858307242393494, 0.9854227304458618]\u001b[39m\n",
      "[2024-10-23 12:25:49,317] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:440517] [RANK:0] sample_packing_eff_est: 0.99\u001b[39m\n",
      "[2024-10-23 12:25:49,317] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:440517] [RANK:0] total_num_steps: 903\u001b[39m\n",
      "[2024-10-23 12:25:49,342] [DEBUG] [axolotl.train.train:66] [PID:440517] [RANK:0] loading tokenizer... meta-llama/Llama-3.1-70B-Instruct\u001b[39m\n",
      "[2024-10-23 12:25:49,804] [DEBUG] [axolotl.load_tokenizer:290] [PID:440523] [RANK:6] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:49,804] [DEBUG] [axolotl.load_tokenizer:291] [PID:440523] [RANK:6] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,804] [DEBUG] [axolotl.load_tokenizer:292] [PID:440523] [RANK:6] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,804] [DEBUG] [axolotl.load_tokenizer:293] [PID:440523] [RANK:6] UNK: None / None\u001b[39m\n",
      "[2024-10-23 12:25:49,812] [DEBUG] [axolotl.load_tokenizer:290] [PID:440517] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:49,812] [DEBUG] [axolotl.load_tokenizer:291] [PID:440517] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,812] [DEBUG] [axolotl.load_tokenizer:292] [PID:440517] [RANK:0] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,812] [DEBUG] [axolotl.load_tokenizer:293] [PID:440517] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-10-23 12:25:49,812] [DEBUG] [axolotl.train.train:98] [PID:440517] [RANK:0] loading model\u001b[39m\n",
      "[2024-10-23 12:25:49,818] [DEBUG] [axolotl.load_tokenizer:290] [PID:440524] [RANK:7] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:49,818] [DEBUG] [axolotl.load_tokenizer:291] [PID:440524] [RANK:7] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,818] [DEBUG] [axolotl.load_tokenizer:292] [PID:440524] [RANK:7] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,818] [DEBUG] [axolotl.load_tokenizer:293] [PID:440524] [RANK:7] UNK: None / None\u001b[39m\n",
      "[2024-10-23 12:25:49,820] [DEBUG] [axolotl.load_tokenizer:290] [PID:440521] [RANK:4] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:49,820] [DEBUG] [axolotl.load_tokenizer:291] [PID:440521] [RANK:4] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,820] [DEBUG] [axolotl.load_tokenizer:292] [PID:440521] [RANK:4] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,820] [DEBUG] [axolotl.load_tokenizer:293] [PID:440521] [RANK:4] UNK: None / None\u001b[39m\n",
      "[2024-10-23 12:25:49,832] [DEBUG] [axolotl.load_tokenizer:290] [PID:440520] [RANK:3] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:49,832] [DEBUG] [axolotl.load_tokenizer:291] [PID:440520] [RANK:3] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,832] [DEBUG] [axolotl.load_tokenizer:292] [PID:440520] [RANK:3] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,832] [DEBUG] [axolotl.load_tokenizer:293] [PID:440520] [RANK:3] UNK: None / None\u001b[39m\n",
      "[2024-10-23 12:25:49,842] [DEBUG] [axolotl.load_tokenizer:290] [PID:440522] [RANK:5] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:49,842] [DEBUG] [axolotl.load_tokenizer:291] [PID:440522] [RANK:5] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,842] [DEBUG] [axolotl.load_tokenizer:292] [PID:440522] [RANK:5] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,842] [DEBUG] [axolotl.load_tokenizer:293] [PID:440522] [RANK:5] UNK: None / None\u001b[39m\n",
      "[2024-10-23 12:25:49,863] [DEBUG] [axolotl.load_tokenizer:290] [PID:440519] [RANK:2] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:49,863] [DEBUG] [axolotl.load_tokenizer:291] [PID:440519] [RANK:2] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,863] [DEBUG] [axolotl.load_tokenizer:292] [PID:440519] [RANK:2] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,863] [DEBUG] [axolotl.load_tokenizer:293] [PID:440519] [RANK:2] UNK: None / None\u001b[39m\n",
      "[2024-10-23 12:25:49,876] [DEBUG] [axolotl.load_tokenizer:290] [PID:440518] [RANK:1] EOS: 128009 / <|eot_id|>\u001b[39m\n",
      "[2024-10-23 12:25:49,876] [DEBUG] [axolotl.load_tokenizer:291] [PID:440518] [RANK:1] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,877] [DEBUG] [axolotl.load_tokenizer:292] [PID:440518] [RANK:1] PAD: 128001 / <|end_of_text|>\u001b[39m\n",
      "[2024-10-23 12:25:49,877] [DEBUG] [axolotl.load_tokenizer:293] [PID:440518] [RANK:1] UNK: None / None\u001b[39m\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [01:12<00:00,  2.41s/it]\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [01:12<00:00,  2.41s/it]\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [01:12<00:00,  2.41s/it]\n",
      "[2024-10-23 12:27:02,881] [INFO] [axolotl.load_model:855] [PID:440519] [RANK:2] GPU memory usage after model load: 131.417GB (+0.001GB cache)\u001b[39m\n",
      "[2024-10-23 12:27:02,888] [INFO] [axolotl.load_model:922] [PID:440519] [RANK:2] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 12:27:02,913] [INFO] [axolotl.load_model:855] [PID:440524] [RANK:7] GPU memory usage after model load: 131.417GB (+0.001GB cache)\u001b[39m\n",
      "[2024-10-23 12:27:02,921] [INFO] [axolotl.load_model:922] [PID:440524] [RANK:7] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 12:27:02,971] [INFO] [axolotl.load_model:855] [PID:440522] [RANK:5] GPU memory usage after model load: 131.417GB (+0.001GB cache)\u001b[39m\n",
      "[2024-10-23 12:27:02,981] [INFO] [axolotl.load_model:922] [PID:440522] [RANK:5] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [01:12<00:00,  2.43s/it]\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [01:12<00:00,  2.43s/it]\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [01:12<00:00,  2.43s/it]\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [01:12<00:00,  2.43s/it]\n",
      "[2024-10-23 12:27:03,465] [INFO] [axolotl.load_model:855] [PID:440523] [RANK:6] GPU memory usage after model load: 131.417GB (+0.001GB cache)\u001b[39m\n",
      "[2024-10-23 12:27:03,473] [INFO] [axolotl.load_model:855] [PID:440517] [RANK:0] GPU memory usage after model load: 131.417GB (+0.001GB cache)\u001b[39m\n",
      "[2024-10-23 12:27:03,475] [INFO] [axolotl.load_model:922] [PID:440523] [RANK:6] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 12:27:03,477] [INFO] [axolotl.load_model:855] [PID:440521] [RANK:4] GPU memory usage after model load: 131.417GB (+0.001GB cache)\u001b[39m\n",
      "[2024-10-23 12:27:03,483] [INFO] [axolotl.load_model:922] [PID:440517] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 12:27:03,485] [INFO] [axolotl.load_model:922] [PID:440521] [RANK:4] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-10-23 12:27:03,510] [INFO] [axolotl.load_model:855] [PID:440518] [RANK:1] GPU memory usage after model load: 131.417GB (+0.001GB cache)\u001b[39m\n",
      "[2024-10-23 12:27:03,526] [INFO] [axolotl.load_model:922] [PID:440518] [RANK:1] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [01:13<00:00,  2.44s/it]\n",
      "[2024-10-23 12:27:03,635] [INFO] [axolotl.load_model:855] [PID:440520] [RANK:3] GPU memory usage after model load: 131.417GB (+0.001GB cache)\u001b[39m\n",
      "[2024-10-23 12:27:03,646] [INFO] [axolotl.load_model:922] [PID:440520] [RANK:3] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/hotaisle/miniforge3/envs/axolotl/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-10-23 12:27:04,511] [INFO] [axolotl.train.train:178] [PID:440517] [RANK:0] Starting trainer...\u001b[39m\n",
      "[2024-10-23 12:27:04,969] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:440517] [RANK:0] gather_len_batches: [2414, 2414, 2414, 2414, 2414, 2414, 2414, 2414]\u001b[39m\n",
      "[2024-10-23 12:27:05,450] [WARNING] [engine.py:1232:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****\n",
      "Parameter Offload: Total persistent parameters: 1318912 in 161 params\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrandomfoo\u001b[0m (\u001b[33maugmxnt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/nvme1n1p1/MI300-testing/wandb/run-20241023_122720-yst3tny8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmi300x-shisa-llama3.1-70b-v1-dsz3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/augmxnt/shisa-v2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/augmxnt/shisa-v2/runs/yst3tny8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "[2024-10-23 12:27:21,016] [INFO] [axolotl.callbacks.on_train_begin:794] [PID:440517] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
      "  0%|                                                   | 0/903 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 0.8859, 'grad_norm': 2.3684496134801707, 'learning_rate': 2.2222222222222224e-07, 'epoch': 0.0}\n",
      "  0%|                                       | 1/903 [01:54<28:44:52, 114.74s/it][2024-10-23 12:29:15,768] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:440517] [RANK:0] gather_len_batches: [471, 471, 471, 471, 471, 471, 471, 471]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                          | 2/58 [00:18<08:40,  9.29s/it]\u001b[A\n",
      "  5%|██▎                                         | 3/58 [00:31<09:51, 10.76s/it]\u001b[A\n",
      "  7%|███                                         | 4/58 [00:47<11:24, 12.67s/it]\u001b[A\n",
      "  9%|███▊                                        | 5/58 [01:00<11:26, 12.95s/it]\u001b[A\n",
      " 10%|████▌                                       | 6/58 [01:14<11:18, 13.06s/it]\u001b[A\n",
      " 12%|█████▎                                      | 7/58 [01:26<10:53, 12.81s/it]\u001b[A\n",
      " 14%|██████                                      | 8/58 [01:38<10:31, 12.64s/it]\u001b[A\n",
      " 16%|██████▊                                     | 9/58 [01:50<10:15, 12.57s/it]\u001b[A\n",
      " 17%|███████▍                                   | 10/58 [02:03<09:58, 12.46s/it]\u001b[A\n",
      " 19%|████████▏                                  | 11/58 [02:15<09:40, 12.34s/it]\u001b[A\n",
      " 21%|████████▉                                  | 12/58 [02:27<09:22, 12.23s/it]\u001b[A\n",
      " 22%|█████████▋                                 | 13/58 [02:39<09:04, 12.10s/it]\u001b[A\n",
      " 24%|██████████▍                                | 14/58 [02:51<08:51, 12.07s/it]\u001b[A\n",
      " 26%|███████████                                | 15/58 [03:02<08:34, 11.97s/it]\u001b[A\n",
      " 28%|███████████▊                               | 16/58 [03:14<08:18, 11.86s/it]\u001b[A\n",
      " 29%|████████████▌                              | 17/58 [03:26<08:03, 11.78s/it]\u001b[A\n",
      " 31%|█████████████▎                             | 18/58 [03:37<07:47, 11.68s/it]\u001b[A\n",
      " 33%|██████████████                             | 19/58 [03:49<07:34, 11.66s/it]\u001b[A\n",
      " 34%|██████████████▊                            | 20/58 [04:00<07:22, 11.65s/it]\u001b[A\n",
      " 36%|███████████████▌                           | 21/58 [04:12<07:12, 11.70s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 22/58 [04:24<07:00, 11.69s/it]\u001b[A\n",
      " 40%|█████████████████                          | 23/58 [04:35<06:48, 11.67s/it]\u001b[A\n",
      " 41%|█████████████████▊                         | 24/58 [04:47<06:38, 11.71s/it]\u001b[A\n",
      " 43%|██████████████████▌                        | 25/58 [04:59<06:29, 11.79s/it]\u001b[A\n",
      " 45%|███████████████████▎                       | 26/58 [05:11<06:19, 11.86s/it]\u001b[A\n",
      " 47%|████████████████████                       | 27/58 [05:23<06:09, 11.92s/it]\u001b[A\n",
      " 48%|████████████████████▊                      | 28/58 [05:35<05:57, 11.92s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 29/58 [05:47<05:47, 11.98s/it]\u001b[A\n",
      " 52%|██████████████████████▏                    | 30/58 [05:59<05:34, 11.96s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 31/58 [06:11<05:22, 11.95s/it]\u001b[A\n",
      " 55%|███████████████████████▋                   | 32/58 [06:23<05:09, 11.90s/it]\u001b[A\n",
      " 57%|████████████████████████▍                  | 33/58 [06:35<04:57, 11.90s/it]\u001b[A\n",
      " 59%|█████████████████████████▏                 | 34/58 [06:46<04:44, 11.84s/it]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 35/58 [06:58<04:33, 11.87s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 36/58 [07:10<04:20, 11.83s/it]\u001b[A\n",
      " 64%|███████████████████████████▍               | 37/58 [07:22<04:07, 11.77s/it]\u001b[A\n",
      " 66%|████████████████████████████▏              | 38/58 [07:34<03:56, 11.81s/it]\u001b[A\n",
      " 67%|████████████████████████████▉              | 39/58 [07:46<03:46, 11.91s/it]\u001b[A\n",
      " 69%|█████████████████████████████▋             | 40/58 [07:58<03:36, 12.01s/it]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 41/58 [08:10<03:24, 12.00s/it]\u001b[A\n",
      " 72%|███████████████████████████████▏           | 42/58 [08:22<03:12, 12.00s/it]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 43/58 [08:34<02:59, 11.96s/it]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 44/58 [08:46<02:47, 11.95s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 45/58 [08:58<02:35, 11.93s/it]\u001b[A\n",
      " 79%|██████████████████████████████████         | 46/58 [09:10<02:23, 11.98s/it]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 47/58 [09:22<02:11, 11.95s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▌       | 48/58 [09:34<01:59, 11.93s/it]\u001b[A\n",
      " 84%|████████████████████████████████████▎      | 49/58 [09:45<01:47, 11.90s/it]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 50/58 [09:57<01:35, 11.90s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 51/58 [10:09<01:23, 11.87s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▌    | 52/58 [10:21<01:11, 11.84s/it]\u001b[A\n",
      " 91%|███████████████████████████████████████▎   | 53/58 [10:33<00:59, 11.83s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 54/58 [10:44<00:47, 11.83s/it]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 55/58 [10:57<00:35, 11.91s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 56/58 [11:08<00:23, 11.91s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▎| 57/58 [11:20<00:11, 11.88s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.48457154631614685, 'eval_runtime': 715.1552, 'eval_samples_per_second': 13.108, 'eval_steps_per_second': 0.206, 'epoch': 0.0}\n",
      "  0%|                                       | 1/903 [13:49<28:44:52, 114.74s/it]\n",
      "100%|███████████████████████████████████████████| 58/58 [11:32<00:00, 11.81s/it]\u001b[A\n",
      "                                                                                \u001b[A[2024-10-23 12:42:33,468] [INFO] [axolotl.callbacks.on_step_end:128] [PID:440520] [RANK:3] GPU memory usage while training: 65.873GB (+118.845GB cache)\u001b[39m\n",
      "[2024-10-23 12:42:33,468] [INFO] [axolotl.callbacks.on_step_end:128] [PID:440523] [RANK:6] GPU memory usage while training: 65.873GB (+118.845GB cache)\u001b[39m\n",
      "[2024-10-23 12:42:33,469] [INFO] [axolotl.callbacks.on_step_end:128] [PID:440518] [RANK:1] GPU memory usage while training: 65.873GB (+118.845GB cache)\u001b[39m\n",
      "[2024-10-23 12:42:33,469] [INFO] [axolotl.callbacks.on_step_end:128] [PID:440519] [RANK:2] GPU memory usage while training: 65.873GB (+118.845GB cache)\u001b[39m\n",
      "[2024-10-23 12:42:33,471] [INFO] [axolotl.callbacks.on_step_end:128] [PID:440524] [RANK:7] GPU memory usage while training: 65.873GB (+118.845GB cache)\u001b[39m\n",
      "[2024-10-23 12:42:33,472] [INFO] [axolotl.callbacks.on_step_end:128] [PID:440521] [RANK:4] GPU memory usage while training: 65.873GB (+118.845GB cache)\u001b[39m\n",
      "[2024-10-23 12:42:33,475] [INFO] [axolotl.callbacks.on_step_end:128] [PID:440517] [RANK:0] GPU memory usage while training: 65.873GB (+118.845GB cache)\u001b[39m\n",
      "  0%|                                      | 2/903 [15:12<129:16:00, 516.49s/it][2024-10-23 12:42:33,508] [INFO] [axolotl.callbacks.on_step_end:128] [PID:440522] [RANK:5] GPU memory usage while training: 65.873GB (+118.845GB cache)\u001b[39m\n",
      "{'loss': 0.8751, 'grad_norm': 2.5432121962914764, 'learning_rate': 4.444444444444445e-07, 'epoch': 0.01}\n",
      "{'loss': 0.9679, 'grad_norm': 2.3862785174944317, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.01}\n",
      "{'loss': 0.8757, 'grad_norm': 2.439050956965708, 'learning_rate': 8.88888888888889e-07, 'epoch': 0.01}\n",
      "{'loss': 0.9223, 'grad_norm': 2.4173808364758718, 'learning_rate': 1.111111111111111e-06, 'epoch': 0.02}\n",
      "{'loss': 0.9449, 'grad_norm': 2.0684678177382985, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.02}\n",
      "{'loss': 0.9647, 'grad_norm': 1.8907428381011002, 'learning_rate': 1.5555555555555558e-06, 'epoch': 0.02}\n",
      "{'loss': 0.89, 'grad_norm': 3.5710881921638298, 'learning_rate': 1.777777777777778e-06, 'epoch': 0.03}\n",
      "{'loss': 0.8837, 'grad_norm': 1.236855072389814, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.03}\n",
      "{'loss': 0.8575, 'grad_norm': 1.0230708597493348, 'learning_rate': 2.222222222222222e-06, 'epoch': 0.03}\n",
      "{'loss': 0.891, 'grad_norm': 1.0651591546326373, 'learning_rate': 2.4444444444444447e-06, 'epoch': 0.04}\n",
      "{'loss': 0.9108, 'grad_norm': 1.4676005916564487, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.04}\n",
      "{'loss': 0.8588, 'grad_norm': 0.9318662986845795, 'learning_rate': 2.888888888888889e-06, 'epoch': 0.04}\n",
      "{'loss': 0.8512, 'grad_norm': 1.1691878421291506, 'learning_rate': 3.1111111111111116e-06, 'epoch': 0.05}\n",
      "{'loss': 0.8231, 'grad_norm': 1.1668413572025838, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.05}\n",
      "{'loss': 0.7867, 'grad_norm': 1.5626663007399657, 'learning_rate': 3.555555555555556e-06, 'epoch': 0.05}\n",
      "{'loss': 0.8474, 'grad_norm': 1.0487059183709988, 'learning_rate': 3.777777777777778e-06, 'epoch': 0.06}\n",
      "{'loss': 0.8204, 'grad_norm': 0.9694882555993521, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 0.8089, 'grad_norm': 1.5701523407848492, 'learning_rate': 4.222222222222223e-06, 'epoch': 0.06}\n",
      "{'loss': 0.8062, 'grad_norm': 1.0133144458645127, 'learning_rate': 4.444444444444444e-06, 'epoch': 0.07}\n",
      "{'loss': 0.7528, 'grad_norm': 0.8586450816211506, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.07}\n",
      "{'loss': 0.8536, 'grad_norm': 1.1182976378660077, 'learning_rate': 4.888888888888889e-06, 'epoch': 0.07}\n",
      "{'loss': 0.8295, 'grad_norm': 1.5304009859765677, 'learning_rate': 5.1111111111111115e-06, 'epoch': 0.08}\n",
      "{'loss': 0.7545, 'grad_norm': 0.9302963829793677, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.08}\n",
      "{'loss': 0.811, 'grad_norm': 1.2556851905026236, 'learning_rate': 5.555555555555557e-06, 'epoch': 0.08}\n",
      "{'loss': 0.7948, 'grad_norm': 0.9928999098813277, 'learning_rate': 5.777777777777778e-06, 'epoch': 0.09}\n",
      "{'loss': 0.8428, 'grad_norm': 1.0089482543667219, 'learning_rate': 6e-06, 'epoch': 0.09}\n",
      "{'loss': 0.8513, 'grad_norm': 0.8589708035069354, 'learning_rate': 6.222222222222223e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7957, 'grad_norm': 0.8222022390289833, 'learning_rate': 6.444444444444445e-06, 'epoch': 0.1}\n",
      "{'loss': 0.8496, 'grad_norm': 1.0768300012605398, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 0.7871, 'grad_norm': 0.8837291563297434, 'learning_rate': 6.88888888888889e-06, 'epoch': 0.1}\n",
      "{'loss': 0.7641, 'grad_norm': 0.9997872033320216, 'learning_rate': 7.111111111111112e-06, 'epoch': 0.11}\n",
      "{'loss': 0.8429, 'grad_norm': 2.0005141126925183, 'learning_rate': 7.333333333333333e-06, 'epoch': 0.11}\n",
      "{'loss': 0.7748, 'grad_norm': 0.9214223977102655, 'learning_rate': 7.555555555555556e-06, 'epoch': 0.11}\n",
      "{'loss': 0.8003, 'grad_norm': 0.9062181114242319, 'learning_rate': 7.77777777777778e-06, 'epoch': 0.12}\n",
      "{'loss': 0.7858, 'grad_norm': 0.9563825969075294, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 0.8144, 'grad_norm': 1.2184331889216449, 'learning_rate': 8.222222222222222e-06, 'epoch': 0.12}\n",
      "{'loss': 0.822, 'grad_norm': 1.043905587995998, 'learning_rate': 8.444444444444446e-06, 'epoch': 0.13}\n",
      "{'loss': 0.805, 'grad_norm': 0.9719997383781914, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.13}\n",
      "{'loss': 0.8331, 'grad_norm': 1.2525272831284167, 'learning_rate': 8.888888888888888e-06, 'epoch': 0.13}\n",
      "{'loss': 0.7879, 'grad_norm': 0.8145833454985966, 'learning_rate': 9.111111111111112e-06, 'epoch': 0.14}\n",
      "{'loss': 0.7265, 'grad_norm': 0.7585613517580526, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.14}\n",
      "{'loss': 0.7999, 'grad_norm': 1.1984975000576188, 'learning_rate': 9.555555555555556e-06, 'epoch': 0.14}\n",
      "  5%|█▊                                   | 43/903 [1:03:17<17:24:29, 72.87s/it][2024-10-23 13:31:51,799] [WARNING] [stage3.py:2105:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "{'loss': 0.8742, 'grad_norm': 0.873671656599469, 'learning_rate': 9.777777777777779e-06, 'epoch': 0.15}\n",
      "  5%|█▊                                   | 44/903 [1:04:30<17:24:38, 72.97s/it][2024-10-23 13:33:09,771] [WARNING] [stage3.py:2105:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "{'loss': 0.7679, 'grad_norm': 0.8015965913822904, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 0.7334, 'grad_norm': 0.8056658228893013, 'learning_rate': 1.0222222222222223e-05, 'epoch': 0.15}\n",
      "{'loss': 0.7508, 'grad_norm': 1.4562451838095778, 'learning_rate': 1.0444444444444445e-05, 'epoch': 0.16}\n",
      "{'loss': 0.7294, 'grad_norm': 0.8533812235295903, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.16}\n",
      "{'loss': 0.6952, 'grad_norm': 0.7541221234716626, 'learning_rate': 1.088888888888889e-05, 'epoch': 0.16}\n",
      "{'loss': 0.7888, 'grad_norm': 1.1000182398852167, 'learning_rate': 1.1111111111111113e-05, 'epoch': 0.17}\n",
      "{'loss': 0.7363, 'grad_norm': 0.9327920390239312, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.17}\n",
      "{'loss': 0.7773, 'grad_norm': 0.9756199788296712, 'learning_rate': 1.1555555555555556e-05, 'epoch': 0.17}\n",
      "{'loss': 0.8233, 'grad_norm': 0.9630246876022216, 'learning_rate': 1.177777777777778e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7075, 'grad_norm': 0.6805430854092958, 'learning_rate': 1.2e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7229, 'grad_norm': 1.005082376790396, 'learning_rate': 1.2222222222222224e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7669, 'grad_norm': 1.0696961568335142, 'learning_rate': 1.2444444444444446e-05, 'epoch': 0.19}\n",
      "{'loss': 0.6978, 'grad_norm': 0.8943068014237684, 'learning_rate': 1.2666666666666667e-05, 'epoch': 0.19}\n",
      "{'loss': 0.7366, 'grad_norm': 0.9565163929195697, 'learning_rate': 1.288888888888889e-05, 'epoch': 0.19}\n",
      "{'loss': 0.7577, 'grad_norm': 0.8990616989956702, 'learning_rate': 1.3111111111111113e-05, 'epoch': 0.2}\n",
      "{'loss': 0.8001, 'grad_norm': 0.9607528733649663, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.2}\n",
      "{'loss': 0.7576, 'grad_norm': 0.8328952846228648, 'learning_rate': 1.3555555555555557e-05, 'epoch': 0.2}\n",
      "{'loss': 0.7565, 'grad_norm': 1.0754694748213947, 'learning_rate': 1.377777777777778e-05, 'epoch': 0.21}\n",
      "{'loss': 0.8261, 'grad_norm': 0.956370528723572, 'learning_rate': 1.4e-05, 'epoch': 0.21}\n",
      "{'loss': 0.8453, 'grad_norm': 1.0801974537147638, 'learning_rate': 1.4222222222222224e-05, 'epoch': 0.21}\n",
      "{'loss': 0.8313, 'grad_norm': 0.8214265428073849, 'learning_rate': 1.4444444444444446e-05, 'epoch': 0.22}\n",
      "{'loss': 0.7412, 'grad_norm': 1.0335148729026957, 'learning_rate': 1.4666666666666666e-05, 'epoch': 0.22}\n",
      "{'loss': 0.6959, 'grad_norm': 1.2305164995057054, 'learning_rate': 1.488888888888889e-05, 'epoch': 0.22}\n",
      "{'loss': 0.7232, 'grad_norm': 1.1478195693834414, 'learning_rate': 1.5111111111111112e-05, 'epoch': 0.23}\n",
      "{'loss': 0.7186, 'grad_norm': 0.8782904707905603, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.23}\n",
      "{'loss': 0.8325, 'grad_norm': 1.0337698777103062, 'learning_rate': 1.555555555555556e-05, 'epoch': 0.23}\n",
      "{'loss': 0.7402, 'grad_norm': 0.8753716796796152, 'learning_rate': 1.577777777777778e-05, 'epoch': 0.24}\n",
      "{'loss': 0.7231, 'grad_norm': 0.8641155289099244, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.24}\n",
      "{'loss': 0.7066, 'grad_norm': 1.446099427412127, 'learning_rate': 1.6222222222222223e-05, 'epoch': 0.24}\n",
      "{'loss': 0.7807, 'grad_norm': 1.141523960200097, 'learning_rate': 1.6444444444444444e-05, 'epoch': 0.25}\n",
      "{'loss': 0.7566, 'grad_norm': 0.9407749419699278, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.25}\n",
      "{'loss': 0.7616, 'grad_norm': 0.8755677685808797, 'learning_rate': 1.688888888888889e-05, 'epoch': 0.25}\n",
      "{'loss': 0.8305, 'grad_norm': 1.0372672147785293, 'learning_rate': 1.7111111111111112e-05, 'epoch': 0.26}\n",
      "{'loss': 0.7655, 'grad_norm': 0.7933765946420078, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.26}\n",
      "{'loss': 0.7482, 'grad_norm': 0.921730742523117, 'learning_rate': 1.7555555555555556e-05, 'epoch': 0.26}\n",
      "{'loss': 0.7178, 'grad_norm': 0.779239973931356, 'learning_rate': 1.7777777777777777e-05, 'epoch': 0.27}\n",
      "{'loss': 0.6764, 'grad_norm': 1.1729223107983997, 'learning_rate': 1.8e-05, 'epoch': 0.27}\n",
      "{'loss': 0.7371, 'grad_norm': 1.0696443401382338, 'learning_rate': 1.8222222222222224e-05, 'epoch': 0.27}\n",
      "{'loss': 0.7414, 'grad_norm': 1.441072219535352, 'learning_rate': 1.8444444444444448e-05, 'epoch': 0.28}\n",
      "{'loss': 0.7283, 'grad_norm': 0.8181853194229657, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.28}\n",
      "{'loss': 0.734, 'grad_norm': 1.29258622537741, 'learning_rate': 1.888888888888889e-05, 'epoch': 0.28}\n",
      "{'loss': 0.7945, 'grad_norm': 1.1416978789761993, 'learning_rate': 1.9111111111111113e-05, 'epoch': 0.29}\n",
      "{'loss': 0.7808, 'grad_norm': 1.0242675617170545, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.29}\n",
      "{'loss': 0.7498, 'grad_norm': 2.448848701109452, 'learning_rate': 1.9555555555555557e-05, 'epoch': 0.29}\n",
      "{'loss': 0.6995, 'grad_norm': 3.157437496913236, 'learning_rate': 1.977777777777778e-05, 'epoch': 0.3}\n",
      "{'loss': 0.7934, 'grad_norm': 1.6976797021646723, 'learning_rate': 2e-05, 'epoch': 0.3}\n",
      "{'loss': 0.7823, 'grad_norm': 0.8467852258242449, 'learning_rate': 1.997539975399754e-05, 'epoch': 0.3}\n",
      "{'loss': 0.7689, 'grad_norm': 1.0314690817728804, 'learning_rate': 1.9950799507995084e-05, 'epoch': 0.31}\n",
      "{'loss': 0.8233, 'grad_norm': 1.0504716117380115, 'learning_rate': 1.9926199261992623e-05, 'epoch': 0.31}\n",
      "{'loss': 0.7875, 'grad_norm': 0.9630457578479829, 'learning_rate': 1.990159901599016e-05, 'epoch': 0.31}\n",
      "{'loss': 0.7563, 'grad_norm': 1.0895411596667357, 'learning_rate': 1.9876998769987702e-05, 'epoch': 0.32}\n",
      "{'loss': 0.7672, 'grad_norm': 1.0424536434129617, 'learning_rate': 1.985239852398524e-05, 'epoch': 0.32}\n",
      "{'loss': 0.7132, 'grad_norm': 0.8653948818954827, 'learning_rate': 1.982779827798278e-05, 'epoch': 0.32}\n",
      "{'loss': 0.7007, 'grad_norm': 0.8767619672976672, 'learning_rate': 1.9803198031980323e-05, 'epoch': 0.33}\n",
      "{'loss': 0.7253, 'grad_norm': 1.309277960686795, 'learning_rate': 1.9778597785977863e-05, 'epoch': 0.33}\n",
      "{'loss': 0.8183, 'grad_norm': 1.0093138927640646, 'learning_rate': 1.97539975399754e-05, 'epoch': 0.33}\n",
      "{'loss': 0.6813, 'grad_norm': 1.4535960624612825, 'learning_rate': 1.972939729397294e-05, 'epoch': 0.34}\n",
      "{'loss': 0.7504, 'grad_norm': 4.344536249353348, 'learning_rate': 1.970479704797048e-05, 'epoch': 0.34}\n",
      "{'loss': 0.784, 'grad_norm': 0.9963377839773399, 'learning_rate': 1.968019680196802e-05, 'epoch': 0.34}\n",
      "{'loss': 0.746, 'grad_norm': 1.3990377091605741, 'learning_rate': 1.9655596555965563e-05, 'epoch': 0.35}\n",
      "{'loss': 0.6859, 'grad_norm': 1.0375618492152185, 'learning_rate': 1.9630996309963103e-05, 'epoch': 0.35}\n",
      "{'loss': 0.7459, 'grad_norm': 1.047377580894791, 'learning_rate': 1.9606396063960642e-05, 'epoch': 0.35}\n",
      "{'loss': 0.7404, 'grad_norm': 0.9402504668738929, 'learning_rate': 1.958179581795818e-05, 'epoch': 0.36}\n",
      "{'loss': 0.7834, 'grad_norm': 0.8704046510770266, 'learning_rate': 1.955719557195572e-05, 'epoch': 0.36}\n",
      "{'loss': 0.7309, 'grad_norm': 1.0575818685254408, 'learning_rate': 1.953259532595326e-05, 'epoch': 0.36}\n",
      "{'loss': 0.6743, 'grad_norm': 1.2728344371247062, 'learning_rate': 1.95079950799508e-05, 'epoch': 0.37}\n",
      "{'loss': 0.7546, 'grad_norm': 0.8771240615209296, 'learning_rate': 1.9483394833948342e-05, 'epoch': 0.37}\n",
      "{'loss': 0.7717, 'grad_norm': 0.91560279617021, 'learning_rate': 1.945879458794588e-05, 'epoch': 0.37}\n",
      "{'loss': 0.7394, 'grad_norm': 0.8716435580203207, 'learning_rate': 1.943419434194342e-05, 'epoch': 0.38}\n",
      "{'loss': 0.779, 'grad_norm': 0.9662560901569021, 'learning_rate': 1.940959409594096e-05, 'epoch': 0.38}\n",
      "{'loss': 0.7674, 'grad_norm': 1.1253676380588684, 'learning_rate': 1.93849938499385e-05, 'epoch': 0.38}\n",
      "{'loss': 0.8026, 'grad_norm': 1.321663265546321, 'learning_rate': 1.936039360393604e-05, 'epoch': 0.39}\n",
      "{'loss': 0.6892, 'grad_norm': 3.3981027776263595, 'learning_rate': 1.9335793357933582e-05, 'epoch': 0.39}\n",
      "{'loss': 0.7107, 'grad_norm': 1.0590509072102146, 'learning_rate': 1.931119311193112e-05, 'epoch': 0.39}\n",
      "{'loss': 0.7197, 'grad_norm': 0.9653703325067772, 'learning_rate': 1.928659286592866e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7466, 'grad_norm': 1.1808713800216208, 'learning_rate': 1.92619926199262e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7664, 'grad_norm': 1.1600886359971634, 'learning_rate': 1.923739237392374e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7134, 'grad_norm': 0.9633055592231603, 'learning_rate': 1.921279212792128e-05, 'epoch': 0.41}\n",
      "{'loss': 0.7209, 'grad_norm': 4.700132411083776, 'learning_rate': 1.918819188191882e-05, 'epoch': 0.41}\n",
      "{'loss': 0.8201, 'grad_norm': 2.383248630164977, 'learning_rate': 1.916359163591636e-05, 'epoch': 0.41}\n",
      "{'loss': 0.7372, 'grad_norm': 5.449553188011381, 'learning_rate': 1.91389913899139e-05, 'epoch': 0.42}\n",
      "{'loss': 0.78, 'grad_norm': 1.1952464493729928, 'learning_rate': 1.9114391143911443e-05, 'epoch': 0.42}\n",
      "{'loss': 0.7257, 'grad_norm': 1.2599493325831381, 'learning_rate': 1.908979089790898e-05, 'epoch': 0.42}\n",
      "{'loss': 0.7217, 'grad_norm': 2.1765980076719615, 'learning_rate': 1.906519065190652e-05, 'epoch': 0.43}\n",
      "{'loss': 0.7782, 'grad_norm': 1.0626943829969184, 'learning_rate': 1.904059040590406e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6504, 'grad_norm': 0.816434975288983, 'learning_rate': 1.90159901599016e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6931, 'grad_norm': 1.051741207357886, 'learning_rate': 1.899138991389914e-05, 'epoch': 0.44}\n",
      "{'loss': 0.807, 'grad_norm': 1.0431955175789016, 'learning_rate': 1.8966789667896683e-05, 'epoch': 0.44}\n",
      "{'loss': 0.7356, 'grad_norm': 0.8773330240619951, 'learning_rate': 1.8942189421894222e-05, 'epoch': 0.44}\n",
      "{'loss': 0.6586, 'grad_norm': 0.7791726437494081, 'learning_rate': 1.8917589175891758e-05, 'epoch': 0.45}\n",
      "{'loss': 0.7455, 'grad_norm': 0.9737492402646806, 'learning_rate': 1.88929889298893e-05, 'epoch': 0.45}\n",
      "{'loss': 0.7949, 'grad_norm': 1.318320005043036, 'learning_rate': 1.886838868388684e-05, 'epoch': 0.45}\n",
      "{'loss': 0.7035, 'grad_norm': 0.9801831148878357, 'learning_rate': 1.884378843788438e-05, 'epoch': 0.46}\n",
      "{'loss': 0.7352, 'grad_norm': 1.0262531000784392, 'learning_rate': 1.8819188191881922e-05, 'epoch': 0.46}\n",
      "{'loss': 0.8033, 'grad_norm': 0.9258960673606091, 'learning_rate': 1.8794587945879462e-05, 'epoch': 0.46}\n",
      "{'loss': 0.772, 'grad_norm': 0.8821473442328079, 'learning_rate': 1.8769987699876998e-05, 'epoch': 0.47}\n",
      "{'loss': 0.7918, 'grad_norm': 0.8740994004803326, 'learning_rate': 1.874538745387454e-05, 'epoch': 0.47}\n",
      "{'loss': 0.7157, 'grad_norm': 0.7915433402060943, 'learning_rate': 1.872078720787208e-05, 'epoch': 0.47}\n",
      "{'loss': 0.7674, 'grad_norm': 0.9615723105839659, 'learning_rate': 1.869618696186962e-05, 'epoch': 0.48}\n",
      "{'loss': 0.7394, 'grad_norm': 1.4524857716778246, 'learning_rate': 1.867158671586716e-05, 'epoch': 0.48}\n",
      "{'loss': 0.7192, 'grad_norm': 0.9188665706178816, 'learning_rate': 1.86469864698647e-05, 'epoch': 0.48}\n",
      "{'loss': 0.7399, 'grad_norm': 0.9472774568416421, 'learning_rate': 1.862238622386224e-05, 'epoch': 0.49}\n",
      "{'loss': 0.7537, 'grad_norm': 0.7744969146086043, 'learning_rate': 1.859778597785978e-05, 'epoch': 0.49}\n",
      "{'loss': 0.8136, 'grad_norm': 1.7913900095279887, 'learning_rate': 1.857318573185732e-05, 'epoch': 0.49}\n",
      "{'loss': 0.7256, 'grad_norm': 1.133777119384905, 'learning_rate': 1.854858548585486e-05, 'epoch': 0.5}\n",
      "{'loss': 0.6816, 'grad_norm': 2.5722486514798066, 'learning_rate': 1.85239852398524e-05, 'epoch': 0.5}\n",
      "{'loss': 0.7402, 'grad_norm': 1.272875635945257, 'learning_rate': 1.849938499384994e-05, 'epoch': 0.5}\n",
      " 17%|██████                              | 151/903 [3:08:37<14:06:57, 67.58s/it][2024-10-23 15:35:58,381] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:440517] [RANK:0] gather_len_batches: [471, 471, 471, 471, 471, 471, 471, 471]\u001b[39m\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                          | 2/58 [00:12<05:39,  6.06s/it]\u001b[A\n",
      "  5%|██▎                                         | 3/58 [00:23<07:46,  8.47s/it]\u001b[A\n",
      "  7%|███                                         | 4/58 [00:35<08:45,  9.72s/it]\u001b[A\n",
      "  9%|███▊                                        | 5/58 [00:47<09:14, 10.46s/it]\u001b[A\n",
      " 10%|████▌                                       | 6/58 [00:59<09:24, 10.85s/it]\u001b[A\n",
      " 12%|█████▎                                      | 7/58 [01:11<09:28, 11.14s/it]\u001b[A\n",
      " 14%|██████                                      | 8/58 [01:22<09:26, 11.34s/it]\u001b[A\n",
      " 16%|██████▊                                     | 9/58 [01:34<09:19, 11.42s/it]\u001b[A\n",
      " 17%|███████▍                                   | 10/58 [01:46<09:10, 11.48s/it]\u001b[A\n",
      " 19%|████████▏                                  | 11/58 [01:57<09:04, 11.58s/it]\u001b[A\n",
      " 21%|████████▉                                  | 12/58 [02:09<08:55, 11.64s/it]\u001b[A\n",
      " 22%|█████████▋                                 | 13/58 [02:21<08:44, 11.67s/it]\u001b[A\n",
      " 24%|██████████▍                                | 14/58 [02:32<08:33, 11.66s/it]\u001b[A\n",
      " 26%|███████████                                | 15/58 [02:44<08:20, 11.65s/it]\u001b[A\n",
      " 28%|███████████▊                               | 16/58 [02:56<08:10, 11.69s/it]\u001b[A\n",
      " 29%|████████████▌                              | 17/58 [03:08<07:59, 11.69s/it]\u001b[A\n",
      " 31%|█████████████▎                             | 18/58 [03:19<07:46, 11.65s/it]\u001b[A\n",
      " 33%|██████████████                             | 19/58 [03:31<07:34, 11.64s/it]\u001b[A\n",
      " 34%|██████████████▊                            | 20/58 [03:42<07:22, 11.65s/it]\u001b[A\n",
      " 36%|███████████████▌                           | 21/58 [03:54<07:10, 11.64s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 22/58 [04:06<06:59, 11.66s/it]\u001b[A\n",
      " 40%|█████████████████                          | 23/58 [04:17<06:47, 11.64s/it]\u001b[A\n",
      " 41%|█████████████████▊                         | 24/58 [04:29<06:35, 11.62s/it]\u001b[A\n",
      " 43%|██████████████████▌                        | 25/58 [04:41<06:23, 11.63s/it]\u001b[A\n",
      " 45%|███████████████████▎                       | 26/58 [04:52<06:13, 11.66s/it]\u001b[A\n",
      " 47%|████████████████████                       | 27/58 [05:04<06:02, 11.69s/it]\u001b[A\n",
      " 48%|████████████████████▊                      | 28/58 [05:16<05:50, 11.70s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 29/58 [05:28<05:41, 11.76s/it]\u001b[A\n",
      " 52%|██████████████████████▏                    | 30/58 [05:40<05:30, 11.80s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 31/58 [05:51<05:18, 11.81s/it]\u001b[A\n",
      " 55%|███████████████████████▋                   | 32/58 [06:03<05:07, 11.82s/it]\u001b[A\n",
      " 57%|████████████████████████▍                  | 33/58 [06:15<04:54, 11.79s/it]\u001b[A\n",
      " 59%|█████████████████████████▏                 | 34/58 [06:27<04:42, 11.76s/it]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 35/58 [06:38<04:29, 11.70s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 36/58 [06:50<04:16, 11.65s/it]\u001b[A\n",
      " 64%|███████████████████████████▍               | 37/58 [07:01<04:03, 11.62s/it]\u001b[A\n",
      " 66%|████████████████████████████▏              | 38/58 [07:13<03:52, 11.62s/it]\u001b[A\n",
      " 67%|████████████████████████████▉              | 39/58 [07:24<03:40, 11.59s/it]\u001b[A\n",
      " 69%|█████████████████████████████▋             | 40/58 [07:36<03:28, 11.56s/it]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 41/58 [07:48<03:16, 11.57s/it]\u001b[A\n",
      " 72%|███████████████████████████████▏           | 42/58 [07:59<03:05, 11.61s/it]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 43/58 [08:11<02:54, 11.65s/it]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 44/58 [08:23<02:43, 11.66s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 45/58 [08:34<02:31, 11.64s/it]\u001b[A\n",
      " 79%|██████████████████████████████████         | 46/58 [08:46<02:19, 11.64s/it]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 47/58 [08:58<02:08, 11.64s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "!time accelerate launch -m axolotl.cli.train mi300x-llama3.1-70b-fft.dsz3.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8e86a-5174-4808-9499-19ba1e78779c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:axolotl]",
   "language": "python",
   "name": "conda-env-axolotl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
